<!DOCTYPE html><html lang="en"> <head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.ico"><title>Seeing AI tasks through a TAM lens | benswift.me</title><meta name="author" content="Ben Swift"><meta name="description" content="When it comes to AI adoption research, we keep asking &#34;do you use ChatGPT?&#34; when we should be adding &#34;for which specific tasks?&#34; The Technology Acceptance…"><!-- Open Graph --><meta property="og:url" content="https://benswift.me/blog/2025/11/12/seeing-ai-tasks-through-a-tam-lens/"><meta property="og:type" content="article"><meta property="og:site_name" content="benswift.me"><meta property="og:title" content="Seeing AI tasks through a TAM lens"><meta property="og:description" content="When it comes to AI adoption research, we keep asking &#34;do you use ChatGPT?&#34; when we should be adding &#34;for which specific tasks?&#34; The Technology Acceptance…"><meta property="og:image" content="https://benswift.me/assets/images/pages/theremin-75.webp"><!-- Twitter --><meta name="twitter:card" content="summary_large_image"><meta name="twitter:site" content="@benswift"><meta name="twitter:title" content="Seeing AI tasks through a TAM lens"><meta name="twitter:description" content="When it comes to AI adoption research, we keep asking &#34;do you use ChatGPT?&#34; when we should be adding &#34;for which specific tasks?&#34; The Technology Acceptance…"><meta name="twitter:image" content="https://benswift.me/assets/images/pages/theremin-75.webp"><!-- AT Protocol --><link rel="site.standard.document" href="at://did:plc:tevykrhi4kibtsipzci76d76/site.standard.document/2025-11-12-seeing-ai-tasks-through-a-tam-lens"><!-- Citation metadata --><meta name="citation_title" content="Seeing AI tasks through a TAM lens"><meta name="citation_author" content="Ben Swift"><meta name="citation_date" content="2025-11-12"><meta name="citation_public_url" content="https://benswift.me/blog/2025/11/12/seeing-ai-tasks-through-a-tam-lens/"><meta name="astro-view-transitions-enabled" content="true"><meta name="astro-view-transitions-fallback" content="animate"><script type="module" src="/_astro/ClientRouter.astro_astro_type_script_index_0_lang.CDGfc0hd.js"></script><script>
      // Runs before paint to avoid flash of wrong theme
      ;(function() {
        const theme = localStorage.getItem("theme")
        if (theme === "dark" || (!theme && window.matchMedia("(prefers-color-scheme: dark)").matches)) {
          document.documentElement.classList.add("dark")
        }
      })()
    </script><link rel="stylesheet" href="/_astro/_slug_.BYY5YBAZ.css">
<style>.tag-container[data-astro-cid-lga65v7i]{display:flex;flex-wrap:wrap;gap:.5rem;margin:.5rem 0}.tag[data-astro-cid-lga65v7i]{display:inline-block;padding:.25rem .5rem;background-color:var(--bg-soft);border-radius:4px;font-size:.875rem;color:var(--text-2);text-decoration:none;transition:background-color .2s,color .2s}.tag[data-astro-cid-lga65v7i]:hover{background-color:var(--brand-soft);color:var(--brand-1)}
.cite-post[data-astro-cid-srla3z7m]{margin-top:2rem;border:1px solid var(--divider);border-radius:8px;padding:.75rem 1rem}.cite-post[data-astro-cid-srla3z7m] summary[data-astro-cid-srla3z7m]{cursor:pointer;font-size:.875rem;color:var(--text-2);user-select:none}.cite-content[data-astro-cid-srla3z7m]{margin-top:.75rem}.cite-content[data-astro-cid-srla3z7m] pre[data-astro-cid-srla3z7m]{background:var(--bg-soft);border-radius:6px;padding:1rem;overflow-x:auto;font-size:.8rem;line-height:1.5}.cite-copy[data-astro-cid-srla3z7m]{margin-top:.5rem;padding:.35rem .75rem;font-size:.8rem;border:1px solid var(--divider);border-radius:4px;background:var(--bg-soft);color:var(--text-2);cursor:pointer;transition:all .2s ease}.cite-copy[data-astro-cid-srla3z7m]:hover{color:var(--brand-1);border-color:var(--brand-1)}
.neon-perceptron.svelte-1ox9ddm{position:relative;width:100%;aspect-ratio:16 / 9;background:#111;border-radius:8px;overflow:hidden}.neon-perceptron.fullscreen.svelte-1ox9ddm{aspect-ratio:unset;width:100vw;height:100vh;border-radius:0}.neon-perceptron.svelte-1ox9ddm canvas{display:block}.controls.svelte-1ox9ddm{position:absolute;top:1rem;left:1rem;display:flex;flex-direction:column;gap:.5rem;z-index:100}.controls.svelte-1ox9ddm button:where(.svelte-1ox9ddm){padding:.5rem 1rem;background:#333;color:#fff;border:1px solid #666;border-radius:4px;cursor:pointer;font-size:.875rem;transition:background .2s}.controls.svelte-1ox9ddm button:where(.svelte-1ox9ddm):hover{background:#444}.slider-container.svelte-1ox9ddm{background:#333;padding:.5rem;border:1px solid #666;border-radius:4px;color:#fff;font-size:.75rem}.slider-container.svelte-1ox9ddm label:where(.svelte-1ox9ddm){display:flex;flex-direction:column;gap:.25rem}.slider-container.svelte-1ox9ddm input[type=range]:where(.svelte-1ox9ddm){width:120px}.fullscreen-button.svelte-1ox9ddm{position:absolute;top:1rem;right:1rem;width:2.5rem;height:2.5rem;padding:.5rem;background:#333;color:#fff;border:1px solid #666;border-radius:4px;cursor:pointer;z-index:100;transition:background .2s}.fullscreen-button.svelte-1ox9ddm:hover{background:#444}.fullscreen-button.svelte-1ox9ddm svg:where(.svelte-1ox9ddm){width:100%;height:100%}
.for-codes-table.svelte-gplc73 .search:where(.svelte-gplc73){width:100%;line-height:1.6;font-size:1rem;padding:.3rem .6rem;border:2px solid var(--brand-1);border-radius:3px;margin-bottom:1rem}.for-codes-table.svelte-gplc73 table:where(.svelte-gplc73){width:100%;border-collapse:collapse}.for-codes-table.svelte-gplc73 th:where(.svelte-gplc73),.for-codes-table.svelte-gplc73 td:where(.svelte-gplc73){padding:.5rem;text-align:left;border-bottom:1px solid var(--divider)}.for-codes-table.svelte-gplc73 .for-code:where(.svelte-gplc73){font-family:var(--font-family-mono);white-space:nowrap}
</style></head> <body> <header class="site-header" data-pagefind-ignore data-astro-cid-dmqpwcec> <nav class="nav-container" aria-label="Main navigation" data-astro-cid-dmqpwcec> <a href="/" class="site-title" data-astro-cid-dmqpwcec>benswift.me</a> <button class="mobile-menu-toggle" aria-label="Toggle navigation menu" aria-expanded="false" aria-controls="nav-links" data-astro-cid-dmqpwcec> <svg width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" data-astro-cid-dmqpwcec> <line x1="3" y1="6" x2="21" y2="6" data-astro-cid-dmqpwcec></line> <line x1="3" y1="12" x2="21" y2="12" data-astro-cid-dmqpwcec></line> <line x1="3" y1="18" x2="21" y2="18" data-astro-cid-dmqpwcec></line> </svg> </button> <div id="nav-links" class="nav-links" data-astro-cid-dmqpwcec> <a href="/blog/" class="nav-link" data-astro-cid-dmqpwcec>Blog</a><a href="/research/" class="nav-link" data-astro-cid-dmqpwcec>Research</a><a href="/livecoding/" class="nav-link" data-astro-cid-dmqpwcec>Livecoding</a><a href="/teaching/" class="nav-link" data-astro-cid-dmqpwcec>Teaching</a><a href="/bio/" class="nav-link" data-astro-cid-dmqpwcec>Bio</a> <div class="nav-social" data-astro-cid-dmqpwcec> <a href="https://github.com/benswift" class="social-link" aria-label="GitHub" target="_blank" rel="noopener" data-astro-cid-dmqpwcec> <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor" data-astro-cid-dmqpwcec> <path d="M12 0C5.37 0 0 5.37 0 12c0 5.31 3.435 9.795 8.205 11.385.6.105.825-.255.825-.57 0-.285-.015-1.23-.015-2.235-3.015.555-3.795-.735-4.035-1.41-.135-.345-.72-1.41-1.23-1.695-.42-.225-1.02-.78-.015-.795.945-.015 1.62.87 1.845 1.23 1.08 1.815 2.805 1.305 3.495.99.105-.78.42-1.305.765-1.605-2.67-.3-5.46-1.335-5.46-5.925 0-1.305.465-2.385 1.23-3.225-.12-.3-.54-1.53.12-3.18 0 0 1.005-.315 3.3 1.23.96-.27 1.98-.405 3-.405s2.04.135 3 .405c2.295-1.56 3.3-1.23 3.3-1.23.66 1.65.24 2.88.12 3.18.765.84 1.23 1.905 1.23 3.225 0 4.605-2.805 5.625-5.475 5.925.435.375.81 1.095.81 2.22 0 1.605-.015 2.895-.015 3.3 0 .315.225.69.825.57A12.02 12.02 0 0024 12c0-6.63-5.37-12-12-12z" data-astro-cid-dmqpwcec></path>   </svg> </a><a href="https://bsky.app/profile/benswift.me" class="social-link" aria-label="Bluesky" target="_blank" rel="noopener" data-astro-cid-dmqpwcec> <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor" data-astro-cid-dmqpwcec>  <path d="M12 10.8c-1.087-2.114-4.046-6.053-6.798-7.995C2.566.944 1.561 1.266.902 1.565.139 1.908 0 3.08 0 3.768c0 .69.378 5.65.624 6.479.785 2.627 3.608 3.494 6.21 3.16-.084.078-3.597.534-5.01 2.583-1.164 1.685.291 3.412 1.576 4.01 4.233 1.972 6.6-1.95 7.6-4.45.999 2.5 3.367 6.422 7.6 4.45 1.285-.598 2.74-2.325 1.576-4.01-1.413-2.049-4.926-2.505-5.01-2.583 2.602.334 5.425-.533 6.21-3.16.246-.829.624-5.789.624-6.478 0-.69-.139-1.861-.902-2.204-.659-.299-1.664-.62-4.3 1.24C14.046 4.747 11.087 8.686 12 10.8z" data-astro-cid-dmqpwcec></path>  </svg> </a><a href="https://www.linkedin.com/in/benjswift" class="social-link" aria-label="LinkedIn" target="_blank" rel="noopener" data-astro-cid-dmqpwcec> <svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor" data-astro-cid-dmqpwcec>   <path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 01-2.063-2.065 2.064 2.064 0 112.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z" data-astro-cid-dmqpwcec></path> </svg> </a> </div> <div class="search-container" data-astro-cid-otpdt6jm> <button class="search-toggle" aria-label="Search" title="Search (Ctrl+K)" data-astro-cid-otpdt6jm> <svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" data-astro-cid-otpdt6jm> <circle cx="11" cy="11" r="8" data-astro-cid-otpdt6jm></circle> <line x1="21" y1="21" x2="16.65" y2="16.65" data-astro-cid-otpdt6jm></line> </svg> </button> <dialog class="search-dialog" data-astro-cid-otpdt6jm> <div id="pagefind-search" data-astro-cid-otpdt6jm></div> <button class="search-close" aria-label="Close search" data-astro-cid-otpdt6jm> <kbd data-astro-cid-otpdt6jm>Esc</kbd> </button> </dialog> </div>   <script>
  (function() {
    let pagefindLoaded = false

    async function loadPagefind() {
      if (pagefindLoaded) return
      pagefindLoaded = true
      try {
        const link = document.createElement("link")
        link.rel = "stylesheet"
        link.href = "/pagefind/pagefind-ui.css"
        document.head.appendChild(link)

        const script = document.createElement("script")
        script.src = "/pagefind/pagefind-ui.js"
        await new Promise((resolve, reject) => {
          script.onload = resolve
          script.onerror = reject
          document.head.appendChild(script)
        })

        new window.PagefindUI({
          element: "#pagefind-search",
          showSubResults: true,
          showImages: false,
        })
      } catch {
        const el = document.getElementById("pagefind-search")
        if (el) el.innerHTML = "<p>Search is not available in dev mode.</p>"
      }
    }

    function initSearch() {
      const toggle = document.querySelector(".search-toggle")
      const dialog = document.querySelector(".search-dialog")
      const close = document.querySelector(".search-close")

      if (toggle) {
        toggle.addEventListener("click", async function() {
          if (!dialog) return
          await loadPagefind()
          dialog.showModal()
          var input = dialog.querySelector(".pagefind-ui__search-input")
          if (input) input.focus()
        })
      }

      if (close) {
        close.addEventListener("click", function() {
          if (dialog) dialog.close()
        })
      }
    }

    function handleKeydown(e) {
      if ((e.ctrlKey || e.metaKey) && e.key === "k") {
        e.preventDefault()
        var dialog = document.querySelector(".search-dialog")
        if (!dialog) return
        loadPagefind().then(function() {
          if (dialog.open) {
            dialog.close()
          } else {
            dialog.showModal()
            var input = dialog.querySelector(".pagefind-ui__search-input")
            if (input) input.focus()
          }
        })
      }
    }

    document.removeEventListener("keydown", handleKeydown)
    document.addEventListener("keydown", handleKeydown)

    initSearch()
    document.addEventListener("astro:page-load", initSearch)
  })()
</script> <button class="dark-mode-toggle" aria-label="Toggle dark mode" title="Toggle dark mode" data-astro-cid-dmqpwcec> <svg class="icon-sun" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" data-astro-cid-dmqpwcec> <circle cx="12" cy="12" r="5" data-astro-cid-dmqpwcec></circle> <line x1="12" y1="1" x2="12" y2="3" data-astro-cid-dmqpwcec></line> <line x1="12" y1="21" x2="12" y2="23" data-astro-cid-dmqpwcec></line> <line x1="4.22" y1="4.22" x2="5.64" y2="5.64" data-astro-cid-dmqpwcec></line> <line x1="18.36" y1="18.36" x2="19.78" y2="19.78" data-astro-cid-dmqpwcec></line> <line x1="1" y1="12" x2="3" y2="12" data-astro-cid-dmqpwcec></line> <line x1="21" y1="12" x2="23" y2="12" data-astro-cid-dmqpwcec></line> <line x1="4.22" y1="19.78" x2="5.64" y2="18.36" data-astro-cid-dmqpwcec></line> <line x1="18.36" y1="5.64" x2="19.78" y2="4.22" data-astro-cid-dmqpwcec></line> </svg> <svg class="icon-moon" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" data-astro-cid-dmqpwcec> <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z" data-astro-cid-dmqpwcec></path> </svg> </button> </div> </nav> </header>  <script type="module">function n(){const e=document.querySelector(".mobile-menu-toggle"),o=document.querySelector("#nav-links");e?.addEventListener("click",()=>{const t=e.getAttribute("aria-expanded")==="true";e.setAttribute("aria-expanded",String(!t)),o?.classList.toggle("open")}),document.querySelector(".dark-mode-toggle")?.addEventListener("click",()=>{const t=document.documentElement.classList.toggle("dark");localStorage.setItem("theme",t?"dark":"light")})}n();document.addEventListener("astro:page-load",n);</script> <main data-pagefind-body>  <h1 class="page-title">Seeing AI tasks through a TAM lens</h1> <p class="post-date">12 Nov 25</p> <p class="tag-container" data-astro-cid-lga65v7i><a href="/blog/tag/ai/" class="tag" data-astro-cid-lga65v7i>ai</a></p>  <p>When it comes to AI adoption research, we keep asking “do you use ChatGPT?” when
we should be adding “for which specific tasks?”</p>
<p>The
<a href="https://en.wikipedia.org/wiki/Technology_acceptance_model">Technology Acceptance Model</a>
(TAM) has been successfully applied to understand LLM
adoption---<a href="https://www.tandfonline.com/doi/full/10.1080/10447318.2024.2314358">surveys of hundreds of users</a>
confirm that perceived usefulness and ease of use predict whether people adopt
these tools. But these studies treat adoption as a technology-level decision
rather than examining the specific <em>tasks</em> where these things are useful.</p>
<p>A researcher might find an LLM really useful for literature search but useless for
theoretical analysis. A journalist might rely on it for drafting routine updates
but avoid it for investigative work. A disinfo actor will gladly use it to
<a href="https://www.mediamatters.org/steve-bannon/misinformer-year-steve-bannons-flood-zone-shit-approach-destroying-american-democracy">“flood the zone”</a>,
but not for writing to their loved ones. The same person using the same model
would give very different answers to the “are LLMs useful” depending on the task
at hand.</p>
<p>So I propose a different framework<sup><a href="#user-content-fn-branding" id="user-content-fnref-branding" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>: treat each (user, model, task)
triple as its own thing, mapped onto a two-dimensional plane. There are two
orthogonal axes:</p>
<p><strong>Familiarity</strong>: how much you’ve actually used this specific model for this
specific task. Ranges from “never tried” to “extensive experience”. This only
moves in one direction---you can’t become less familiar with something you’ve
tried.</p>
<p><strong>Usefulness</strong>: whether using the model actually helps you get the task done
faster. Ranges from actively slowing you down through making no real difference
to genuinely speeding you up. This corresponds to TAM’s “perceived usefulness”
but evaluated task-specifically and focused on time/effort rather than moral
dimensions<sup><a href="#user-content-fn-ethics" id="user-content-fnref-ethics" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup>. Crucially, this assessment can change as familiarity
increases---a tool that initially seems fast might prove time-consuming once you
factor in error correction, or initial setup overhead might give way to genuine
productivity gains. And there’s always going to be noise (stochastic parrots and
all that) so it’s really just an “in general” judgement.</p>
<p>The same user with the same AI model might simultaneously occupy multiple zones
depending on task. And importantly, there’s a substantial neutral zone in the
middle---tasks where using the tool takes about as much time and effort as doing
it yourself.</p>
<svg class="tam-diagram" width="100%" viewBox="0 0 600 500" xmlns="http://www.w3.org/2000/svg">
  <!-- Background zones -->
  <rect x="50" y="50" width="250" height="133" class="zone-green-light"></rect>
  <text x="175" y="110" text-anchor="middle" font-size="14" class="text-green" font-weight="600">Early positive</text>
  <text x="175" y="128" text-anchor="middle" font-size="12" class="text-green">impression</text>
  <rect x="300" y="50" width="250" height="133" class="zone-green-dark"></rect>
  <text x="425" y="110" text-anchor="middle" font-size="14" class="text-green-dark" font-weight="600">Proven</text>
  <text x="425" y="128" text-anchor="middle" font-size="12" class="text-green-dark">integration</text>
  <rect x="50" y="183" width="250" height="134" class="zone-orange-light"></rect>
  <text x="175" y="243" text-anchor="middle" font-size="14" class="text-orange" font-weight="600">Neutral zone</text>
  <text x="175" y="261" text-anchor="middle" font-size="12" class="text-orange">(premature/speculative)</text>
  <rect x="300" y="183" width="250" height="134" class="zone-orange-dark"></rect>
  <text x="425" y="243" text-anchor="middle" font-size="14" class="text-orange" font-weight="600">Neutral zone</text>
  <text x="425" y="261" text-anchor="middle" font-size="12" class="text-orange">(informed)</text>
  <rect x="50" y="317" width="250" height="133" class="zone-red-light"></rect>
  <text x="175" y="377" text-anchor="middle" font-size="14" class="text-red" font-weight="600">Premature</text>
  <text x="175" y="395" text-anchor="middle" font-size="12" class="text-red">rejection</text>
  <rect x="300" y="317" width="250" height="133" class="zone-red-dark"></rect>
  <text x="425" y="377" text-anchor="middle" font-size="14" class="text-red-dark" font-weight="600">Informed</text>
  <text x="425" y="395" text-anchor="middle" font-size="12" class="text-red-dark">rejection</text>
  <!-- Axes -->
  <line x1="50" y1="450" x2="550" y2="450" class="axis" stroke-width="2" marker-end="url(#arrowhead)"></line>
  <line x1="50" y1="450" x2="50" y2="50" class="axis" stroke-width="2" marker-end="url(#arrowhead)"></line>
  <!-- Arrow markers -->
  <defs>
    <marker id="arrowhead" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
      <polygon points="0 0, 10 3, 0 6" class="arrowhead"></polygon>
    </marker>
  </defs>
  <!-- Axis labels -->
</svg><p><text x="300" y="485" text-anchor="middle" font-size="16" class="axis-label" font-weight="600">Familiarity →</text>
<text x="25" y="250" text-anchor="middle" font-size="16" class="axis-label" font-weight="600" transform="rotate(-90, 25, 250)">Usefulness →</text></p>
  <!-- Grid lines -->
  <line x1="300" y1="50" x2="300" y2="450" class="grid-line" stroke-width="1" stroke-dasharray="5,5">
  <line x1="50" y1="183" x2="550" y2="183" class="grid-line" stroke-width="1" stroke-dasharray="5,5">
  <line x1="50" y1="317" x2="550" y2="317" class="grid-line" stroke-width="1" stroke-dasharray="5,5">

<h2 id="the-zones">The zones</h2>
<p><strong>High familiarity, speeds you up</strong> (upper right): This is the good place.
You’ve got extensive experience, you’ve developed effective prompting
strategies, you understand the limitations, and you’ve integrated it into your
workflow in ways that genuinely save time. This might be generating first drafts
of routine correspondence that need minimal editing. For me (an academic AI
researcher and software developer) things like writing scripts to automate
repetitive tasks and generating boilerplate code are in this bucket.</p>
<p><strong>High familiarity, no difference or slows you down</strong> (middle/lower right):
Informed rejection. You haven’t simply failed to try---you’ve engaged
extensively and concluded it doesn’t actually save time, or actively wastes it.
You’ve hit the model’s limitations repeatedly enough to form a stable
assessment.</p>
<p>The neutral zone is interesting---tasks where using the tool takes about as much
time and effort as doing it yourself, so you might use it or might not depending
on mood (or whether you’re paying for it or you’re being
<a href="https://www.wheresyoured.at/why-everybody-is-losing-money-on-ai/">subsidised by Silicon Valley VCs</a>).
A researcher editing AI-generated literature summaries that need as much work to
fix as they would to write from scratch. A designer tweaking AI-generated
layouts that never quite capture the intended aesthetic and require just as much
time to correct as to create manually.</p>
<p>The genuinely slowing-you-down zone includes complex reasoning tasks,
fact-checking mission-critical information, or creative work requiring genuine
originality where the tool actively wastes your time with output that needs
extensive correction or produces misleading results you have to untangle. In my
use of Claude Code (and friends) some coding tasks fall into this for
sure---they add technical debt that takes longer to fix than writing correctly
from scratch.</p>
<p><strong>Low familiarity, speeds you up</strong> (upper left): Early positive impression.
You’ve tried it once or twice and it seemed to save time, but you haven’t
encountered edge cases or the full overhead of error correction. This zone is
unstable---continued use drives rightward along the familiarity axis, but
percieved usefulness might shift up or down as experience accumulates and you
discover hidden time costs.</p>
<p><strong>Low familiarity, no difference or slows you down</strong> (middle/lower left):
Premature rejection or speculative avoidance. Either you tried it once, found it
took just as long or longer, and gave up, or you suspect the model can’t handle
it efficiently based on general reputation. Unlike informed rejection, these
assessments are speculative rather than experiential.</p>
<h2 id="why-this-matters">Why this matters</h2>
<p>Consider an academic researcher (hey---I write what I know). I might map my
experience like this:</p>
<ul>
<li><em>vibecoding all the things</em>: upper right---see elsewhere on my blog, but I’ve
overall seen an increase in my productivity, genuinely getting more done
faster</li>
<li><em>literature search and summarisation</em>: upper right---proven to save time
finding relevant papers quickly</li>
<li><em>drafting standard email responses</em>: upper right---saves time, works
consistently with minimal editing needed</li>
<li><em>generating first drafts of “methods sections”</em>: middle right---tried
extensively, but I end up rewriting so much it takes about the same time as
writing from scratch</li>
<li><em>writing out core/key arguments</em>: lower right for sure---consistently produces
superficial output that takes longer to fix than to write properly in the
first place</li>
</ul>
<p>Technology-level TAM would aggregate these into a single “perceived usefulness”
score for “LLMs in academic research”. But that obscures the actual pattern:
which is much lumpier and task-dependent, with some tasks genuinely saving time
and others actively wasting it.</p>
<p>The framework also explains why people’s assessments differ so dramatically.
We’re often arguing about different tasks while thinking we’re arguing about the
same technology. When someone says “LLMs are transformative for writing” and
someone else says “they’re useless”---they might both be right, just talking
about different writing tasks with genuinely different time costs.</p>
<p>This matches what
<a href="https://www.nature.com/articles/s41562-024-02024-1">recent meta-analyses</a> have
found: human-AI combinations perform significantly differently depending on task
type, with performance losses in decision-making tasks but gains in content
creation tasks. The tool’s utility is entirely task-dependent. Which really
shouldn’t surprise anyone, but here we are.</p>
<h2 id="the-transformationautomationmagnification-thing">The transformation/automation/magnification thing</h2>
<p>You’ve probably seen people claim AI will “transform” work in their domain. Most
“transformation” claims turn out to be:</p>
<ul>
<li><strong>automation</strong> of tasks already in the upper-right quadrant (where the tool
genuinely speeds you up on familiar tasks, and/or can be used to write a
script to fully automate a task)</li>
<li><strong>magnification</strong> of existing patterns (making fast workers slightly faster,
inefficient workers slightly more inefficient)</li>
<li><strong>wishful thinking</strong> about tasks currently in the lower quadrants,
particularly by folks selling AI tools</li>
</ul>
<p>Real transformation would mean moving tasks between zones in systematic ways.
That might happen---models improve, prompting strategies evolve---but it’s an
empirical question, not a foregone conclusion.</p>
<p>And let’s be honest about the neutral zone. A lot of supposed “AI-assisted” work
actually lives here---using the tool because it’s there, because everyone else
is, because it feels like you should, even when it’s not actually saving time.</p>
<h2 id="what-to-do-with-this">What to do with this</h2>
<p>For users: instead of asking “should I use ChatGPT?”, ask “for which specific
tasks does it actually save me time after sufficient practice?” This encourages
experimentation while validating informed rejection.</p>
<p>Different zones need different strategies:</p>
<ul>
<li>upper-right tasks deserve workflow integration and continued refinement to
maximise time savings</li>
<li>middle-right neutral tasks might warrant periodic re-evaluation as models
improve, or just accepting they’re optional time-wise</li>
<li>lower-right time-wasting tasks probably aren’t worth more effort unless models
substantially improve their speed/accuracy trade-offs</li>
<li>upper-left tasks need systematic testing to see if initial time savings hold
up under regular use</li>
<li>lower-left tasks might benefit from one serious attempt with better prompting
before abandoning them</li>
</ul>
<p>For researchers: adopt task-level analysis. Ask participants to identify
specific tasks, plot them in this space, track how positions change over time
(evaluate!). This would reveal patterns currently hidden by aggregation. Given
that
<a href="https://aisel.aisnet.org/ecis2020_rp/200/">individual performance gains from AI systems depend on task-technology fit</a>,
we need frameworks that capture this task-level variation.</p>
<h2 id="caveats">Caveats</h2>
<p>All models are wrong, some are useful. Is this one useful? Maybe… I’m still
thinking it through.</p>
<p>The two dimensions do miss important factors---confidence, cost, and especially
ethics/responsible use questions<sup><a href="#user-content-fn-ethics" id="user-content-fnref-ethics-2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup>. The discrete task framing might
obscure the fluid, exploratory way people actually interact with LLMs. The
familiarity axis collapses several concepts: frequency of use, diversity of use
cases, quality of prompting strategies.</p>
<p>But even a simplified framework beats treating adoption as a binary
technology-level decision. At minimum, it captures the obvious truth that your
relationship with these tools is task-specific, and aggregating across tasks
obscures more than it reveals.</p>
<p>The real test will be whether thinking in these terms helps you make better
decisions about where to invest effort learning these tools. For me, it’s been
clarifying---it legitimises informed rejection (neo-luddism) while encouraging
strategic experimentation, and it helps me recognise when I’m in that neutral
zone where using the tool is more about performance than productivity.</p>
<p>Your mileage may vary.</p>
<!-- styles for the TAM diagram SVG (light/dark mode) -->
<style scoped>
.tam-diagram .zone-green-light { fill: #e8f5e9; opacity: 0.5; }
.tam-diagram .zone-green-dark { fill: #a5d6a7; opacity: 0.7; }
.tam-diagram .text-green { fill: #2e7d32; }
.tam-diagram .text-green-dark { fill: #1b5e20; }
.tam-diagram .zone-orange-light { fill: #fff3e0; opacity: 0.5; }
.tam-diagram .zone-orange-dark { fill: #ffe0b2; opacity: 0.7; }
.tam-diagram .text-orange { fill: #e65100; }
.tam-diagram .zone-red-light { fill: #ffebee; opacity: 0.5; }
.tam-diagram .zone-red-dark { fill: #ef9a9a; opacity: 0.7; }
.tam-diagram .text-red { fill: #c62828; }
.tam-diagram .text-red-dark { fill: #b71c1c; }
.tam-diagram .axis { stroke: #333; }
.tam-diagram .arrowhead { fill: #333; }
.tam-diagram .axis-label { fill: #333; }
.tam-diagram .grid-line { stroke: #999; }

.dark .tam-diagram .zone-green-light { fill: #1b5e20; opacity: 0.4; }
.dark .tam-diagram .zone-green-dark { fill: #2e7d32; opacity: 0.5; }
.dark .tam-diagram .text-green { fill: #a5d6a7; }
.dark .tam-diagram .text-green-dark { fill: #c8e6c9; }
.dark .tam-diagram .zone-orange-light { fill: #e65100; opacity: 0.3; }
.dark .tam-diagram .zone-orange-dark { fill: #e65100; opacity: 0.45; }
.dark .tam-diagram .text-orange { fill: #ffcc80; }
.dark .tam-diagram .zone-red-light { fill: #b71c1c; opacity: 0.35; }
.dark .tam-diagram .zone-red-dark { fill: #c62828; opacity: 0.5; }
.dark .tam-diagram .text-red { fill: #ef9a9a; }
.dark .tam-diagram .text-red-dark { fill: #ffcdd2; }
.dark .tam-diagram .axis { stroke: #ccc; }
.dark .tam-diagram .arrowhead { fill: #ccc; }
.dark .tam-diagram .axis-label { fill: #ccc; }
.dark .tam-diagram .grid-line { stroke: #666; }
</style>
<section data-footnotes="" class="footnotes"><h2 class="sr-only" id="footnote-label">Footnotes</h2>
<ol>
<li id="user-content-fn-branding">
<p>The framework doesn’t have a name, because I’m bad at branding… hmm. <a href="#user-content-fnref-branding" data-footnote-backref="" aria-label="Back to reference 1" class="data-footnote-backref">↩</a></p>
</li>
<li id="user-content-fn-ethics">
<p>The moral/ethical dimension matters enormously---things like
<a href="https://gizmodo.com/were-doing-ai-phrenology-again-2000553600">digital phrenology</a>/<a href="https://hai.stanford.edu/news/covert-racism-ai-how-language-models-are-reinforcing-outdated-stereotypes">racism</a>
and racism aren’t just “not useful”, they’re harmful. A tool can be both
fast and unethical, or slow and ethical. The framework deliberately focuses
more on the pragmatic “does this save me time?” dimension while
acknowledging that ethics is a separate consideration. If you like,
add a third “is it good for human flourishing” dimension. <a href="#user-content-fnref-ethics" data-footnote-backref="" aria-label="Back to reference 2" class="data-footnote-backref">↩</a> <a href="#user-content-fnref-ethics-2" data-footnote-backref="" aria-label="Back to reference 2-2" class="data-footnote-backref">↩<sup>2</sup></a></p>
</li>
</ol>
</section></line></line></line>  <details class="cite-post" data-astro-cid-srla3z7m> <summary data-astro-cid-srla3z7m>Cite this post</summary> <div class="cite-content" data-astro-cid-srla3z7m> <pre data-astro-cid-srla3z7m><code data-astro-cid-srla3z7m>@online{swift2025seeingAiTasksThroughATamLens,
  author = {Ben Swift},
  title = {Seeing AI tasks through a TAM lens},
  url = {https://benswift.me/blog/2025/11/12/seeing-ai-tasks-through-a-tam-lens/},
  year = {2025},
  month = {11},
  note = {AT-URI: at://did:plc:tevykrhi4kibtsipzci76d76/site.standard.document/2025-11-12-seeing-ai-tasks-through-a-tam-lens},
}</code></pre> <button class="cite-copy" data-bibtex="@online{swift2025seeingAiTasksThroughATamLens,
  author = {Ben Swift},
  title = {Seeing AI tasks through a TAM lens},
  url = {https://benswift.me/blog/2025/11/12/seeing-ai-tasks-through-a-tam-lens/},
  year = {2025},
  month = {11},
  note = {AT-URI: at://did:plc:tevykrhi4kibtsipzci76d76/site.standard.document/2025-11-12-seeing-ai-tasks-through-a-tam-lens},
}" data-astro-cid-srla3z7m>Copy BibTeX</button> </div> </details>  <script type="module">function i(){document.querySelectorAll(".cite-copy").forEach(t=>{t.addEventListener("click",async()=>{const e=t.dataset.bibtex;e&&(await navigator.clipboard.writeText(e),t.textContent="Copied",setTimeout(()=>t.textContent="Copy BibTeX",2e3))})})}i();document.addEventListener("astro:page-load",i);</script> <footer class="site-footer" data-pagefind-ignore data-astro-cid-gcn2mc3v> <p data-astro-cid-gcn2mc3v>
designed &amp; built with
<a href="https://astro.build" title="Astro website" data-astro-cid-gcn2mc3v>&#9889;</a>,
<a href="#" class="random-cafe" title="See Ben's favourite coffee shops" data-astro-cid-gcn2mc3v>&#9749;</a>
and
<a href="https://www.youtube.com/watch?v=6H2FRxvsd2M" title="What is love?" data-astro-cid-gcn2mc3v>&#10084;</a>
on unceded
<a href="https://www.nca.gov.au/welcome-ngunnawal-country" data-astro-cid-gcn2mc3v>Ngunnawal Country</a>
by Ben Swift
</p> <p class="footer-links" data-astro-cid-gcn2mc3v> <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/" class="licence" aria-label="Creative Commons Attribution-ShareAlike 4.0 licence" data-astro-cid-gcn2mc3v>cc by-sa</a>
&middot;
<a href="https://github.com/benswift/benswift.github.io/blob/main/blog/2025/11/12/seeing-ai-tasks-through-a-tam-lens" data-astro-cid-gcn2mc3v>source</a>
&middot;
<a href="https://github.com/benswift/benswift.github.io/commits/main/blog/2025/11/12/seeing-ai-tasks-through-a-tam-lens" data-astro-cid-gcn2mc3v>history</a> </p> </footer>  <script type="module">const e=["https://tilleys.com.au","https://www.harvestcoffee.com.au","https://www.facebook.com/goodbrothercbr","https://frontgallerycafe.com","https://redbrick.coffee"];function t(){document.querySelectorAll(".random-cafe").forEach(o=>{o.addEventListener("click",a=>{a.preventDefault(),window.location.href=e[Math.floor(Math.random()*e.length)]})})}t();document.addEventListener("astro:page-load",t);</script>  </main> </body></html>