---
title: "DeepSeek and Shallow Moats: Implications for Higher Education"
---

> This piece originally published in Times Higher Education

<!-- DeepSeek's arrival may have spooked the markets, but what does it
mean for the research and development of LLMs? Higher education should avoid
putting all its eggs in one GenAI basket, writes Ben Swift -->

The higher education sector has form for betting on technological moats that
turned out to be mirages. In the early 2010s we rushed to build MOOC platforms,
convinced we'd need our own infrastructure to survive in the digital age. A
decade later, most of those courses---and the custom platforms we built to host
them---have been abandoned. As AI reshapes education, we risk repeating this
costly mistake.

[DeepSeek R1](https://github.com/deepseek-ai/DeepSeek-R1) recently made a
splash---you may have heard of it (or even
[downloaded it](https://techcrunch.com/2025/01/27/deepseek-displaces-chatgpt-as-the-app-stores-top-app/)).
It's technically impressive,
[meeting or beating similar models from OpenAI on many benchmarks](https://arxiv.org/pdf/2501.12948),
and it's also ["open weight"](https://epoch.ai/blog/open-models-report), so
anyone can download and run the model if they have the hardware to run it.

DeepSeek didn't even just release one model---they released
[a few different models](https://arcprize.org/blog/r1-zero-r1-results-analysis)
(each with slightly different tradeoffs). They also describe in their research
paper how they trained them all for a significantly lower cost, in terms of time
and money, than their competitors. The research community needs more time to
evalutate these claims, but it does seem like this could be at least a small
breakthrough in reducing the amount of resources it takes to train a new LLM.

The market certainly seemed to think so: Nvidia's shares lost nearly \$US600bn
in one day, based on fears that customers wouldn't need to buy as many of their
AI accelerator chips to train their models. Although even that story's
complicated---DeepSeek is a "reasoning" model, which trades off less time and
resources for training with more time and resources for inference (i.e.Â running
the model to generate text).

Still, DeepSeek's technical achievements are impressive, but the deeper story is
what it tells us about the state of LLM research and development. The argument
of the
[leaked 2023 Google memo](https://semianalysis.com/2023/05/04/google-we-have-no-moat-and-neither/)
asserting "we have no moat, and neither does OpenAI" seems to be holding up.
Despite trillions of dollars of investment, it really does still seem like an
upstart can come out of nowhere to release---and share!---something that's
competitive with state of the art offerings from the tech giants. This poses a
strategic question for higher education leaders: how should institutions
position themselves in response?

Some universities have already placed significant bets, signing exclusive
partnerships with major AI companies. The California State University system's
deal with OpenAI will
[provide ChatGPT access to 500,000 students and faculty](https://openai.com/index/openai-and-the-csu-system/).
UNSW Sydney has
[inked a similar agreement (albeit on a smaller scale)](https://www.unsw.edu.au/newsroom/news/2024/12/UNSW-Sydney-signs-landmark-agreement-with-OpenAI).
These moves reflect an understandable desire to get ahead of the curve, but they
may also lock institutions into particular tools and ecosystems at a time where
new, and perhaps better, alternatives are emerging. The higher education sector
is
[facing huge financial challenges](https://universitiesaustralia.edu.au/wp-content/uploads/2024/11/UA091-Critical-challenges-in-Australias-university-sector_v2.pdf),
and these contracts take precious resources away from faculty salaries or tutor
budgets or any of the other functions of the institution.

The emergence of models like DeepSeek R1 is a timely reminder that things in AI are still moving fast. Rather than pursuing exclusive relationships
with specific providers, institutions might better serve their communities by
staying provider-agnostic (where they engage at all). This approach acknowledges
both the rapid pace of technical change and the likelihood that tomorrow's
leading models may come from unexpected sources.

For individual educators, DeepSeek's release reinforces what many of us have
already realised: the specific model matters less than how we integrate AI
capabilities into our pedagogical practice. Whether students use GPT-4, Claude
or DeepSeek (and let's face it, they _will_) the fundamental challenges remain
the same. How do we design assessments that meaningfully evaluate learning in an
AI-augmented world? How do we help students develop the critical thinking skills
to effectively collaborate with AI tools?

For university administrators and planners, these developments suggest a few key
principles:

1. avoid long-term exclusive commitments to specific AI platforms or providers
2. invest in developing institutional AI literacy and governance frameworks
3. focus on building adaptable infrastructure that can accommodate multiple AI
   tools

The may be other upsides to these developments. As model training and deployment
costs decrease, universities may find it increasingly feasible to develop
specialised models for specific academic domains or research applications. Such
projects could focus on specific institutional needs rather than attempting to
compete with general-purpose models.

What DeepSeek R1 really shows is that in the AI era, competitive
advantage will come not from controlling access to certain models, but from
skillfully integrating AI capabilities into our core educational mission.
Universities that build their strategies around particular AI platforms risk
finding themselves trapped in technological dead ends, while those that focus on
developing institutional AI literacy and adaptable frameworks will be better
positioned to embrace whatever technological developments emerge.

The real moat in higher education isn't technological; it never has been. It's
the ability to teach well and generate new knowledge. Technology is merely a tool---in reality, a _system_ of tools, people
and other resources---in service of these fundamental goals. The winners won't
be those who bet early on the right AI platform, but those who most effectively
help their communities master the art of learning and creating in an
AI-augmented world.
