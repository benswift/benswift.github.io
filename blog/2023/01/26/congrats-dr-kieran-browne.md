---
title: "Congrats Dr. Kieran Browne"
tags:
  - research
  - ai
---

# Congrats Dr. Kieran Browne




Last December [Kieran](https://kieranbrowne.com) graduated---very exciting for
all concerned.

<Picture file="images/posts/ben-kieran-phd-graduation.jpg" alt="Ben and Kieran in full academic dress at the ANU graduation ceremony in December 2022" />

His thesis, _Neurological Metaphor in Deep Learning: Issues and Alternatives_,
is [available online through the ANU
Library](https://openresearch-repository.anu.edu.au/handle/1885/274243). It's a
really interesting mix of insightful scholarship and practice-based design
interventions. In other words, he has interesting things to say _and_ he built
interesting things (some of which are available online).

Here's the abstract:

> Representations of deep learning---discursive, historical and
> diagrammatic---are structured by a neurological metaphor that overstates a
> likeness to the brain and disguises other ways of understanding the
> technology. These neurological representations muddle the crucial public
> debate even as deep learning is applied in high-stakes applications,
> particularly in institutions of social and political power. This thesis draws
> on historical sources and contemporary literature to trace the development and
> contemporary expression of the neurological metaphor in deep learning
> discourse; particularly with respect to the field's terminology, the telling
> of its history, and the drawing of its diagrams. In the manuscript and in
> three documented practice-based works, I propose alternative metaphors for
> deep learning---divination, surveillance and memory---to highlight
> sociotechnical concerns posed by the technology. As a highly interdisciplinary
> project, this thesis applies a range of methods drawn variously from digital
> humanities, discourse analysis, human-centred computing, visual arts and
> design, and deep learning itself. The traditional scholarship and
> practice-based aspects of the thesis are situated in contemporary debates of
> AI bias and interpretability, and the role of deep learning in systems of
> power.
