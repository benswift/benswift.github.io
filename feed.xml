<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://benswift.me/feed.xml" rel="self" type="application/atom+xml" /><link href="https://benswift.me/" rel="alternate" type="text/html" /><updated>2024-11-07T11:06:56+11:00</updated><id>https://benswift.me/feed.xml</id><title type="html">benswift.me</title><subtitle>livecoder &amp; researcher homepage - code, creativity, culture</subtitle><author><name>Ben Swift</name></author><entry><title type="html">LLM Parlour Games for Overeducated Wankers</title><link href="https://benswift.me/blog/2024/11/07/llm-parlour-games-for-overeducated-wankers/" rel="alternate" type="text/html" title="LLM Parlour Games for Overeducated Wankers" /><published>2024-11-07T00:00:00+11:00</published><updated>2024-11-07T00:00:00+11:00</updated><id>https://benswift.me/blog/2024/11/07/llm-parlour-games-for-overeducated-wankers</id><content type="html" xml:base="https://benswift.me/blog/2024/11/07/llm-parlour-games-for-overeducated-wankers/"><![CDATA[<p><em>Note: this stuff is the workshop content for an alumni workshop in November
2024 at the ANU School of Cybernetics.</em></p>

<section class="center">
<script src="/assets/js/qrcode.min.js"></script>
<div id="qrcode-https-benswift-me-blog-2024-11-07-llm-parlour-games-for-overeducated-wankers" class="qrcode"></div><p style="text-align: center;"><a href="https://benswift.me/blog/2024/11/07/llm-parlour-games-for-overeducated-wankers/">https://benswift.me/blog/2024/11/07/llm-parlour-games-for-overeducated-wankers/</a></p><script>
 let qrSize = Math.min(window.innerWidth, window.innerHeight) * 0.5;
 let qrDiv = document.getElementById("qrcode-https-benswift-me-blog-2024-11-07-llm-parlour-games-for-overeducated-wankers");
 new QRCode(qrDiv,
            {text: "https://benswift.me/blog/2024/11/07/llm-parlour-games-for-overeducated-wankers/",
             width: qrSize,
             height: qrSize,
             colorDark : "#333",
             colorLight : "#fafafa",
             correctLevel : QRCode.CorrectLevel.H});
 // hacky page centering
 qrDiv.getElementsByTagName("img")[0].style.margin = "0 auto";
</script>
</section>

<h2 id="abstract">Abstract</h2>

<p>In this interactive design session participants will design and prototype their
own language-model-based parlour game. We’ll think critically about what
language models are (and aren’t) and what they’re good for (and rubbish at).
You’ll interact with other humans and design systems with goals and guardrails,
and think about what it means to give input to (and understand output from) LLMs
and genAI systems.</p>

<p>Prerequisites: ability to lounge around and use big words to impress your
friends in games of no stakes whatsoever. Self-satisfied smugness about said
loquaciousness is helpful but not essential.</p>

<h2 id="tech-note">Tech note</h2>

<p>This workshop requires access to a chat-based LLM (e.g. ChatGPT). If you’ve got
a laptop (or even a phone, although you’ll be typing on your janky little phone
keyboard) you can head to <a href="https://chatgpt.com">https://chatgpt.com</a> (no sign-up required). But if
you’ve got a different favourite chat-based LLM, feel free to use that instead.</p>

<h2 id="outline">Outline</h2>

<ul>
  <li>intro</li>
  <li>play 20 questions
    <ul>
      <li>shareback</li>
    </ul>
  </li>
  <li>adventures in amphibology
    <ul>
      <li>shareback</li>
    </ul>
  </li>
  <li>design your own LLM parlour game
    <ul>
      <li>shareback</li>
    </ul>
  </li>
</ul>

<h2 id="thesis-statement">Thesis statement</h2>

<blockquote>
  <p>the killer app for genAI is parlour games for overeducated wankers</p>
</blockquote>

<p>(this is a demographic I know well, because I am one)</p>

<p>To break it down:</p>

<ul>
  <li>
    <p><strong>parlour</strong>: involving co-located humans. Bored. Night outside, drinks and a
warm fire inside… and so</p>
  </li>
  <li>
    <p><strong>games</strong>: to entertain ourselves and each other</p>
  </li>
</ul>

<p>…for…</p>

<ul>
  <li>
    <p><strong>overeducated</strong>: word games, word play, we are masters of language and we
love to show off</p>
  </li>
  <li>
    <p><strong>wankers</strong>: (literally) self-indulgent. Not about a bigger goal, or doing
good in the world, it’s just for the heck of it.</p>
  </li>
</ul>

<h2 id="mechanics-of-a-parlour-game">Mechanics of a parlour game</h2>

<pre><code class="language-text">10 someone says something
20 someone(s) says something in response
30 GOTO 20
</code></pre>

<p>As an example, consider the game of
<a href="https://en.wikipedia.org/wiki/Twenty_questions">Twenty Questions</a>.</p>

<p><em>Ben scrawls on the whiteboard for 5mins</em></p>

<h2 id="play-llm-augmented-20-questions">Play: <em>LLM-augmented 20 Questions</em></h2>

<p>Here are the prompts (you can copy-paste them automatically with the widget at
the top right of the text).</p>

<pre><code class="language-markdown">I'm thinking of an object. Ask me a yes/no question about the object and I'll
give you an answer.
</code></pre>

<pre><code class="language-markdown">If the object in question is
$OBJECT, what is the answer to the yes/no question "$QUESTION?"
</code></pre>

<h3 id="shareback">Shareback</h3>

<ul>
  <li>what’s the funnest/funniest moment, and why?</li>
  <li>what parts sucked?</li>
  <li>how did your play/strategy/behaivour change over time?</li>
  <li>did you tweak the game rules at all? if so, how?</li>
</ul>

<h2 id="play-adventures-in-amphibology">Play: <em>Adventures in Amphibology</em></h2>

<p>Every player thinks of a word or (short) phrase, writes it down on a piece of
paper and puts it in a hat.</p>

<p>These words/phrases are all fed into an LLM using the following prompt template:</p>

<pre><code class="language-text">You are an expert in the use of language, and you have been given the following words/phrases:

- &lt;phrase one&gt;
- &lt;phrase two&gt;
- &lt;phrase three&gt;
- etc.

Which of these words/phrases is the most ambiguous, and why?
</code></pre>

<p>The player who wrote the thing that the LLM chooses scores 1 point. But they’re
not the winner just yet.</p>

<p>Using the same words/phrases (i.e. without starting a new ChatGPT session) ask
the LLM to pick again, based on successively different criteria:</p>

<pre><code class="language-markdown">Which of these words/phrases best describes your perfect date?</code></pre>

<pre><code class="language-markdown">Which of these words/phrases is the purplest?</code></pre>

<pre><code class="language-markdown">Which of these words/phrases most evokes the experience of a crisp winter sunrise in Canberra?</code></pre>

<pre><code class="language-markdown">Which of these words/phrases would be the best title for a sci-fi movie?</code></pre>

<pre><code class="language-markdown">Which of these words/phrases is the most nihilistic?</code></pre>

<pre><code class="language-markdown">Which of these words/phrases has the most assonance?</code></pre>

<pre><code class="language-markdown">Which of these words/phrases is the most disrespectful?</code></pre>

<pre><code class="language-markdown">Which of these words/phrases would be the best name for a pet cat?</code></pre>

<pre><code class="language-markdown">Which of these words/phrases sounds most like a boy band track from the 90s?</code></pre>

<pre><code class="language-markdown">Which of these words/phrases would be the easiest to explain to a toddler?</code></pre>

<pre><code class="language-markdown">Which of these words/phrases would be the best password for a secret underground antifascist network?</code></pre>

<p>At the end, the player with the most points wins. You can play as many times as
you like, with new words/phrases and/or new “judging” criteria.</p>

<h3 id="shareback-1">Shareback</h3>

<ul>
  <li>what’s the funnest/funniest moment, and why?</li>
  <li>what parts sucked?</li>
  <li>how did your play/strategy/behaivour change over time?</li>
  <li>did you tweak the game rules at all? if so, how?</li>
</ul>

<h2 id="play-design-your-own-llm-parlour-game">Play: design your own LLM parlour game</h2>

<p>Write/draw it up in such a way that a different group (in this workshop) could
play it without you being there to help them out.</p>

<h3 id="shareback-and-remember">Shareback, and remember</h3>

<p>There’s no higher purpose here. It’s all just parlour games for overeducated
wankers.</p>]]></content><author><name>Ben Swift</name></author><category term="teaching" /><category term="ai" /><summary type="html"><![CDATA[Note: this stuff is the workshop content for an alumni workshop in November 2024 at the ANU School of Cybernetics.]]></summary></entry><entry><title type="html">Format Markdown on save in Zed using Prettier</title><link href="https://benswift.me/blog/2024/09/20/format-markdown-on-save-in-zed-using-prettier/" rel="alternate" type="text/html" title="Format Markdown on save in Zed using Prettier" /><published>2024-09-20T00:00:00+10:00</published><updated>2024-09-20T00:00:00+10:00</updated><id>https://benswift.me/blog/2024/09/20/format-markdown-on-save-in-zed-using-prettier</id><content type="html" xml:base="https://benswift.me/blog/2024/09/20/format-markdown-on-save-in-zed-using-prettier/"><![CDATA[<p>One thing I’ve particularly enjoyed since switching to Zed is format-on-save,
which is turned on by default in most programming modes. However, it’s not
turned on by default for Markdown files.</p>

<p>Since I like my Markdown files formatted with <a href="https://prettier.io">Prettier</a>,
including the “wrap to 80 cols” <code>--prose-wrap always</code> option, I set that command
as an “external” formatter for Markdown files and turned on <code>format_on_save</code>.
Here’s the config if you want to do the same:</p>

<pre><code class="language-json">"languages": {
    "Markdown": {
      "format_on_save": "on",
      "formatter": {
        "external": {
          "command": "prettier",
          "arguments": [
            "--prose-wrap",
            "always",
            "--stdin-filepath",
            "{buffer_path}"
          ]
        }
      }
    }
  }
</code></pre>]]></content><author><name>Ben Swift</name></author><category term="tools" /><category term="zed" /><summary type="html"><![CDATA[One thing I’ve particularly enjoyed since switching to Zed is format-on-save, which is turned on by default in most programming modes. However, it’s not turned on by default for Markdown files.]]></summary></entry><entry><title type="html">Hosting a genAI trivia night</title><link href="https://benswift.me/blog/2024/08/12/hosting-a-genai-trivia-night/" rel="alternate" type="text/html" title="Hosting a genAI trivia night" /><published>2024-08-12T00:00:00+10:00</published><updated>2024-08-12T00:00:00+10:00</updated><id>https://benswift.me/blog/2024/08/12/hosting-a-genai-trivia-night</id><content type="html" xml:base="https://benswift.me/blog/2024/08/12/hosting-a-genai-trivia-night/"><![CDATA[<p>I was recently tasked with organising a trivia night, and decided to generate
all the questions (and answers) with a large language model (I used
<a href="https://claude.ai/">Claude</a>, although obviously this would work with any model.</p>

<p>Here’s the initial prompt I used:</p>

<blockquote>
  <p>Write a set of questions (10 rounds, 5 questions per round) for a trivia
night, including answers. Each round must have a different theme, including
rounds on the topics of “<em>insert list of rounds here</em>”. You must provide
questions which have a single, unambiguous correct answer. Include a mix of
easy and difficult questions, such that a graduate-level audience would get
approximately 50% of the answers correct.</p>
</blockquote>

<p>Looking over the answers, they looked a little too easy, so I provided a
follow-up:</p>

<blockquote>
  <p>Those questions are all too easy. Try again, and dial up the difficulty.</p>
</blockquote>

<p>which gave questions which looked (to my eyes) to be around the right level.</p>

<p>Now, LLMs are notorious for hallucinating/making up facts, and I couldn’t be
bothered to check that all the answers were correct. So I incorporated this “is
the LLM making stuff up?” dynamic into the rules. As well as the usual trivia
night procedure:</p>

<ul>
  <li>1 pt per question</li>
  <li>each question will be read <strong>twice</strong> (no more than that)</li>
  <li>we’ll give answers and tally scores after each round</li>
  <li>no cheating (internet <em>or</em> AI models, inc. self-hosted ones)</li>
</ul>

<p>there was an additional rule: at the end of each round, each team can challenge
any answer(s) they think the LLM got wrong. For each challenge, the trivia hosts
would investigate (using the internet, or whatever) to see what the correct
answer is.</p>

<ul>
  <li>if the LLM’s answer was wrong, <em>all teams</em> have that question re-marked with
the correct answer</li>
  <li>if the LLM’s answer was ambiguous (i.e. it was correct, but there are other
answers that were equally correct) then <em>all teams</em> have that question
re-marked, accepting any of the correct answers</li>
  <li>if the LLM’s answer was correct (or if we can’t find a reliable answer in an
appropriate timeframe) then the question is not re-marked, and the challenging
team receives an additional one-point penalty</li>
</ul>

<p>As for whether the LLM was correct/ambiguous/wrong, all decisions by the trivia
hosts were final.</p>

<p>And how’d it go? Pretty well, overall. In the end the questions were a bit too
tricky. Turns out it’s really hard to eyeball questions <em>with</em> answers to guess
how many you’d get correct, so if you’re going to do that make sure you do it
without looking at the answers.</p>

<p>There was one successful challenge on the night, but overall there didn’t seem
to be too many hallucinations. In some ways it would have been more fun if there
were.</p>

<p>Anyway if you need to organise a trivia night and don’t want to do any
painstaking research, then give the above prompts a try.</p>]]></content><author><name>Ben Swift</name></author><category term="ai" /><summary type="html"><![CDATA[I was recently tasked with organising a trivia night, and decided to generate all the questions (and answers) with a large language model (I used Claude, although obviously this would work with any model.]]></summary></entry><entry><title type="html">Livecoding set ICLC’24 - Shanghai Concert Hall</title><link href="https://benswift.me/blog/2024/05/30/livecoding-set-iclc-24-shanghai-concert-hall/" rel="alternate" type="text/html" title="Livecoding set ICLC’24 - Shanghai Concert Hall" /><published>2024-05-30T00:00:00+10:00</published><updated>2024-05-30T00:00:00+10:00</updated><id>https://benswift.me/blog/2024/05/30/livecoding-set-iclc-24-shanghai-concert-hall</id><content type="html" xml:base="https://benswift.me/blog/2024/05/30/livecoding-set-iclc-24-shanghai-concert-hall/"><![CDATA[<p>I’m currently in Shanghai tomorrow night I’ll be performing at the <a href="https://www.shanghaiconcerthall.org/">Shanghai Concert Hall</a> as part of <a href="https://iclc.toplap.org/2024/program.html#table-day2">ICLC ‘24</a>. I’m told tickets are already sold out, but if you’ve already got one and you’re coming along then come say hi after the set.</p>

<p>I’ll try and put up a video of the performance (I’ll be doing music, with LXT
and Beverly Edwards on visuals) once it’s all done.</p>]]></content><author><name>Ben Swift</name></author><summary type="html"><![CDATA[I’m currently in Shanghai tomorrow night I’ll be performing at the Shanghai Concert Hall as part of ICLC ‘24. I’m told tickets are already sold out, but if you’ve already got one and you’re coming along then come say hi after the set.]]></summary></entry><entry><title type="html">Parental leave take 3</title><link href="https://benswift.me/blog/2023/05/13/parental-leave-take-3/" rel="alternate" type="text/html" title="Parental leave take 3" /><published>2023-05-13T00:00:00+10:00</published><updated>2023-05-13T00:00:00+10:00</updated><id>https://benswift.me/blog/2023/05/13/parental-leave-take-3</id><content type="html" xml:base="https://benswift.me/blog/2023/05/13/parental-leave-take-3/"><![CDATA[<p>Apologies for the radio silence over the last couple of months. I have the happy
opportunity to take one more round of parental leave. So I’ll be off doing Dad
stuff until March ‘24.</p>]]></content><author><name>Ben Swift</name></author><summary type="html"><![CDATA[Apologies for the radio silence over the last couple of months. I have the happy opportunity to take one more round of parental leave. So I’ll be off doing Dad stuff until March ‘24.]]></summary></entry><entry><title type="html">Writing graph theory proofs with ChatGPT</title><link href="https://benswift.me/blog/2023/02/08/writing-graph-theory-proofs-with-chatgpt/" rel="alternate" type="text/html" title="Writing graph theory proofs with ChatGPT" /><published>2023-02-08T00:00:00+11:00</published><updated>2023-02-08T00:00:00+11:00</updated><id>https://benswift.me/blog/2023/02/08/writing-graph-theory-proofs-with-chatgpt</id><content type="html" xml:base="https://benswift.me/blog/2023/02/08/writing-graph-theory-proofs-with-chatgpt/"><![CDATA[<p>Posting logs of <a href="https://chat.openai.com">ChatGPT</a> interaction is getting a bit
passé by now in Feb ‘23, so I’ll stop doing it soon (I promise). But yesterday I
was hanging out with my father-in-law and showing how it might impact his
classes—he’s Associate Chair of the Mathematics Department at a top uni in
China.</p>

<p>The prompts were his (with a bit of light suggesting from me), responses from
ChatGPT.</p>

<p><strong>Write a proof of of Pythagoras’s theorem.</strong></p>

<p>Pythagoras’s theorem states that in a right triangle, the square of the length
of the hypotenuse (the side opposite the right angle) is equal to the sum of the
squares of the lengths of the other two sides. Symbolically, this can be written
as:</p>

<p>c^2 = a^2 + b^2</p>

<p>where c is the length of the hypotenuse, and a and b are the lengths of the
other two sides.</p>

<p>Proof:</p>

<p>Draw a right triangle ABC with sides AB (a), BC (b), and AC (c).</p>

<p>Draw squares with sides AB, BC, and AC on each side of the triangle, as shown
below:</p>

<p>[Diagram of a right triangle with squares on each side]</p>

<p>The area of each of the squares is equal to the square of the length of its
side. Hence:</p>

<p>a^2 = AB x AB = area of square with side AB</p>

<p>b^2 = BC x BC = area of square with side BC</p>

<p>c^2 = AC x AC = area of square with side AC</p>

<p>Consider the combined area of the squares on the two smaller sides (a and b). It
can also be obtained by covering the entire triangle with a larger square and
then subtracting the area of the square on the hypotenuse (c). Hence:</p>

<p>a^2 + b^2 = (AB + BC) x (AB + BC) - AC x AC</p>

<p>On the right-hand side of the equation, (AB + BC) is equal to the length of the
hypotenuse (c**, since it is the longest side in a right triangle. Hence:</p>

<p>a^2 + b^2 = c x c - c x c</p>

<p>Simplifying the right-hand side of the equation, we obtain:</p>

<p>a^2 + b^2 = c x c</p>

<p>Hence, we have proved that:</p>

<p>c^2 = a^2 + b^2</p>

<p>This is Pythagoras’s theorem.</p>

<p><strong>Ok, that’s great. Now it’s time for some graph theory. Can you give me a proof
of the 5-color theorem?</strong></p>

<p>The five color theorem states that any planar graph (a graph that can be drawn
on a plane without any of its edges crossing) can be colored with no more than
five colors, such that no two adjacent vertices (vertices connected by an edge)
have the same color.</p>

<p>Proof:</p>

<p>Consider a planar graph G with a minimum number of vertices, and suppose that it
cannot be colored with fewer than five colors.</p>

<p>Since G has a minimum number of vertices, there must be a vertex v in G with the
smallest degree (the number of edges incident to v). Let d be the degree of v.</p>

<p>Since G cannot be colored with fewer than five colors, d must be greater than or
equal to 4.</p>

<p>Consider the set of vertices adjacent to v, and let S be the set of colors that
have been used to color these vertices.</p>

<p>Since the degree of v is greater than or equal to 4, the number of colors in S
is greater than or equal to 4.</p>

<p>Suppose, S contains all five colors. Then, since each color can be assigned to
at most one of the vertices adjacent to v, we have a contradiction, as there are
more vertices than colors.</p>

<p>Hence, there must be a color not in S. Call this color c.</p>

<p>Color vertex v with color c. Since no two adjacent vertices have the same color,
it follows that G can be colored with no more than five colors.</p>

<p>This proves the five color theorem: any planar graph can be colored with no more
than five colors, such that no two adjacent vertices have the same color.</p>

<p><strong>Ok, can you prove the 4-color theorem as well?</strong></p>

<p>The four color theorem states that any planar graph can be colored with no more
than four colors, such that no two adjacent vertices have the same color.</p>

<p>Proof:</p>

<p>Consider a planar graph G and let H be a subgraph of G.</p>

<p>We proceed by induction on the number of vertices of H. If H has only one
vertex, it can be colored with a single color.</p>

<p>Suppose that the statement is true for all subgraphs of G with at most n - 1
vertices, where n is a positive integer.</p>

<p>Let H be a subgraph of G with n vertices, and let v be a vertex in H with the
minimum degree.</p>

<p>By the induction hypothesis, all subgraphs of H with fewer than n vertices can
be colored with at most four colors.</p>

<p>Consider the set of vertices adjacent to v in H, and let S be the set of colors
used to color these vertices.</p>

<p>If |S| &lt; 4, then we can color vertex v with a color not in S, and H can be
colored with at most four colors.</p>

<p>Otherwise, |S| = 4. We can color v with any color not in S, and since all
subgraphs of H with fewer than n vertices can be colored with at most four
colors, it follows that H can be colored with at most four colors.</p>

<p>Hence, the statement is true for all subgraphs of G with at most n vertices.</p>

<p>Since the statement is true for all positive integers n, it follows that any
planar graph can be colored with no more than four colors, such that no two
adjacent vertices have the same color.</p>

<p>This proves the four color theorem: any planar graph can be colored with no more
than four colors, such that no two adjacent vertices have the same color.</p>

<h2 id="his-response">His response?</h2>

<p>Shock, really. The proof of the <a href="https://en.wikipedia.org/wiki/Five_color_theorem">five colour
theorem</a> is an assignment he
might set in one of his early-year undergraduate classes, and the proof given
certainly looks ok. It might well be wrong (he didn’t look at it in detail) but
it’s the sort of thing a harried marker would assume was written by a student
who had some idea of what was going on in class. The <a href="https://en.wikipedia.org/wiki/Four_color_theorem">four colour
theorem</a> is a much trickier
proof—it was an unsolved research problem until 2005. The proof for that one
is almost certainly wrong, but that would only be obvious to someone with
considerable expertise in the domain (graph theory). Such is the way of LLMs.</p>

<p>What does it all mean? I dunno. It’s gonna be a wild decade.</p>]]></content><author><name>Ben Swift</name></author><category term="ai" /><category term="teaching" /><summary type="html"><![CDATA[Posting logs of ChatGPT interaction is getting a bit passé by now in Feb ‘23, so I’ll stop doing it soon (I promise). But yesterday I was hanging out with my father-in-law and showing how it might impact his classes—he’s Associate Chair of the Mathematics Department at a top uni in China.]]></summary></entry><entry><title type="html">Academic integrity guidelines re: ChatGPT and generative AI tools</title><link href="https://benswift.me/blog/2023/02/02/academic-integrity-policy-re-chatgpt-and-generative-ai-tools/" rel="alternate" type="text/html" title="Academic integrity guidelines re: ChatGPT and generative AI tools" /><published>2023-02-02T00:00:00+11:00</published><updated>2023-02-02T00:00:00+11:00</updated><id>https://benswift.me/blog/2023/02/02/academic-integrity-policy-re-chatgpt-and-generative-ai-tools</id><content type="html" xml:base="https://benswift.me/blog/2023/02/02/academic-integrity-policy-re-chatgpt-and-generative-ai-tools/"><![CDATA[<p>Here in Australia Semester 1 is approaching and
<a href="https://chat.openai.com">ChatGPT</a> is, undoubtedly, <em>a thing</em>. From a practical
perspective it’s important to have some​ sort of guidelines about about ChatGPT
and other generative AI tools in the classroom (<a href="https://twitter.com/dbkahn/status/1616494433587040257">everyone’s doing
it</a>). If you don’t
provide any advice ahead of time you’ll end up making it up as you go along
(because it <em>will</em> come up) and <a href="https://www.youtube.com/watch?v=7XeQin9abx4">policy on the run is policy
underdone</a>.</p>

<p>In terms of the opportunities to incorporate, explore and critique new tools in
the classroom, I’m actually kindof excited. <a href="https://www.timeshighereducation.com/campus/so-you-want-use-chatgpt-classroom-semester">I’ve written elsewhere about how
you might be able to do
this</a>.
The <em>tl;dr</em> is that you should look at your class activities (including
assessment items) and try and actually <em>do</em> them with ChatGPT, just to see how
it goes. OpenAI have also just released some stuff about <a href="https://platform.openai.com/docs/chatgpt-education">considerations for
educators</a>.</p>

<p class="hl-para">At this stage these are just my own personal thoughts as a teaching academic;
I’m not wearing my <a href="https://cybernetics.anu.edu.au/people/ben-swift/">Associate Director
(Education)</a> hat here, and
<strong>this is not an official (or unofficial) ANU School of Cybernetics policy</strong>. If
you’re also putting together some guidelines for your own classroom, then
questions/comments/suggesions are welcome—do <a href="mailto:ben.swift@anu.edu.au">get in
touch</a>.</p>

<p>Here are my current thoughts what some good <em>use of ChatGPT in the classroom</em>
guidelines might look like. It doesn’t have everything precisely defined, but it
gives you an idea of how I want to run my classes, balancing the opportunities
and challenges these tools present for student learning.</p>

<ol>
  <li>
    <p>Unless otherwise specified, you <strong>are</strong> allowed to use
ChatGPT<sup id="fnref:other-similar-tools" role="doc-noteref"><a href="#fn:other-similar-tools" class="footnote" rel="footnote">1</a></sup> in this class, including in work submitted for
assessment.</p>
  </li>
  <li>
    <p>Wherever ChatGPT is used it must be cited according to the <a href="https://platform.openai.com/docs/chatgpt-education/disclosing-the-use-of-chatgpt">OpenAI citation
instructions</a>.<sup id="fnref:attribution" role="doc-noteref"><a href="#fn:attribution" class="footnote" rel="footnote">2</a></sup></p>
  </li>
  <li>
    <p>You are responsible for everything you submit. “It’s not my fault—the AI
generated text introduced non-sequiturs/errors/plagiarised text/offensive
language” will never get you off the hook; if it’s in your submission you’re
responsible for it just as you would be if you’d written it without ChatGPT.</p>
  </li>
  <li>
    <p>You are expected to be able to explain (to your tutor, lecturer or course
convenor) any assessment submission to demonstrate your understanding of the
concepts being assessed.</p>
  </li>
  <li>
    <p>Any violations of the above will be considered a potential breach of academic
integrity under clause 9 of section 12(2) of the <a href="#appendix-anu-academic-integrity-rule">ANU Academic Integrity
Rule</a> “improperly recycles work or
otherwise improperly submits or publishes work that is not original”
(<strong>note</strong>: I’m unsure on which clause is best to use here—could be clause
8, could be one of the others as well).</p>
  </li>
  <li>
    <p>No “is-this-written-by-an-AI?”​ detection tools (e.g.
<a href="https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text/">this</a>)
will be used as part of the marking process.</p>
  </li>
</ol>

<p>One open question (not necessarily part of the student-facing guidelines, but
relevant for anyone running a course) is what guidance should be given to the
markers (e.g. tutors/TAs) on what to do when marking ChatGPT-generated content.
Should submissions created with the help of ChatGPT be marked lower than
“equivalent standard” (whatever that means) submissions that aren’t?</p>

<p>Anyway, these are just some draft thoughts—I’ll keep this post updated as my
thinking changes.</p>

<h2 id="appendix-anu-academic-integrity-rule">Appendix: ANU Academic Integrity Rule</h2>

<p>From the <a href="https://www.legislation.gov.au/Details/F2021L00997/Html/Text#_Toc73961519">ANU Academic Integrity Rule
2021</a>
Section 12 (2), here’s the list of what constitutes a breach of the academic
integrity principle.</p>

<style>
#academic-integrity-definitions ol {list-style-type: lower-alpha;}
#academic-integrity-definitions ol ol {list-style-type: lower-roman;}
</style>

<div id="academic-integrity-definitions">

  <blockquote>
    <p>(2) For this instrument, a student breaches the academic integrity principle if, in scholarly practice, the student:</p>
    <ol>
      <li>cheats; or</li>
      <li>impersonates another person; or</li>
      <li>engages in plagiarism; or</li>
      <li>colludes with another person; or</li>
      <li>improperly shares material with another person; or</li>
      <li>engages in contract cheating or improperly engages another person to prepare, or assist in preparing, work for the student; or</li>
      <li>submits or publishes anything that fails to correctly or appropriately acknowledge the work of another person or otherwise improperly appropriates the intellectual property or contribution of another person; or</li>
      <li>otherwise passes off the work of another person as the student’s own work; or</li>
      <li>improperly recycles work or otherwise improperly submits or publishes work that is not original; or</li>
      <li>takes a prohibited item into an examination or other assessment venue or otherwise breaches the University’s directions (however described) in relation to an examination or other assessment; or</li>
      <li>fabricates or falsifies any document, data or other information, or anything else, including, for example, by intentionally omitting data to obtain a desired result, or by falsely representing observations as genuinely held; or</li>
      <li>otherwise intentionally or recklessly engages in conduct:
        <ol>
          <li>that impedes the progress of research; or</li>
          <li>that risks corrupting research records or compromising the integrity of research practices; or</li>
          <li>that uses research data from another person without appropriate acknowledgement; or</li>
          <li>that breaches a research protocol approved by a research ethics committee or a statutory licence condition applying to research; or</li>
        </ol>
      </li>
      <li>otherwise engages in conduct with the intention of gaining, or assisting another person to gain, an unethical, dishonest, unfair or unjustified advantage; or</li>
      <li>otherwise engages in conduct, or assists another person to engage in conduct, that is unethical, dishonest or unfair; or</li>
      <li>engages in any other conduct declared to be academic misconduct by the orders.</li>
    </ol>
  </blockquote>

  <p>My commentary on the above (and IANAL) is that none of those points really
capture the specific case of “ChatGPT wrote this essay, not the student”, in
particular because so many of the definitions reference “of another <em>person</em>”.
I’m sure this language will be updated in the future in light of the widespread
availability of generative AI tools.</p>
</div>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:other-similar-tools" role="doc-endnote">

      <p>Wherever ChatGPT is named in these guidelines it should be read as “ChatGPT
and other generative AI tools”, where those tools are defined according to
(ERROR: definition not found). Any guidelines which are restrict themselves
to specific AI tools by name are doomed to become out of date real fast. <a href="#fnref:other-similar-tools" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:attribution" role="doc-endnote">

      <p>These guidelines deliberately doesn’t try to address the (important) issue
of AI tools and the way they appropriate the skilled labour of the millions
of individuals who created, edited and labelled the data on which they were
trained. <a href="#fnref:attribution" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Ben Swift</name></author><category term="teaching" /><category term="ai" /><summary type="html"><![CDATA[Here in Australia Semester 1 is approaching and ChatGPT is, undoubtedly, a thing. From a practical perspective it’s important to have some​ sort of guidelines about about ChatGPT and other generative AI tools in the classroom (everyone’s doing it). If you don’t provide any advice ahead of time you’ll end up making it up as you go along (because it will come up) and policy on the run is policy underdone.]]></summary></entry><entry><title type="html">Jekyll build speedups for Ruby 3.2</title><link href="https://benswift.me/blog/2023/02/02/jekyll-build-speedups-for-ruby-3-2/" rel="alternate" type="text/html" title="Jekyll build speedups for Ruby 3.2" /><published>2023-02-02T00:00:00+11:00</published><updated>2023-02-02T00:00:00+11:00</updated><id>https://benswift.me/blog/2023/02/02/jekyll-build-speedups-for-ruby-3-2</id><content type="html" xml:base="https://benswift.me/blog/2023/02/02/jekyll-build-speedups-for-ruby-3-2/"><![CDATA[<p>There’s a <a href="https://news.ycombinator.com/item?id=34413012">bunch of buzz</a> about
Ruby’s new YJIT in v3.2.0. I have to develop and maintain a bunch of Jekyll
websites for work, some of which are getting into “non-trivial build time”
territory (or maybe I’m really easily distracted, but a 30s build is enough for
me to break my flow).</p>

<p>Here’s some very unscientifc benchmarks from my <a href="https://jekyllrb.com">Jekyll</a>
(v4.3) builds on my M1 Max MBP (64GB).</p>

<h2 id="ruby-312p20-2022-04-12-revision-4491bb740a-arm64-darwin21">ruby 3.1.2p20 (2022-04-12 revision 4491bb740a) [arm64-darwin21]</h2>

<p>First, this is the previous version of Ruby, which I’ve been happily working
with for ages.</p>

<pre><code>bundle exec jekyll build
</code></pre>

<p>Averaged over 3 runs, the build time was 17.7 (±0.8) seconds.</p>

<h2 id="ruby-320-2022-12-25-revision-a528908271-arm64-darwin22">ruby 3.2.0 (2022-12-25 revision a528908271) [arm64-darwin22]</h2>

<p>After upgrading to the latest Ruby v3.2.0, the average over 3 runs was 17.2 (±0.2) seconds.</p>

<h2 id="ruby-320-2022-12-25-revision-a528908271-yjit-arm64-darwin22">ruby 3.2.0 (2022-12-25 revision a528908271) +YJIT [arm64-darwin22]</h2>

<p>I <a href="https://dev.to/dpaluy/install-ruby-320-yjit-with-asdf-b82">followed these
instructions</a> to
build a YJIT-enabled Ruby v3.2. Then, after re-installing all the deps:</p>

<pre><code>RUBY_YJIT_ENABLE=true bundle exec jekyll build
</code></pre>

<p>The build was <em>heaps</em> faster—the average over 3 runs was 3.7 (±0.2) seconds.
<strong>That’s a 4.8x speedup</strong>.</p>

<p>Obviously, like all benchmarks on the internet this one is wrong &amp; stupid and
you should do your own testing. Three runs probably isn’t enough to shake out
any cache effects, and I don’t know (but could guess?) that the JIT might have
even more pronounced cold start issues (although I didn’t really see it above).
Anyway, if you build a lot of Jekyll sites, my anecdotal evidence is that you
can save yourself a bunch of time, and tighten those feedback loops to stay in
the flow state. Have fun!</p>]]></content><author><name>Ben Swift</name></author><category term="web" /><category term="tools" /><summary type="html"><![CDATA[There’s a bunch of buzz about Ruby’s new YJIT in v3.2.0. I have to develop and maintain a bunch of Jekyll websites for work, some of which are getting into “non-trivial build time” territory (or maybe I’m really easily distracted, but a 30s build is enough for me to break my flow).]]></summary></entry><entry><title type="html">Congrats Dr. Kieran Browne</title><link href="https://benswift.me/blog/2023/01/26/congrats-dr-kieran-browne/" rel="alternate" type="text/html" title="Congrats Dr. Kieran Browne" /><published>2023-01-26T00:00:00+11:00</published><updated>2023-01-26T00:00:00+11:00</updated><id>https://benswift.me/blog/2023/01/26/congrats-dr-kieran-browne</id><content type="html" xml:base="https://benswift.me/blog/2023/01/26/congrats-dr-kieran-browne/"><![CDATA[<p>Last December <a href="https://kieranbrowne.com">Kieran</a> graduated—very exciting for
all concerned.</p>

<picture style="position: relative;">
  <img alt="Ben and Kieran in full academic dress at the ANU graduation ceremony in December 2022" src="/assets/images/posts/ben-kieran-phd-graduation.jpg" />

  
</picture>

<p>His thesis, <em>Neurological Metaphor in Deep Learning: Issues and Alternatives</em>,
is <a href="https://openresearch-repository.anu.edu.au/handle/1885/274243">available online through the ANU
Library</a>. It’s a
really interesting mix of insightful scholarship and practice-based design
interventions. In other words, he has interesting things to say <em>and</em> he built
interesting things (some of which are available online).</p>

<p>Here’s the abstract:</p>

<blockquote>
  <p>Representations of deep learning—discursive, historical and
diagrammatic—are structured by a neurological metaphor that overstates a
likeness to the brain and disguises other ways of understanding the
technology. These neurological representations muddle the crucial public
debate even as deep learning is applied in high-stakes applications,
particularly in institutions of social and political power. This thesis draws
on historical sources and contemporary literature to trace the development and
contemporary expression of the neurological metaphor in deep learning
discourse; particularly with respect to the field’s terminology, the telling
of its history, and the drawing of its diagrams. In the manuscript and in
three documented practice-based works, I propose alternative metaphors for
deep learning—divination, surveillance and memory—to highlight
sociotechnical concerns posed by the technology. As a highly interdisciplinary
project, this thesis applies a range of methods drawn variously from digital
humanities, discourse analysis, human-centred computing, visual arts and
design, and deep learning itself. The traditional scholarship and
practice-based aspects of the thesis are situated in contemporary debates of
AI bias and interpretability, and the role of deep learning in systems of
power.</p>
</blockquote>]]></content><author><name>Ben Swift</name></author><category term="research" /><category term="ai" /><summary type="html"><![CDATA[Last December Kieran graduated—very exciting for all concerned.]]></summary></entry><entry><title type="html">Handling Square Webhooks in Phoenix</title><link href="https://benswift.me/blog/2023/01/22/handling-square-webhooks-in-phoenix/" rel="alternate" type="text/html" title="Handling Square Webhooks in Phoenix" /><published>2023-01-22T00:00:00+11:00</published><updated>2023-01-22T00:00:00+11:00</updated><id>https://benswift.me/blog/2023/01/22/handling-square-webhooks-in-phoenix</id><content type="html" xml:base="https://benswift.me/blog/2023/01/22/handling-square-webhooks-in-phoenix/"><![CDATA[<p>My <a href="https://the-riotact.com/hot-in-the-suburbs-little-luxton-serves-up-coffee-for-the-community/618459">brother’s
cafe</a>
donates a dollar to the local community centre for every coffee sold, and over
the summer I built
him a live “donation counter” which displays a small “thankyou” animation when
anyone buys a coffee. It’s a web app which they run on an iPad sitting on the
coffee machine.</p>

<p>Since the cafe uses Square for all payments, I was able to set up a
<a href="https://developer.squareup.com/docs/webhooks/overview">webhook</a> so the app
would receive the “new sale” notification ASAP—this should be both
lower-latency and more efficient than polling.</p>

<p>The app is basically a single <a href="https://www.phoenixframework.org">Phoenix
LiveView</a>. Sadly the Square guides don’t have
examples for Elixir, although it’s pretty easy to modify the e.g. <a href="https://developer.squareup.com/docs/webhooks/step3validate">Ruby
example</a> code to get
the job done. If you’re looking to do something similar I cobbled together this
info from docs (and a few blogs) and it might help you out to have it all in one
place.</p>

<h2 id="step-1-set-up-webhook-controller-including-validation">Step 1: set up webhook controller (including validation)</h2>

<p>It’s important to validate that any incoming webhook is actually from Square, so
Square send a special <code>x-square-hmacsha256-signature</code> header for <a href="https://developer.squareup.com/docs/webhooks/step3validate">validation
purposes</a>, although
performing this validation step requires having access to the raw request body.
Thankfully, the <a href="https://hexdocs.pm/plug/Plug.Parsers.html#module-custom-body-reader">“Custom Body Reader” section in the <code>Plug.Parsers</code>
docs</a> shows
how to do exactly that—just follow the instructions there.</p>

<h2 id="step-2-create-webhook-controller-including-validation">Step 2: create webhook controller (including validation)</h2>

<p>The webhook controller module should look something like this (replace the
<code>notification_url</code> and <code>signature_key</code> with the right values for your
app—you’ll get your signature key from Square when you register the webhook):</p>

<pre><code class="language-elixir">defmodule MyAppWeb.SquareWebhookController do
  @moduledoc """
  Handle webhooks sent from Square.
  """
  use MyAppWeb, :controller

  @doc "handle the webhook request"
  def webhook(conn, params) do
    if is_from_square?(conn) do
      do_stuff(params)
    end

    send_response(conn)
  end

  @doc "respond to the Square server (always 200 OK otherwise they'll freak out)"
  defp send_response(conn) do
    conn
    |&gt; put_resp_content_type("text/plain")
    |&gt; send_resp(200, "webhook received - thanks.")
  end

  @doc "returns `true` if webhook came from Square, `false` otherwise"
  defp is_from_square?(conn) do
    notification_url = "http://example.com/square/webhook"
    signature_key = "WEBHOOK_SIGNATURE_KEY_FROM_SQUARE"
    {_, signature} = List.keyfind!(conn.req_headers, "x-square-hmacsha256-signature", 0)

    ## here's where we access the raw request body we put there in the Plug.Parser
    raw_body = Enum.join(conn.assigns.raw_body)

    hash =
      :crypto.mac(:hmac, :sha256, signature_key, notification_url &lt;&gt; raw_body)
      |&gt; Base.encode64()

    signature == hash
  end
end
</code></pre>

<h2 id="step-3-add-the-endpoint-to-your-router">Step 3: add the endpoint to your router</h2>

<p>Finally, add it to to your <code>router.ex</code> - something like this, you know the
drill.</p>

<pre><code class="language-elixir">scope "/square", MyAppWeb do
  pipe_through :api

  post "/webhook", SquareWebhookController, :webhook
end
</code></pre>

<h2 id="step-4-subscribe-to-the-webhook">Step 4: subscribe to the webhook</h2>

<p>After that’s all done (and you’ve deployed your app) you’re ready to <a href="https://developer.squareup.com/docs/webhooks/overview">set up a
webhook subscription</a>.
Follow the Square docs and Square will start hitting your (deployed) app’s
<code>https://example.com/square/webhook</code> endpoint, and your app can do its thing.</p>

<p class="hl-para">Note that these incoming webhook requests <em>won’t</em> hit your local development
server running on <code>localhost</code>, so testing webhooks is a bit trickier. Since my
app runs on <a href="https://fly.io">fly</a> it involved a little bit of <code>IO.inspect</code>ing in
production and then looking at the logs with <code>flyctl logs</code>.</p>

<p>Have fun! And if you live in Canberra, especially in Tuggeranong/Lanyon, maybe
go buy a coffee from <a href="https://www.littleluxton.com">Little Luxton</a> and you can
see it for yourself 😊</p>]]></content><author><name>Ben Swift</name></author><category term="web" /><category term="elixir" /><category term="phoenix" /><summary type="html"><![CDATA[My brother’s cafe donates a dollar to the local community centre for every coffee sold, and over the summer I built him a live “donation counter” which displays a small “thankyou” animation when anyone buys a coffee. It’s a web app which they run on an iPad sitting on the coffee machine.]]></summary></entry></feed>