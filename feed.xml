<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="https://benswift.me/feed.xml" rel="self" type="application/atom+xml" /><link href="https://benswift.me/" rel="alternate" type="text/html" /><updated>2022-10-12T17:26:46+11:00</updated><id>https://benswift.me/feed.xml</id><title type="html">benswift.me</title><subtitle>livecoder &amp; researcher homepage - code, creativity, culture</subtitle><author><name>Ben Swift</name></author><entry><title type="html">NGA Un-tour: The Hidden Gallery</title><link href="https://benswift.me/blog/2022/10/12/nga-un-tour-the-hidden-gallery/" rel="alternate" type="text/html" title="NGA Un-tour: The Hidden Gallery" /><published>2022-10-12T00:00:00+11:00</published><updated>2022-10-12T00:00:00+11:00</updated><id>https://benswift.me/blog/2022/10/12/nga-un-tour-the-hidden-gallery</id><content type="html" xml:base="https://benswift.me/blog/2022/10/12/nga-un-tour-the-hidden-gallery/"><![CDATA[<p>For the last year or so my team has been collaborating with the good folks at
<a href="https://www.bestfestivalever.com.au">BOHO Interactive</a> and the National Gallery
of Australia on something which launches tonight‚Äîthe <em>NGA Un-Tour</em>.</p>

<p>From the <a href="https://nga.gov.au/events/un-tour-the-hidden-gallery/">NGA website</a>:</p>

<blockquote>
  <p>Experience an immersive cybernetic walking tour of the National Gallery after
dark. Travel through familiar and behind-the scenes spaces and investigate the
dynamic relationships between humans, technology and the built environment
found within works of art and the Gallery itself. Wear your walking shoes and
join us as we explore previously hidden parts of the building and gardens.</p>

  <p>Held of over one week during the Gallery‚Äôs 40th birthday celebrations. This
special event is co-presented by the National Gallery and the ANU School of
Cybernetics.</p>
</blockquote>

<p>I‚Äôm not sure if there are any tickets left, but if there are you should
definitely check it out. You won‚Äôt get another chance to experience one of
Canberra‚Äôs cultural institutions in this way for a long time.</p>]]></content><author><name>Ben Swift</name></author><category term="cybernetics" /><summary type="html"><![CDATA[For the last year or so my team has been collaborating with the good folks at BOHO Interactive and the National Gallery of Australia on something which launches tonight‚Äîthe NGA Un-Tour.]]></summary></entry><entry><title type="html">So this is how it feels when the robots come for your job: what GitHub‚Äôs Copilot ‚ÄòAI assistant‚Äô means for coders</title><link href="https://benswift.me/blog/2022/06/30/what-githubs-copilot-ai-assistant-means-for-coders/" rel="alternate" type="text/html" title="So this is how it feels when the robots come for your job: what GitHub‚Äôs Copilot ‚ÄòAI assistant‚Äô means for coders" /><published>2022-06-30T00:00:00+10:00</published><updated>2022-06-30T00:00:00+10:00</updated><id>https://benswift.me/blog/2022/06/30/what-githubs-copilot-ai-assistant-means-for-coders</id><content type="html" xml:base="https://benswift.me/blog/2022/06/30/what-githubs-copilot-ai-assistant-means-for-coders/"><![CDATA[<p>I wrote <a href="https://theconversation.com/so-this-is-how-it-feels-when-the-robots-come-for-your-job-what-githubs-copilot-ai-assistant-means-for-coders-185957">a piece for the Conversation</a> about GitHub‚Äôs new
<em>Copilot</em> AI programming assistant. You can <a href="https://theconversation.com/so-this-is-how-it-feels-when-the-robots-come-for-your-job-what-githubs-copilot-ai-assistant-means-for-coders-185957">head over there</a> to
read it if you like.</p>]]></content><author><name>Ben Swift</name></author><category term="tools" /><category term="ai" /><summary type="html"><![CDATA[I wrote a piece for the Conversation about GitHub‚Äôs new Copilot AI programming assistant. You can head over there to read it if you like.]]></summary></entry><entry><title type="html">Redacting craiyon prompts with imagemagick</title><link href="https://benswift.me/blog/2022/06/22/redacting-craiyon-prompts-with-imagemagick/" rel="alternate" type="text/html" title="Redacting craiyon prompts with imagemagick" /><published>2022-06-22T00:00:00+10:00</published><updated>2022-06-22T00:00:00+10:00</updated><id>https://benswift.me/blog/2022/06/22/redacting-craiyon-prompts-with-imagemagick</id><content type="html" xml:base="https://benswift.me/blog/2022/06/22/redacting-craiyon-prompts-with-imagemagick/"><![CDATA[<p>I‚Äôve been messing around with <a href="https://www.craiyon.com">craiyon</a> (formerly
<a href="https://huggingface.co/spaces/dalle-mini/dalle-mini">DALL-E mini</a>), because who
<em>hasn‚Äôt</em> been doing that recently.</p>

<p>As part of a workshop I‚Äôm running soon at the <a href="https://cybernetics.anu.edu.au">School of
Cybernetics</a> I need to provide ‚Äúredacted‚Äù
versions of the classic 3x3 craiyon output image‚Äîand I need to do it for quite
a few outputs.</p>

<p>Because it‚Äôs tedious to do that by hand, here‚Äôs what I came up with:</p>

<ol>
  <li>
    <p>input a prompt and generate the craiyon output as normal</p>
  </li>
  <li>
    <p>use the <em>üì∑ Screenshot</em> button to get a nice, clean screenshot</p>
  </li>
  <li>
    <p>run this <a href="https://imagemagick.org">imagemagick</a> command (in my case the
downloaded screenshot name was <code>craiyon_2022-6-22_17-21-5.png</code>, yours will be
similar but with a different timestamp at the end)</p>

    <pre><code class="language-sh">convert craiyon_2022-6-22_17-21-5.png -fill red -draw 'rectangle 30, 240, 1320, 320' -fill white -pointsize 50 -gravity north -annotate +0+250 'REDACTED' craiyon_2022-6-22_17-21-5-redacted.png
</code></pre>
  </li>
  <li>
    <p>(bonus round) if you want to loop over a bunch of files and do it in batch, I
did that in Emacs with:</p>
    <pre><code class="language-lisp">(--each
    (f-entries "." (lambda (s) (s-ends-with? "png" s)))
  (shell-command (format "convert %s -fill red -draw 'rectangle 30, 240, 1320, 320' -fill white -pointsize 50 -gravity north -annotate +0+250 'REDACTED' redacted-%s.jpg"
                         it
                         (f-base it))))
</code></pre>
  </li>
</ol>

<h2 id="an-example">An example</h2>

<p>Here‚Äôs an example screenshot:</p>

<p><img src="/assets/images/posts/craiyon/craiyon_2022-6-22_17-21-5.png" alt="Grid of AI image outputs generated in response to the prompt &quot;redacting the prompt from a DALL-E image output with imagemagick&quot;" /></p>

<p>and the same output, after the redaction command has been run:</p>

<p><img src="/assets/images/posts/craiyon/redacted-craiyon_2022-6-22_17-21-5.jpg" alt="Grid of AI image outputs generated in response to the prompt, which has been redacted" /></p>

<p>If you need to do the same, then hopefully I‚Äôve saved you a bit of time ‚ò∫</p>]]></content><author><name>Ben Swift</name></author><category term="tools" /><category term="ai" /><summary type="html"><![CDATA[I‚Äôve been messing around with craiyon (formerly DALL-E mini), because who hasn‚Äôt been doing that recently.]]></summary></entry><entry><title type="html">Pulling apart Zoom attendance csv dumps in tidy R</title><link href="https://benswift.me/blog/2022/05/23/pulling-apart-zoom-attendance-csv-dumps-in-tidy-r/" rel="alternate" type="text/html" title="Pulling apart Zoom attendance csv dumps in tidy R" /><published>2022-05-23T00:00:00+10:00</published><updated>2022-05-23T00:00:00+10:00</updated><id>https://benswift.me/blog/2022/05/23/pulling-apart-zoom-attendance-csv-dumps-in-tidy-r</id><content type="html" xml:base="https://benswift.me/blog/2022/05/23/pulling-apart-zoom-attendance-csv-dumps-in-tidy-r/"><![CDATA[<p>My team ran some Zoom training last week and today I needed to figure out who
actually attended across all the days, and for how long.</p>

<p>Zoom can give you a csv dump of all attendees but doesn‚Äôt provide the
aggregations I was after, so I hacked up a little script (in <a href="https://www.tidyverse.org">tidy
R</a>) to do it. If you ever want to do something
similar, feel free to use it (<a href="https://mit-license.org">MIT Licence</a>).</p>

<pre><code class="language-R">read_zoom_attendance_csv = function(filename){
  read_csv(filename, show_col_types = FALSE) %&gt;%
    # I only needed the date, not the actual start time, so I didn't bother parsing
    # the full datetime + timezone string that Zoom gives
    mutate(date = parse_date(str_sub(`Join Time`, end = 10), format = "%m/%d/%Y")) %&gt;%
    # this isn't necessary, but I like shorter column names
    rename(name = `Name (Original Name)`, email = `User Email`, duration = `Duration (Minutes)` ) %&gt;%
    # I'm only intrested in these columns
    select(name, email, date, duration) %&gt;%
    # this isn't necessary, but handy if individuals have signed in with
    # slightly different names on different days (requires eyeballing the data)
    mutate(name = recode(name,
                         "JS" = "Joanna Smith",
                         "Louise" = "Louise Jones"
}
</code></pre>

<p>Then you can read the Zoom csv file like so:</p>

<pre><code class="language-R">df = read_zoom_attendance_csv("zoom-call.csv")
</code></pre>

<p>And to visualise in <a href="https://ggplot2.tidyverse.org">ggplot2</a> (which was my
reason for using R in the first place) you could try something like:</p>

<pre><code class="language-R">df %&gt;%
  group_by(name, date) %&gt;%
  # this was the key summarisation I was after - total time 
  # in-call across multiple connects/re-connects
  summarise(duration = sum(duration)) %&gt;%
  ungroup() %&gt;%
  ggplot(aes(name, duration)) +
  geom_col() +
  coord_flip() +
  facet_wrap(~date, nrow = 1) +
  labs(
    title = "Zoom call attendance",
    x = "participant name",
    y = "duration on the call (minutes)"
  )
</code></pre>

<p>Enjoy!</p>]]></content><author><name>Ben Swift</name></author><category term="tools" /><summary type="html"><![CDATA[My team ran some Zoom training last week and today I needed to figure out who actually attended across all the days, and for how long.]]></summary></entry><entry><title type="html">Scar trees &amp;amp; living typefaces</title><link href="https://benswift.me/blog/2022/05/02/scar-trees-living-typefaces/" rel="alternate" type="text/html" title="Scar trees &amp;amp; living typefaces" /><published>2022-05-02T00:00:00+10:00</published><updated>2022-05-02T00:00:00+10:00</updated><id>https://benswift.me/blog/2022/05/02/scar-trees-living-typefaces</id><content type="html" xml:base="https://benswift.me/blog/2022/05/02/scar-trees-living-typefaces/"><![CDATA[<picture style="position: relative;">
  <img alt="Yellow box tree on ANU campus. üì∏ ANU Photography, 2016" src="/assets/images/posts/20190103_H1P3978_scar_tree.jpg" />

  
</picture>

<p>I wrote something up for the ANU School of Cybernetics blog (where <a href="https://cybernetics.anu.edu.au/people/ben-swift/">I
work</a>) which has the same
energy as some of the stuff I post on here. If you‚Äôre interested, <a href="https://cybernetics.anu.edu.au/2022/05/02/scar-trees-living-typefaces/">go check it
out</a> ‚ò∫</p>]]></content><author><name>Ben Swift</name></author><category term="cybernetics" /><category term="web" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Teaching the world to Cybernetics</title><link href="https://benswift.me/blog/2022/03/07/teaching-the-world-to-cybernetics/" rel="alternate" type="text/html" title="Teaching the world to Cybernetics" /><published>2022-03-07T00:00:00+11:00</published><updated>2022-03-07T00:00:00+11:00</updated><id>https://benswift.me/blog/2022/03/07/teaching-the-world-to-cybernetics</id><content type="html" xml:base="https://benswift.me/blog/2022/03/07/teaching-the-world-to-cybernetics/"><![CDATA[<p>If you‚Äôre the sort of person who lurks on people‚Äôs LinkedIn accounts, you may
have noticed that I‚Äôve recently become the <a href="https://cybernetics.anu.edu.au/people/ben-swift/">lead of the <em>Experiences</em>
Team</a> at the School of
Cybernetics. My team‚Äôs mission is:</p>

<blockquote>
  <p>to take Cybernetics to the world by providing encounters with cybernetics to
individuals and organisations who are (currently) not in our Masters/PhD
programs.</p>

  <p>‚Ä¶and to find ways to do it sustainably.</p>
</blockquote>

<p><img src="/assets/images/posts/alina-grubnyak-ZiQkhI7417A-unsplash.jpg" alt="a bunch of wires connected together in interesting geometric shapes" /></p>

<p>That might strike you as a pretty broad mission, for a couple of reasons:</p>

<ul>
  <li>what counts as an <em>encounter</em>? couldn‚Äôt that be anything?</li>
  <li>the world is a big and diverse place</li>
</ul>

<p>‚Ä¶and you‚Äôd be right. If you follow the rest of the communications from the
School of Cybernetics you‚Äôll know that we‚Äôre not shy about painting a grand,
totalising vision of how the world can/might work and what part cybernetics has
to play in it. And while I‚Äôm a bit daunted by the task, I‚Äôm also pretty excited.</p>

<p>Here are some of the things my team will be working on over the next weeks/months/years:</p>

<ul>
  <li>
    <p>site-specific experiences based around specific places; uncovering the
cybernetic histories of some of the places we inhabit on the ANU campus and
beyond, and creating narrative experiences to share those histories with
others</p>
  </li>
  <li>
    <p>articulating many different answers to the question ‚Äúwhat is cybernetics?‚Äù for
different audiences &amp; mediums (online/in-person, talks/workshops/happenings,
prosaic/poetic)</p>
  </li>
  <li>
    <p>creating a curriculum for interested partners to understand how the key ideas
of cybernetics can help them untagle (or at least manage) the complexity in
their businesses and other organisations</p>
  </li>
</ul>

<p>What I can say is that I want the things we make to be <strong>weird</strong>. If I ever turn
up in a tie and a blue suit and deliver an hours-long bullet-pointed PowerPoint
presentation<sup id="fnref:ppt" role="doc-noteref"><a href="#fn:ppt" class="footnote" rel="footnote">1</a></sup> on this stuff then you have my permission to point me back to
this post and ask me where it all went wrong. Otherwise, I look forward to
crossing paths with you and sharing an educational experience about cybernetics.</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:ppt" role="doc-endnote">

      <p>Don‚Äôt get me wrong, PowerPoint (well, visual aids in general) can be super
effective as part of a multimedia presentation strategy, but the
<a href="https://twitter.com/add_hawk/status/1489001635779018754">affordances of the tool are such that it makes it hard to avoid the
pitfalls</a>.¬†<a href="#fnref:ppt" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Ben Swift</name></author><category term="cybernetics" /><summary type="html"><![CDATA[If you‚Äôre the sort of person who lurks on people‚Äôs LinkedIn accounts, you may have noticed that I‚Äôve recently become the lead of the Experiences Team at the School of Cybernetics. My team‚Äôs mission is:]]></summary></entry><entry><title type="html">Running an AI neural style transfer model under Singularity</title><link href="https://benswift.me/blog/2022/02/01/running-an-ai-neural-style-transfer-model-under-singularity/" rel="alternate" type="text/html" title="Running an AI neural style transfer model under Singularity" /><published>2022-02-01T00:00:00+11:00</published><updated>2022-02-01T00:00:00+11:00</updated><id>https://benswift.me/blog/2022/02/01/running-an-ai-neural-style-transfer-model-under-singularity</id><content type="html" xml:base="https://benswift.me/blog/2022/02/01/running-an-ai-neural-style-transfer-model-under-singularity/"><![CDATA[<p>I‚Äôve recently been given access to a beefy AI server (6x RTX3090s!) which is
managed via <a href="https://sylabs.io/singularity/">SingularityCE</a>, whose homepage
boldly asks and then forgets to answer the question: ‚ÄúWhat is SingularityCE?‚Äù</p>

<p>If you <a href="https://sylabs.io/guides/latest/user-guide/introduction.html">dig further into the
documentation</a>
it‚Äôs a little less coy:</p>

<blockquote>
  <p>SingularityCE is a container platform. It allows you to create and run
containers that package up pieces of software in a way that is portable and
reproducible. You can build a container using SingularityCE on your laptop,
and then run it on many of the largest HPC clusters in the world, local
university or company clusters, a single server, in the cloud, or on a
workstation down the hall. Your container is a single file, and you don‚Äôt have
to worry about how to install all the software you need on each different
operating system.</p>
</blockquote>

<p>I want to fire up my new GPUs and run one of Katherine Crowson‚Äôs awesome pytorch
scripts to do some <a href="https://github.com/crowsonkb/style-transfer-pytorch">neural style
transfer</a>. I‚Äôm very
familiar with Docker, but new to this Singularity thing, so here are some of the
hurdles I encountered (and cleared) along the way.</p>

<h2 id="finding-a-base-image">Finding a base image</h2>

<p>Looking in the style transfer repo‚Äôs
<a href="https://github.com/crowsonkb/style-transfer-pytorch/blob/master/setup.py#L23"><code>setup.py</code></a>,
it looks like <a href="https://pytorch.org">torch</a> v1.7.1 or later is required. Having
done this sort of thing before, I know that these deep learning frameworks
change a fair bit even between minor versions, so the safest option is to pick
the exact version that it was designed for‚Äîin this case v1.7.1 (or at least
v1.7.x).</p>

<p>So, the challenge is to find a Singularity image with that version of torch
installed. The singularity docs <a href="https://sylabs.io/guides/latest/user-guide/quick_start.html#download-pre-built-images">suggest using the search
command</a>
like so:</p>

<pre><code class="language-shell">$ singularity search torch

Found 34 container images for amd64 matching "torch":

	library://adalisan81/default/pytorch:latest

	library://aday651/default/pytorch-geometric-gpu:latest

	library://aphoh/default/pytorch-20.11-py3:v-1

	library://aradeva24/default/ar_pytorch_21.06-py3.sif:latest
		PyTorch NGC container with CUDA11.0, where PyTorch and apex are installed

	library://calebh/hpccm-test/faircluster-pytorch-1.10-cuda11.3:sha256.7c63a6c1f6f125b8d3e14fa10203965536ec7173d50e85b8c9ecf6ee0bff2ba7

	library://claytonm/default/ubuntu18_torch_torchvision_opencv_cuda10:latest

	library://dxtr/default/hpc-pytorch:0.1

	library://guoweihe/default/pytorch:hz1

	library://guoweihe/default/pytorch:v1.2

	library://guoweihe/default/torch:deep-ed

	library://guoweihe/default/torch:sha256.ff32c85ade2c8f6a1d34bd500de1b7bd11cdac16461aeef4d7cbd16ab129d8a7

	library://guoweihe/default/torchgpipe:master

	library://guoweihe/default/torchgpipe:sha256.a6ea5d732cba07c043e2f06cccbe541d28da6a8d9e5a3d18872d58af288dbc62

	library://ipa/medimgproc/pytorch:latest

	library://jamiechang917/default/pytorch:sha256.9c60c9825f20626cc0d6e69ac61d862bfec927e82d86becee73f853d657f2425

	library://lamastex/default/pytorch_21.03.sif:berzelius-20211027

	library://lamastex/default/pytorch_21.07.sif:berzelius-20211027

	library://lev-hpc/ml/pytorch_gpu:jupyter

	library://lev-hpc/ml/torch_tf_jupyter:latest

	library://mbalazs/default/pytorch:latest

	library://mbalazs/default/pytorch_cuda110:latest

	library://mike_holcomb/pytorchvision/v0.1.0:latest,v0.1.0

	library://oscartang/default/pytorch_translation:latest

	library://ottino8/default/pytorch:first

	library://pauldhein/hpc-deep-learning/torch-base:latest

	library://sina-ehsani/default/transformer-googlecrawl-torch-opencv:latest

	library://sina-ehsani/default/transformer-googlecrawl-torch1.10:latest

	library://skykiny/default/pytorch_skykiny:latest

	library://tmyoda/default/cuda-torch-pyenv:latest

	library://tru/default/c7-conda-pytorch-10.0:2019-07-12-2053,latest

	library://ufscar/hpc/cuda_pytorch:latest

	library://uvarc/default/pytorch:1.4.0-py37

	library://yboget/default/pytorch_rdkit_visdom:sha256.d97f221ef1294a8ef57d40cf7994d05d4955abc7cf39e3ce42faafd59fe3151a

	library://zhengtang/default/torch_translation:latest
</code></pre>

<p>Hmm. It‚Äôs hard to know which is official, which ones are going to work (a few of
them mention torch versions, but none of them are v1.7.x) and which ones might
even be malicious? That‚Äôs a worry.</p>

<p>Looking a bit deeper into the Singularity docs I find that one can <a href="https://sylabs.io/guides/latest/user-guide/singularity_and_docker.html">also use
Docker/OCI
images</a>,
and Singularity can pull them straight from Docker hub. That‚Äôs good news,
because NVIDIA do maintain <a href="https://hub.docker.com/r/pytorch/pytorch/tags">official Docker
images</a> for using torch with
NVIDIA graphics cards (like the 3090), so I find the <a href="https://hub.docker.com/layers/pytorch/pytorch/1.7.1-cuda11.0-cudnn8-runtime/images/sha256-db6086be92f439b918c96dc002f4cf40239e247f0b1b6c32e3fb36de70032bf9?context=explore">specific container image
for torch
v1.7.1</a>
and pull it down with:</p>

<pre><code class="language-shell">singularity pull docker://pytorch/pytorch:1.7.1-cuda11.0-cudnn8-runtime
</code></pre>

<h2 id="running-the-style_transfer-python-script">Running the <code>style_transfer</code> python script</h2>

<p>I‚Äôd already cloned the neural style transfer repo, so I can follow the
instructions in that
<a href="https://github.com/crowsonkb/style-transfer-pytorch/blob/master/README.md">README.md</a></p>

<pre><code class="language-shell">$ singularity shell pytorch_1.7.0-cuda11.0-cudnn8-runtime.sif 
Singularity&gt; cd style-transfer-pytorch/
Singularity&gt; pip install --user .
</code></pre>

<p>I got a bunch of warnings about certain things not being on the <code>$PATH</code>, but it
seems to finish installing everthing ok.</p>

<p>Continuing on with the instructions in the README, let‚Äôs try running this thing
(I‚Äôd downloaded a couple of image files to use as my <em>content</em> and <em>style</em> images).</p>

<pre><code class="language-shell">Singularity&gt; style_transfer ben.jpg tiger.jpg -o ben-tiger.jpg
bash: style_transfer: command not found
</code></pre>

<p>Hmm, looks like those <code>$PATH</code> warnings were prescient. Looking back, the exact
warning was:</p>

<pre><code class="language-shell">WARNING: The script normalizer is installed in '/home/users/ben/.local/bin' which is not on PATH
</code></pre>

<p>The quickest &amp; dirtiest fix for this is to add that <code>/bin</code> directory to my path
and try and re-run the script.</p>

<pre><code class="language-shell">Singularity&gt; PATH="$PATH:~/.local/bin" style_transfer ben.jpg tiger.jpg -o ben-tiger.jpg
</code></pre>

<p>And away it went! Several minutes later, it was done. Here are the original two images:</p>

<p><img src="/assets/images/headshots/headshot.jpg" alt="Original ben.jpg image" />
<img src="/assets/images/posts/tiger.jpg" alt="Original tiger.jpg" /></p>

<p>and here‚Äôs the output:</p>

<p><img src="/assets/images/posts/ben-tiger.jpg" alt="style-transferred ben-tiger.jpg" /></p>

<p>Success‚Ä¶ish. Clearly I need to keep tweaking parameters &amp; input images to come
up with an output that‚Äôs actually <em>good</em>, but at least that journey can now
begin.</p>

<h2 id="but-is-it-fast">But is it <em>fast</em>?</h2>

<p>Actually, that declaration of success is a bit premature. At the top of the
output I noticed that the script was running on the CPU, not the GPU.</p>

<pre><code class="language-shell">Singularity&gt; PATH="$PATH:~/.local/bin" style_transfer ben.jpg tiger.jpg -o ben-tiger.jpg
~/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)
  return torch._C._cuda_getDeviceCount() &gt; 0
Using devices: cpu
CPU threads: 128
Loading model...
</code></pre>

<p>That‚Äôs really not ok‚Äîthe whole point of running on this machine is to take
advantage of the GPUs. There could be lots of reasons for this, but I have a
hunch it has something to do with Singularity not allowing the script access to
the hardware. Sure enough, looking through the <a href="https://sylabs.io/guides/3.7/user-guide/gpu.html">Singularity GPU support
documentation</a> it turns out
there‚Äôs a magic <code>--nv</code> flag which must be passed when starting up the
Singularity session, so let‚Äôs do that.</p>

<pre><code class="language-shell">$ singularity shell --nv pytorch_1.7.1-cuda11.0-cudnn8-runtime.sif 
Singularity&gt; PATH="$PATH:~/.local/bin" style_transfer ben.jpg tiger.jpg -o ben-tiger.jpg
Using devices: cuda:0
~/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:143: UserWarning: 
NVIDIA GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.
If you want to use the NVIDIA GeForce RTX 3090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/

  warnings.warn(incompatible_device_warn.format(device_name, capability, " ".join(arch_list), device_name))
GPU 0 type: NVIDIA GeForce RTX 3090 (compute 8.6)
GPU 0 RAM: 24268 MB
Loading model...

*error traceback intensifies*
</code></pre>

<p>Well, that‚Äôs progress. Looking through the output I can see</p>

<pre><code class="language-shell">Using devices: cuda:0
GPU 0 type: NVIDIA GeForce RTX 3090 (compute 8.6)
GPU 0 RAM: 24268 MB
</code></pre>

<p>so torch can now see the GPUs. However, the error message in the middle of that
output is now the problem:</p>

<blockquote>
  <p>NVIDIA GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the
current PyTorch installation.</p>

  <p>The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60
sm_70.</p>

  <p>If you want to use the NVIDIA GeForce RTX 3090 GPU with PyTorch, please check
the instructions at <a href="https://pytorch.org/get-started/locally/">https://pytorch.org/get-started/locally/</a></p>
</blockquote>

<p>Like I said earlier, torch/tensorflow/CUDA and deep learning frameworks in
general are really finnicky about versions. It‚Äôs tricky to get things up and
running so that (i) all the versions work together and (ii) the changes you make
don‚Äôt break the delicate version relationships between other deep learning
projects you want to run on the same system<sup id="fnref:singularity-isolation" role="doc-noteref"><a href="#fn:singularity-isolation" class="footnote" rel="footnote">1</a></sup>.</p>

<p>After a web search, it seems <a href="https://github.com/pytorch/vision/issues/4886">like others
</a> <a href="https://discuss.pytorch.org/t/geforce-rtx-3090-with-cuda-capability-sm-86-is-not-compatible-with-the-current-pytorch-installation/123499">have
had</a>
<a href="https://github.com/crowsonkb/style-transfer-pytorch/issues/1#issuecomment-769701949">similar
issues</a>,
although I tried all the approaches listed there and none of them worked.</p>

<h2 id="using-a-pytorch-image-from-nvidias-container-registry">Using a pytorch image from NVIDIA‚Äôs container registry</h2>

<p>Changing tack a bit (after a suggestion from a colleague) I decided to try using
a (Docker) <a href="https://catalog.ngc.nvidia.com/orgs/nvidia/containers/pytorch">container image from the NVIDIA
registry</a>, rather
than the official pytorch channel on Docker Hub.</p>

<pre><code class="language-shell">$ singularity pull docker://nvcr.io/nvidia/pytorch:22.01-py3
$ singularity shell --nv pytorch_22.01-py3.sif 
Singularity&gt; pip install --user .
</code></pre>

<p>Now, let‚Äôs try running the <code>style_trasfer</code> script one more time:</p>

<pre><code class="language-shell">Singularity&gt; PATH="$PATH:~/.local/bin" style_transfer ben.jpg tiger.jpg -o ben-tiger.jpg
Using devices: cuda:0
GPU 0 type: NVIDIA GeForce RTX 3090 (compute 8.6)
GPU 0 RAM: 24268 MB
Loading model...
Processing content image (128x85)...
</code></pre>

<p>Hooray! It works, and runs, like 10000x faster on the GPU.</p>

<h2 id="open-questions">Open questions</h2>

<p>I really was just ‚Äúhacking it until it worked‚Äù during this process, so I have a
few open questions.</p>

<ul>
  <li>
    <p>What‚Äôs the ‚Äúpersistance‚Äù story with the singularity images (<code>*.sif</code> files)? Is
it like docker, where I <code>singularity shell</code> in, do some things, but then any
changes I make in the shell (container?) don‚Äôt persist? It doesn‚Äôt seem like
that‚Ä¶ but need to have a better mental model of how singularity images work.</p>
  </li>
  <li>
    <p>I didn‚Äôt use <a href="https://virtualenv.pypa.io/en/latest/">venvs</a> or
<a href="https://docs.conda.io/en/latest/">conda</a> or
<a href="https://python-poetry.org/docs/">poetry</a> or any of the things I‚Äôd usually use
when python-ing on my own machine, partially because of my above questions
about how the whole singularity shell thing actually works. I just did <code>pip
install --user .</code> and hoped it didn‚Äôt break anything else. Is that ok? Or
should I still use venvs in the singularity image?</p>
  </li>
</ul>

<p>I will return and try and better understand these things later, but right now
this isn‚Äôt on the critical path for me so I‚Äôll have to park it. This blog post
is really just me opening a ticket for myself to return to later. I share it so
that you, dear reader, can also benefit from my mistakes (and if you know of
better ways to do any of this then do <a href="mailto:ben.swift@anu.edu.au">drop me a
line</a>.</p>

<h2 id="footnotes">Footnotes</h2>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:singularity-isolation" role="doc-endnote">

      <p>I had hoped that Singularity might help with the ‚Äúisolation‚Äù part of this,
but I‚Äôm not sure I understand it well enough yet to know how to do it.¬†<a href="#fnref:singularity-isolation" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Ben Swift</name></author><category term="tools" /><category term="ai" /><summary type="html"><![CDATA[I‚Äôve recently been given access to a beefy AI server (6x RTX3090s!) which is managed via SingularityCE, whose homepage boldly asks and then forgets to answer the question: ‚ÄúWhat is SingularityCE?‚Äù]]></summary></entry><entry><title type="html">Cybernetic futures explained (maybe)</title><link href="https://benswift.me/blog/2022/01/20/cybernetic-futures-explained/" rel="alternate" type="text/html" title="Cybernetic futures explained (maybe)" /><published>2022-01-20T00:00:00+11:00</published><updated>2022-01-20T00:00:00+11:00</updated><id>https://benswift.me/blog/2022/01/20/cybernetic-futures-explained</id><content type="html" xml:base="https://benswift.me/blog/2022/01/20/cybernetic-futures-explained/"><![CDATA[<p class="hl-para">One of my current projects at the ANU School of Cybernetics is to develop tools
&amp; procedures for futuring. This post is an attempt to get my head around how
these things fit together (spoiler: they do!).</p>

<h2 id="futures">Futures</h2>

<p>Futures/futuring<sup id="fnref:terminology" role="doc-noteref"><a href="#fn:terminology" class="footnote" rel="footnote">1</a></sup> is <em>a thing</em>‚Äîsee <a href="https://www.howtofuture.com">Smith and
Ashby</a> for a practical guide or
<a href="https://www.press.uillinois.edu/books/?id=p084690">Powers</a> for a more critical
history and review. It‚Äôs the idea and practice of futuring as a verb, and this
video from the <a href="https://www.iftf.org">Institute for the Future</a> is a good
articulation of the ‚Äúpitch‚Äù:</p>

<div style="width:100%; margin: 0px auto; margin-bottom: 1rem;">
  <div style="position: relative; padding-bottom: 62.5%; height: 0px;">
	<iframe style="position: absolute; top: 0px; left: 0px; width: 100%; height: 100%;" src="https://www.youtube.com/embed/5_EsLu4qydw" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="">
	</iframe>
  </div>
</div>

<p>Just so I‚Äôm clear up-front: I think that futuring is a genuinely useful tool in
the toolbelt of any individual or organisation trying to figure out what success
looks like and how to achieve it.</p>

<p>One diagram which is often used in futuring is the <a href="https://thevoroscope.com/publications/foresight-primer/">futures
cone</a>, which helps
visualise the relationship between the <em>now</em> and the different potential
<em>futures</em> which might eventuate.</p>

<p><img src="/assets/images/posts/cybernetic-futures/futures-cone.png" alt="The futures cone" /></p>

<p>This diagram is just a visual aid‚Äîthe future doesn‚Äôt really exist as a series
of concentric discs of soothing colours‚Äîbut it helps to anchor discussions we
might have and predictions we might make about the future. In this sense, any
prediction or ‚Äúvision‚Äù of the future is a single <strong>point</strong> in the futures cone,
and exactly where it falls in the space of possible, plausible, probable, or
preferable futures is part of the discussion. Think about it as <a href="https://en.wikipedia.org/wiki/Monte_Carlo_method">monte
carlo</a> of the future:</p>

<p><img src="/assets/images/posts/cybernetic-futures/futures-sampling.png" alt="An example distribution of potential futures in the futures cone" /></p>

<p>One thing to note here is that futuring is not about predicting the future. In
many ways it makes one less certain about the future; futuring requires a
healthy dose of epistemic humility, but that‚Äôs ok. It‚Äôs hard to expect the
unexpected and predict the unpredictable, so these sampled points (potential
futures) are really just a way of thinking about the current state of the world,
and especially how we might act and position ourselves in the world now to make
the most of future opportunities and steer towards the more desirable potential
futures.</p>

<h2 id="cybernetics">Cybernetics</h2>

<p><a href="https://en.wikipedia.org/wiki/Stafford_Beer">Stafford Beer</a> tells a joke about
defining cybernetics in <a href="https://www.emerald.com/insight/content/doi/10.1108/03684920210417283/">an address he gave at the University of
Valladolid</a>:</p>

<blockquote>
  <p>‚Ä¶it concerns three men who are about to be executed. The prison governor
calls them to his office, and explains that each will be granted a last
request. The first one confesses that he has led a sinful life, and would like
to see a priest. The governor says he thinks he can arrange that. And the
second man? The second man explains that he is a professor of cybernetics. His
last request is to deliver a final and definitive answer to the question: what
is cybernetics? The governor accedes to this request also. And the third man?
Well, he is a doctoral student of the professor‚Äîhis request is to be
executed second.</p>
</blockquote>

<p>It‚Äôs a great joke, grounded in a deep truth. One way to define cybernetic
systems is as systems with (i) a purpose/goal and (ii) a mechanism for steering
towards<sup id="fnref:towards" role="doc-noteref"><a href="#fn:towards" class="footnote" rel="footnote">2</a></sup> said purpose. In some cases there‚Äôs a defined end state, where
upon attaining said purpose victory is declared and the job is done. However in
many cases what‚Äôs desirable is
<a href="https://en.wikipedia.org/wiki/Homeostasis">homeostasis</a>, i.e. a system which
can keep itself ‚Äúin its happy place‚Äù, stable and resistant to peturbations.</p>

<p><img src="/assets/images/posts/cybernetic-futures/evgeni-tcherkasski-SHA85I0G8K4-unsplash.jpg" alt="A lighthouse on the shore" /></p>

<p>There are lots of potential illustrations of this idea, but one that many of my
cybernetic forebears liked is the one of using a lighthouse to steer a ship.
<a href="https://history-computer.com/the-complete-guide-to-cybernetics/">Here‚Äôs</a> a nice
explanation:</p>

<blockquote>
  <p>In ancient Greece, the
<a href="https://en.wikipedia.org/wiki/Cybernetics#Etymology"><em>Kubernetes</em></a>
[navigator/helmsperson] was in charge of controlling the Grecian longships.
The ships had to be steered through all kinds of unpredictable forces,
including wind, waves, storms, currents, and tides. The Greeks found that they
could ignore all of these and control the ship via a small tiller connected to
the ship‚Äôs larger rudder just by pointing the tiller toward a fixed object in
the distance, such as a lighthouse, and making adjustments in real-time.</p>
</blockquote>

<p>There‚Äôs a <a href="https://www.youtube.com/watch?v=iXmlbd86YGA">YouTube ‚ÄúWhat is
cybernetics?‚Äù</a> video which includes
a diagram like this:</p>

<p><img src="/assets/images/posts/cybernetic-futures/kubernetes-steering-procedure.png" alt="Diagram of the kubernetes' steering procedure" /></p>

<p>It‚Äôs not the particular position of the tiller at any one time that‚Äôs important,
is the way that the navigator watches the lighthouse and moves the tiller in
response (as the ship is affected by currents &amp; winds). If the ship‚Äôs bow is
pointing to one side of the lighthouse, then adjust the tiller in the opposite
direction until it does. If you keep up that simple procedure, you‚Äôll get there
in the end, and with your ship in one piece.</p>

<p>It‚Äôs the navigator‚Äôs continued monitoring of the difference between the
purpose/goal (as indicated by the lighthouse) and the current state (as
indicated by the where the bow is pointing) which matters. Once you know how to
respond to that difference, by steering in the opposite direction of that
difference, then you‚Äôve got a simple and reliable procedure for successful
sailing.</p>

<p>Here‚Äôs the key point: cybernetic systems don‚Äôt work by planning out a complex,
go-to-whoa list of actions to take and then mindlessly following them. Instead
they use a simpler process involving <em>feedback</em>: do a thing,
looking/listening/sense what happened, compare the new state of the world with
the goal, and then do another thing‚Ä¶ and so on<sup id="fnref:all-encompassing" role="doc-noteref"><a href="#fn:all-encompassing" class="footnote" rel="footnote">3</a></sup>.</p>

<p><img src="/assets/images/posts/cybernetic-futures/remy-gieling-n_QECf2Qm4E-unsplash.jpg" alt="A radar dish" /></p>

<p>Here‚Äôs another example of a feedback-powered system. The development of radar in
WWII was deeply connected to the birth of cybernetics (as detailed by Thomas Rid
in <a href="https://wwnorton.com/books/Rise-of-the-Machines/">Rise of the Machines</a>
Chapter 1). Take it away, <a href="https://en.wikipedia.org/wiki/Radar">Wikipedia</a>:</p>

<blockquote>
  <p>A radar system consists of a
<a href="https://en.wikipedia.org/wiki/Transmitter" title="Transmitter">transmitter</a>
producing <a href="https://en.wikipedia.org/wiki/Electromagnetic_wave" title="Electromagnetic
wave">electromagnetic
waves</a> in the <a href="https://en.wikipedia.org/wiki/Radio_spectrum" title="Radio
spectrum">radio</a> or <a href="https://en.wikipedia.org/wiki/Microwave" title="Microwave">microwaves</a> domain, a transmitting
<a href="https://en.wikipedia.org/wiki/Antenna_(radio)" title="Antenna (radio)">antenna</a>, a
receiving antenna (often the same antenna is used for transmitting and
receiving) and a <a href="https://en.wikipedia.org/wiki/Radio_receiver" title="Radio receiver">receiver</a> and
<a href="https://en.wikipedia.org/wiki/Data_processing_system" title="Data
processing system">processor</a> to determine properties of the object(s). Radio waves
(pulsed or continuous) from the transmitter reflect off the object and return
to the receiver, giving information about the object‚Äôs location and speed.</p>
</blockquote>

<p>The radar sends out the pulses, which bounce (reflect) off the environment‚Äîand
these these reflections are sufficient (with some <a href="https://nato-us.org/analysis2000/papers/moran.pdf">tricky
maths</a>) to figure out what
the environment looks like. Often there‚Äôs some sort of visual representation of
the results, like the classic ‚Äúbeeping dots on concentric circles‚Äù radar sweep
interface you‚Äôll know from the movies.</p>

<p>The radar example is different from the ship steering one in that lighthouses
don‚Äôt really move/change (although the currents in the water &amp; other
environmental factors do‚Ä¶ hence the need for the feedback-powered steering
procedure). Using the radar properly requires sending an ongoing series of
pulses, because they each give an indication of what the environment looked like
when the pulses were reflected, but to track moving objects you need to monitor
the dots over time to see how the environment changes.</p>

<h2 id="cybernetic-futures">Cybernetic futures</h2>

<p>Returning to futuring; each future scenario you can imagine (regardless of where
it falls in the futures cone) is a way of projecting a potential ‚Äúend state‚Äù.
That end state doesn‚Äôt have to be desirable‚Äîmany potential futures
aren‚Äôt‚Äîbut it gives a ‚Äúconcrete‚Äù thing against which to compare your current
state to inform your current actions. Even the more mundane acts of management
and oversight‚Äîstrategy, tactics, contingency planning‚Äîwhen done well they
all involve articulating goals and thinking about ways to bring them about.
There‚Äôs clearly an echo of the ‚Äústeering systems‚Äù thing here.</p>

<p>However, one pitfall of that sort of mental picture of the future is that
futuring looks like a three step process:</p>

<ol>
  <li>come up with (sample) a bunch of potential futures from the futures cone (the
points in the diagram above)</li>
  <li>pick one of the potential futures you like the most (from the <em>preferable</em>
area of the futures cone)</li>
  <li>steer towards<sup id="fnref:lighthouse-steering" role="doc-noteref"><a href="#fn:lighthouse-steering" class="footnote" rel="footnote">4</a></sup> it like a lighthouse (whatever that looks
like)</li>
</ol>

<p><img src="/assets/images/posts/cybernetic-futures/steering-towards-preferred-future.png" alt="Steering towards a preferred future" /></p>

<p>That‚Äôs an unhelpful picture of what futuring is because it implies that the
potential future you‚Äôre steering towards is solid &amp; stationary, but that‚Äôs just
not how potential futures work. Instead, I think that futuring works best when
it‚Äôs more like a radar:</p>

<ol>
  <li>come up with (sample) a bunch of potential futures from the futures cone
(send out radar pulses)</li>
  <li>look for their reflections in the present</li>
  <li>analyse these reflections to decide how to act</li>
  <li>goto step 1 (because things have now changed)</li>
</ol>

<p><img src="/assets/images/posts/cybernetic-futures/futures-as-radar.png" alt="Futuring as a radar" /></p>

<p>As well as giving a different mental model of what futuring is and isn‚Äôt, I
think there are two implications of this switch in perspective.</p>

<ol>
  <li>
    <p>Just like a ship drifts on the currents, our orientation to these potential
futures is constantly changing as we &amp; others act in the present‚Äîwe‚Äôre
agents; we have agency. So we need to constantly re-examine our orientation
towards these multiple futures and reorient ourselves as a result. That‚Äôs a
‚Äúradar-like‚Äù model of futuring. Cybernetics doesn‚Äôt provide a ‚Äúonce you
measure &amp; model all the things you can predict the future‚Äù silver bullet
(although it‚Äôs not like some folks haven‚Äôt tried <a href="https://eujournalfuturesresearch.springeropen.com/articles/10.1007/s40309-013-0029-y">and
failed</a>),
but rather it‚Äôs a commitment to using a simple ‚Äúsense-analyze-act‚Äù feedback
loop to keep the system on track.</p>
  </li>
  <li>
    <p>Don‚Äôt be fooled by the simplicity of the steering procedure in the
ship/lighthouse example; the radar example shows that making sense of the
feedback from the environment can require non-trivial analysis before it‚Äôs
useful.</p>
  </li>
</ol>

<p>To close, I want to stress that I‚Äôm not saying anything remotely new here about
the connection between futuring and cybernetics‚Äîthey‚Äôre very often seen &amp;
discussed together. William Gibson, award-winning sci-fi novelist and sometime
futurist was <a href="http://www.nytimes.com/2007/08/19/magazine/19wwln-q4-t.html">steeped in cybernetic
lore</a> when he
<a href="https://www.themarginalian.org/2014/08/26/how-william-gibson-coined-cyberspace/">coined the term
‚Äúcyberspace‚Äù</a>.
My boss <a href="https://cybernetics.anu.edu.au/people/genevieve-bell/">Genevieve Bell
AO</a>, director of the <a href="https://cybernetics.anu.edu.au">ANU
School of Cybernetics</a>, has thought deeply and
written persuasively and generally projected big futuring energy for pretty much
her whole career.</p>

<h2 id="footnotes">Footnotes</h2>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:terminology" role="doc-endnote">
      <p>or foresight, or forecasting‚Ä¶ there are a few terms which are used relatively interchangeably¬†<a href="#fnref:terminology" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:towards" role="doc-endnote">

      <p>The system‚Äôs purpose can also be stated negatively, e.g. avoiding pain. So
towards/away from are equally valid when talking about purpose.¬†<a href="#fnref:towards" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:all-encompassing" role="doc-endnote">

      <p>If that definition sounds all-encompassing, you‚Äôre not the first person to
notice that. Cybernetics <a href="https://www.pangaro.com/cybernetics-the-center-of-sciences-future.html">isn‚Äôt
shy</a>
about claiming all things as within its purview‚ÄîWiener was an ersatz
theologian.¬†<a href="#fnref:all-encompassing" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:lighthouse-steering" role="doc-endnote">

      <p>Yeah, I know, you don‚Äôt steer towards the lighthouse exactly‚Äîthey just
<a href="https://adventure.howstuffworks.com/lighthouse.htm">show you where the rocks and reefs
are</a>. Don‚Äôt @ me.¬†<a href="#fnref:lighthouse-steering" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Ben Swift</name></author><category term="cybernetics" /><summary type="html"><![CDATA[One of my current projects at the ANU School of Cybernetics is to develop tools &amp; procedures for futuring. This post is an attempt to get my head around how these things fit together (spoiler: they do!).]]></summary></entry><entry><title type="html">Livecoder-in-the-club as a system</title><link href="https://benswift.me/blog/2021/11/11/livecoder-in-the-club-as-a-system/" rel="alternate" type="text/html" title="Livecoder-in-the-club as a system" /><published>2021-11-11T00:00:00+11:00</published><updated>2021-11-11T00:00:00+11:00</updated><id>https://benswift.me/blog/2021/11/11/livecoder-in-the-club-as-a-system</id><content type="html" xml:base="https://benswift.me/blog/2021/11/11/livecoder-in-the-club-as-a-system/"><![CDATA[<div class="hl-para">

  <p>Here in the <a href="https://cybernetics.anu.edu.au/">School of Cybernetics</a> we are building our
capability in cybernetics‚Äîits histories and possibilities‚Äîand
working out how each of us will contribute to the new cybernetics for the 21st
Century.</p>

  <p>This blog post, written for a general audience, is part of a content development
sprint, written in reponse to the task of developing a short (1000 words)
persuasive argument about the role and value of cybernetics as an approach to
shape futures through and with technology.</p>

</div>

<p>If you follow this blog, you‚Äôll know that I‚Äôm a <a href="/livecoding/index.html">livecoder</a>. I <em>code</em> (i.e. write computer programs) to make music in a
club setting, with an audience that just wants to dance and have a good
time<sup id="fnref:niche" role="doc-noteref"><a href="#fn:niche" class="footnote" rel="footnote">1</a></sup>. Between the code, the thumping music, the dancing humans, and all
the other glorious complexities of live entertainment, there‚Äôs certainly a lot
of different stuff going on. You might find watching a livecoder in action to be
entertaining, or impressive, or bewildering, or all of the above. Most of all,
when you see/attend a livecoding gig for the first time, I bet that your initial
feeling is one of <em>what is going on?</em></p>

<p>In this post I‚Äôm going to use some ideas from cybernetics to try and help you
make sense of a livecoder performing in a club, in part to help you understand
for what it <em>feels like</em> I‚Äôm doing when I do it. From there I want to think
about ways to make livecoding even better, that is, to figure out put on a
better show for the adoring crowds.</p>

<h2 id="livecoder-in-the-club-as-a-system">Livecoder-in-the-club as a system</h2>

<p><a href="https://www.youtube.com/watch?v=kx79HLLboT8">Cybernetics</a> is all about the
looking at and reasoning about <strong>systems</strong> with <em>goals</em>, interacting with and
connected to their <em>environment</em> via perception/action <em>feedback loops</em>. These
sorts of systems exist at all sorts of different scales (big/small, fast/slow,
old/new, cheap/expensive, etc.) and they‚Äôre <a href="https://www.goodreads.com/book/show/10698938-the-fractal-organization">fractal in
nature</a>‚Äîit
doesn‚Äôt matter what level of ‚Äúmagnification‚Äù you look at, each component of a
system is itself a system of interacting components, and each system is itself a
component interacting in a larger system. But since that‚Äôs all pretty abstract,
let‚Äôs return to the example of the livecoder-in-the-club. This is written in the
first person, but other livecoders may have similar understandings of their own
livecoder-in-the-club practice.</p>

<ul>
  <li>
    <p>I start with a full tank of <strong>brain juice</strong> which allows me to work on tricky
coding problems. But it‚Äôs mentally taxing. When I‚Äôm happy, rested &amp; in the
zone, I feel like I‚Äôve got a full tank, but writing code takes mental energy,
and so writing the code in the performance drains my brain juice until I‚Äôm
cooked, and then I can‚Äôt write any more code (or at least will write bad/buggy
code) until I recharge.</p>
  </li>
  <li>
    <p>To write the <strong>code</strong> I tap my fingers on the keys of my keyboard. I use a
<a href="https://emacs.sexy">specialised program</a> for this (i.e. I don‚Äôt write it in
MS Word) which has a bunch of features to help, like different colours for the
different parts of the code (e.g. functions vs variable vs numerical parameter
values), and auto-completion, and inline documentation/help about the
particular bit of code that I‚Äôm working on. This code is also projected onto a
big screen in the club so that the dancers can look at it (or not).</p>
  </li>
  <li>
    <p>As the code runs, it generates <strong>music</strong>. Different parts of the code are
responsible for different parts of the music, and I try and give the functions
&amp; variables in my code human-readable names (like <code>piano</code>) so that the
correspondence between the code and the music is clear-ish. The music will
only be generated if the code is running nicely (i.e. without bugs/errors) and
is hooked up to the PA system in the club. If I crash the program (or if
someone unplugs the PA) then the music will stop.</p>
  </li>
  <li>
    <p>The people in the club‚Äîpeople dancing, people chilling at the bar, people
watching the code on the screen‚Äîare collectively having an experience which
(hopefully) is giving them <strong>good vibes</strong>. Obviously this is a <em>huge</em>
oversimplification, and the extent to which any individual is enjoying
themselves (and therefore contributing positively to the amount of good vibes
in the room) depends on all sorts of things. But, in a real sense, the
creation of <strong>good vibes</strong> in the room is the goal of the live coder‚Äîor at
least it‚Äôs <em>my</em> goal when I perform in this situtation. So I (like any
performer) feed off the good vibes, replenishing (to some extent) my brain
juice.</p>
  </li>
</ul>

<p>It‚Äôs a bit clearer to see in a picture:</p>

<picture style="position: relative;">
  <img alt="system diagram for the livecoder-in-a-club system" src="/assets/images/posts/livecoder-in-a-club-system-diagram.png" />

  
</picture>

<p>So, clearly,</p>

<blockquote>
  <p>a livecoder is a machine for turning <strong>brain juice</strong> into <strong>good vibes</strong> (via
<strong>code</strong> and <strong>music</strong>)</p>
</blockquote>

<p>which is a nice way to think about it, and actually is a relatively accurate
picture of what I <em>feel</em> is going on when I‚Äôm performing.</p>

<h2 id="how-does-cybernetics-help-us-understand-and-improve-this-system">How does cybernetics help us understand and improve this system?</h2>

<p>In this account of livecoding-in-the-club, there are a few things worth
noticing:</p>

<ul>
  <li>
    <p>there are different ‚Äústocks‚Äù (reservoirs of brain juice, code, music and good vibes)</p>
  </li>
  <li>
    <p>there are various flows between those stocks, and in both directions (e.g. I
turn brain juice into code by typing at my keyboard, but I also receive
information about what the code looks like from my laptop screen, via my eyes)</p>
  </li>
  <li>
    <p>there‚Äôs a goal: to put on a good show for the audience to enjoy (to increase
the stock of good vibes in the room)</p>
  </li>
  <li>
    <p>the system includes closed loops, and so is capable of feedback</p>
  </li>
</ul>

<p>A key principle of cybernetics is that the structure of the system‚Äîwhat the
parts are, and how they relate to one another‚Äîdetermines the behaviour of the
system. But anyone can sketch out a (highly contestable) jumble of blobs and
arrows to describe whatever thing they‚Äôre interested in. What do we gain from
seeing things in this way?</p>

<p>This is where another key idea‚Äîand person‚Äîin cybernetics/systems thinking
comes in: Donella Meadows‚Äô<sup id="fnref:is-meadows-cybernetics" role="doc-noteref"><a href="#fn:is-meadows-cybernetics" class="footnote" rel="footnote">2</a></sup> <a href="https://donellameadows.org/archives/leverage-points-places-to-intervene-in-a-system/">Leverage Points: Places to
Intervene in a
System</a>.
The key idea is this: once you‚Äôve mapped out your system, you need to know where
the most effective ‚Äúintervention points‚Äù to try and implement change? If you‚Äôre
going to expend energy to make things better, where should you focus that energy
to get the most <em>leverage</em>?</p>

<p>In the livecoder-in-the-club system, to make changes to the system in service of
the the goal (as stated above) of creating maximum good vibes. One obvious
solution is to start the gig with a bigger reservoir of brain juice (either by
having a good night‚Äôs sleep, popping an adderall, or whatever). Or it could be
to start with a larger code reservoir by starting with a bunch of code
pre-written<sup id="fnref:blank-slate-code" role="doc-noteref"><a href="#fn:blank-slate-code" class="footnote" rel="footnote">3</a></sup>.</p>

<p>However, Meadows‚Äô rules for leverage also suggest that some interventions
provide more leverage than others<sup id="fnref:different-interventions" role="doc-noteref"><a href="#fn:different-interventions" class="footnote" rel="footnote">4</a></sup>. For example,
changing the flow rates (leverage point #10) is likely to have more impact than
just changing the sizes of the stocks/buffers (leverage point #11). This implies
that changing the rate at which I turn brain juice into code (perhaps having a
nicer keyboard, perhaps having better code auto-completion support, or perhaps
just good-ol‚Äô <em>practice</em> to improve my coding skills) is likely to be more
impactful than starting with a bigger store of brain juice (so, thankfully,
there‚Äôs no need to buy shady adderall on the dark web). Will Larson (who has
been a software engineering leader at Calm, Stripe, Uber, and Digg) <a href="https://lethain.com/systems-thinking/">has some
interesting ideas on systems thinking as applied to software
development</a> that I‚Äôm keen to think more
about as well.</p>

<p>For even greater leverage, there are interventions which are related to
restructuring the system itself, for example adding new information flows
(leverage point #6). The dancers can already see the code, but what if I was
hooked up to a live <a href="https://en.wikipedia.org/wiki/Electroencephalography">EEG</a>
so they could see the current state of my brain juice?<sup id="fnref:eeg" role="doc-noteref"><a href="#fn:eeg" class="footnote" rel="footnote">5</a></sup>. And even higher up (in
terms of leverage) is changing the goals of the system itself (leverage point
#3). Why <em>do</em> people come to a club to dance and have good vibes? What if their
goal was different?</p>

<p>Now, the thing about leverage is that it doesn‚Äôt guarantee good or bad outcomes,
it just means you for a small amount of input you see a large effect in the
output. Figuring out where to intervene in the livecoder-in-the-club system is
one thing, figuring out how to intervene so that the changes are positive is a
deep challenge. Leverage means that when things go well they go really well, but
the opposite is also true (e.g. with margin calls in a bear market). I feel like
this is an especially apposite point for programmers, because the cheap leverage
afforded by software is catnip for programmers, but presents some real dangers.
(as <a href="https://idlewords.com/talks/sase_panel.htm">as Maciej Ceg≈Çowski puts so
eloquently</a>).</p>

<h2 id="so-whats-the-point">So what‚Äôs the point?</h2>

<p>Obviously the livecoder-in-the-club system described above is an
oversimplification; it makes certain things easy to see but renders other things
invisible, and every aspect of both the components (the things it talks about)
and their relationships (the connections between them) is contestable. But
that‚Äôs one of the benefits by laying things out like this‚Äîwe can at least see
the things that we‚Äôre explicitly considering, and we may well need to add new
things to the model for consideration (and examine all the new connections and
potential feedback loops those new things create).</p>

<p>My main goal here is really just to provide a worked example of how ideas from
cybernetics and systems thinking can help us move beyond just describing things
to figuring out where to place our energies to effect change‚Äîwhere we‚Äôll get
the most leverage. Being the best livecoder I can be is a lifetime goal, just
like any other instrumental or artistic practice. I‚Äôm keen to keep using the
tools of cybernetics to push in that direction, and bring the assemblage of
dancing bodies of the livecoder-in-the-club system with me for the ride :)</p>

<h2 id="meadows-12-places-to-intervene">Appendix: Meadows‚Äô <em>12 Places to Intervene in a System</em></h2>

<p class="hl-para">Note: these are taken straight from the <a href="https://donellameadows.org/archives/leverage-points-places-to-intervene-in-a-system/">Donella Meadows foundation
website</a>.</p>

<p><em>(lower numbers = less effective, higher numbers = more effective)</em></p>

<ol reversed="">

<li>Constants, parameters, numbers (such as subsidies, taxes, standards).</li>

<li>The sizes of buffers and other stabilizing stocks, relative to their flows.</li>

<li>The structure of material stocks and flows (such as transport networks, population age structures).</li>

<li>The lengths of delays, relative to the rate of system change.</li>

<li>The strength of negative feedback loops, relative to the impacts they are trying to correct against.</li>

<li>The gain around driving positive feedback loops.</li>

<li>The structure of information flows (who does and does not have access to information).</li>

<li>The rules of the system (such as incentives, punishments, constraints).</li>

<li>The power to add, change, evolve, or self-organize system structure.</li>

<li>The goals of the system.</li>

<li>The mindset or paradigm out of which the system ‚Äî its goals, structure, rules, delays, parameters ‚Äî arises.</li>

<li>The power to transcend paradigms.</li>

</ol>

<h2 id="footnotes">Footnotes</h2>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:niche" role="doc-endnote">

      <p>It‚Äôs a pretty niche activity, but there‚Äôs an <a href="https://toplap.org">international
community</a> of us, and if you‚Äôre interested then you can
<a href="https://twitter.com/benswift">follow me on twitter</a> to hear about upcoming
gigs.¬†<a href="#fnref:niche" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:is-meadows-cybernetics" role="doc-endnote">

      <p><a href="https://donellameadows.org/archives/leverage-points-places-to-intervene-in-a-system/">Donella
Meadows</a>
tended to prefer terms like ‚Äúsystems thinking‚Äù and ‚Äúsystems change‚Äù rather
than using the term ‚Äúcybernetics‚Äù directly, but she certainly was involved
with some of the key people &amp; events in the cybernetics story, and her work
is highly relevant to cybernetic ideas. Plus, <a href="https://books.google.com.au/books/about/Thinking_in_Systems.html?id=leE8R9pehg4C&amp;redir_esc=y">Google Books categorises her
work under <em>Computers &gt;
Cybernetics</em></a>,
and you <em>know</em> the Big G is never wrong about that stuff.¬†<a href="#fnref:is-meadows-cybernetics" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:blank-slate-code" role="doc-endnote">

      <p>This is actually a subtle point in livecoding. I (along with some other
livecoders) am committed to starting each gig ‚Äúfrom scratch‚Äù with a blank
code page. However, I‚Äôve written a lot of library code ahead of time to
provide me with nice abstractions for making music with code, and I use that
(hidden‚Äînot on the screen) from the very first line of code that I write.
Thinking about the livecoder-in-the-club system one question that I‚Äôm
pondering is whether that library code constitutes a larger stock of code,
or whether it‚Äôs a restructuring (an increase) of the flow rate from code
into music, or both.</p>

      <p>To make things even more complicated, and there‚Äôs <em>kindof</em> a blurry line
between where the code ends and the music begins in livecoding (i.e. there‚Äôs
the code you see on the screen, which is the code that I‚Äôm writing &amp;
executing ‚Äúlive‚Äù, but there‚Äôs also a bunch of pre-written code in my
operating system‚Äôs audio plumbing just to get the music to come out of the
speakers properly).¬†<a href="#fnref:blank-slate-code" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:different-interventions" role="doc-endnote">

      <p>There‚Äôs not enough room in this blog post for a full ‚Äúsystems change
analysis‚Äù of the livecoder-in-the-club system according to all 12 leverage
points, but if you‚Äôre interested I do recommend you <a href="https://donellameadows.org/archives/leverage-points-places-to-intervene-in-a-system/">check out that
article</a>
as a starting point.¬†<a href="#fnref:different-interventions" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:eeg" role="doc-endnote">

      <p>Coming up with a reliable, portable EEG machine which can measure a useful
biometric signal which corresponds to an individual‚Äôs perceived current
level of brain juice is beyond the scope of this blog post.¬†<a href="#fnref:eeg" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Ben Swift</name></author><category term="cybernetics" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">Cutting ruby CI pipeline times with pre-installed bundles</title><link href="https://benswift.me/blog/2021/10/21/cutting-ruby-ci-pipeline-times-with-pre-installed-bundles/" rel="alternate" type="text/html" title="Cutting ruby CI pipeline times with pre-installed bundles" /><published>2021-10-21T00:00:00+11:00</published><updated>2021-10-21T00:00:00+11:00</updated><id>https://benswift.me/blog/2021/10/21/cutting-ruby-ci-pipeline-times-with-pre-installed-bundles</id><content type="html" xml:base="https://benswift.me/blog/2021/10/21/cutting-ruby-ci-pipeline-times-with-pre-installed-bundles/"><![CDATA[<p>I (and, increasingly many of my colleagues) are using
<a href="https://jekyllrb.com">Jekyll</a> to create open (CC-licenced), hackable, acessible
course websites &amp; teaching content for our classes. We use a self-hosted GitLab
server for all the websites sources, and then build/deploy them with <a href="https://docs.gitlab.com/ee/ci/">GitLab
CI</a>. It works well, it means I don‚Äôt have to
fight with our LMS to do interesting things, and it means I can open my learning
materials to everyone (not just those who are privileged enough to be able to
pay the fees to study at the ANU).</p>

<p>The <code>jekyll build</code> step runs in a container, and for a long time we‚Äôve just used
the <a href="https://hub.docker.com/_/ruby/">official ruby image</a> as a starting point,
then done a <code>bundle install</code> inside the container before running the build step
to get all the deps. However, this means the deps are <em>installed from scratch on
every deploy</em>, which isn‚Äôt the greenest (although ANU is <a href="https://www.anu.edu.au/research/research-initiatives/anu-below-zero">heading in a good
direction on net
zero</a>) and
it also means the feedback loop from push-&gt;deployed site is much longer than it
needs to be.</p>

<p>Yesterday (prompted by the understandable frustrations of my colleague
<a href="https://charlesmartin.com.au">Charles</a> about the build times) I spent some time
fixing things. I ended up creating a new docker image with the required gems
pre-installed, and it <strong>cut our CI pipeline times by up to 90%</strong> (i.e. a 10x
speedup).</p>

<p>There were a couple of tricky parts, so I include some commentary here in case
anyone else (including future me when if I forget how this works) wants to do
similar things.</p>

<pre><code class="language-Dockerfile"># Choose and name our temporary image.
FROM ruby:3.0.2 as builder

WORKDIR /app

# Take an SSH key as a build argument.
ARG SSH_PRIVATE_KEY

# required to pull from the (private) theme gem repos
# create the SSH directory.
RUN mkdir -p ~/.ssh/ &amp;&amp; \
  # populate the private key file.
  echo "$SSH_PRIVATE_KEY" &gt; ~/.ssh/id_rsa &amp;&amp; \
  # set the required permissions.
  chmod -R 600 ~/.ssh/ &amp;&amp; \
  # add our GitLab server to our list of known hosts for ssh.
  ssh-keyscan -t rsa gitlab.anu.edu.au &gt;&gt; ~/.ssh/known_hosts

# install the deps - this is really just for "caching", the expectation is that
# the CI job will re-run `bundle install` to pick up any differences
COPY Gemfile Gemfile.lock* .
RUN bundle install

# Choose the base image for our final image
FROM ruby:3.0.2
WORKDIR /app

# Copy across the files from our `builder` container
# this really assumes the same base container
COPY --from=builder $BUNDLE_APP_CONFIG $BUNDLE_APP_CONFIG
</code></pre>

<p>The main tricky bit is the ssh setup, because some of the (in-house) gems are
only available in git repos which require authentication. This Dockerfile pulls
in the SSH key from an environment variable, then uses it to <code>bundle install</code>
the required gems. Then, the key part is that there‚Äôs a second <code>FROM</code> command to
create a new image (sans any trace of the SSH key) and only the installed gems
are copied across.</p>

<p>To build the container, you need to do something like</p>

<pre><code class="language-shell">MY_KEY=$(cat gitlab-ci-runner-key)
docker build --build-arg SSH_PRIVATE_KEY="$MY_KEY" --tag YOUR_TAG_NAME .
</code></pre>

<p>A couple of caveats with this approach: the container just caches the gems; the
<code>bundle install</code> step will still (probably) need to run in the CI pipeline, but
it‚Äôll be a no-op if <code>Gemfile.lock</code> hasn‚Äôt changed. You‚Äôll never be worse off
(time-wise) than if you‚Äôre installing from scratch, because only the deps which
have changed in the lock file will be downloaded. But over time, the container
may take longer to run as the list of pre-installed vs actually required
packages diverges.</p>

<p class="hl-para">I did try a similar approach that used <code>bundle cache</code> to pull all the deps into
a <code>vendor/cache</code> folder and then copy <em>that</em> across into the new image, but I
had weird permissions errors that I didn‚Äôt have the time to figure out. If
you‚Äôve got tips on whether that‚Äôs a more ‚Äúbundler-y‚Äù way to do things then <a href="mailto:ben@benswift.me">hit
me up</a>.</p>

<p>I want to give a shoutout to Jan Akerman who wrote <a href="https://janakerman.co.uk/docker-git-clone/">a helpful blog
post</a> which got me started‚Äîand
some of the Dockerfile is taken from that post.</p>]]></content><author><name>Ben Swift</name></author><category term="tools" /><category term="web" /><summary type="html"><![CDATA[I (and, increasingly many of my colleagues) are using Jekyll to create open (CC-licenced), hackable, acessible course websites &amp; teaching content for our classes. We use a self-hosted GitLab server for all the websites sources, and then build/deploy them with GitLab CI. It works well, it means I don‚Äôt have to fight with our LMS to do interesting things, and it means I can open my learning materials to everyone (not just those who are privileged enough to be able to pay the fees to study at the ANU).]]></summary></entry></feed>