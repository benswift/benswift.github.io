<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="https://benswift.me/feed.xml" rel="self" type="application/atom+xml" /><link href="https://benswift.me/" rel="alternate" type="text/html" /><updated>2023-02-06T13:46:16+11:00</updated><id>https://benswift.me/feed.xml</id><title type="html">benswift.me</title><subtitle>livecoder &amp; researcher homepage - code, creativity, culture</subtitle><author><name>Ben Swift</name></author><entry><title type="html">Academic integrity policy re: ChatGPT and generative AI tools</title><link href="https://benswift.me/blog/2023/02/02/academic-integrity-policy-re-chatgpt-and-generative-ai-tools/" rel="alternate" type="text/html" title="Academic integrity policy re: ChatGPT and generative AI tools" /><published>2023-02-02T00:00:00+11:00</published><updated>2023-02-02T00:00:00+11:00</updated><id>https://benswift.me/blog/2023/02/02/academic-integrity-policy-re-chatgpt-and-generative-ai-tools</id><content type="html" xml:base="https://benswift.me/blog/2023/02/02/academic-integrity-policy-re-chatgpt-and-generative-ai-tools/"><![CDATA[<p>Here in Australia Semester 1 is approaching and
<a href="https://chat.openai.com">ChatGPT</a> is, undoubtedly, <em>a thing</em>. From a practical
perspective it’s important to have some​ sort of policy about about ChatGPT and
other generative AI tools in the classroom (<a href="https://twitter.com/dbkahn/status/1616494433587040257">everyone’s doing
it</a>). If you don’t have
an explicit policy you’ll end up making your policy up as you go along (because
it <em>will</em> come up) and <a href="https://www.youtube.com/watch?v=7XeQin9abx4">policy on the run is policy
underdone</a>.</p>

<p>In terms of the opportunities to incorporate, explore and critique new tools in
the classroom, I’m actually kindof excited. <a href="https://www.timeshighereducation.com/campus/so-you-want-use-chatgpt-classroom-semester">I’ve written elsewhere about how
you might be able to do
this</a>.
The <em>tl;dr</em> is that you should look at your class activities (including
assessment items) and try and actually <em>do</em> them with ChatGPT, just to see how
it goes. OpenAI have also just released some stuff about <a href="https://platform.openai.com/docs/chatgpt-education">considerations for
educators</a>.</p>

<p class="hl-para">At this stage these are just my own personal thoughts as a teaching academic;
I’m not wearing my <a href="https://cybernetics.anu.edu.au/people/ben-swift/">Associate Director
(Education)</a> hat here, and
<strong>this is not an official (or unofficial) ANU School of Cybernetics policy</strong>. If
you’re also putting together a policy for your classroom, then
questions/comments/suggesions are welcome—do <a href="mailto:ben.swift@anu.edu.au">get in
touch</a>.</p>

<p>Here are my current thoughts what a good <em>use of ChatGPT in the classroom</em>
policy might look like. Because it’s not a proper policy it doesn’t have
everything precisely defined, but it gives you an idea of how I want to run my
classes.</p>

<ol>
  <li>
    <p>Unless otherwise specified, you <strong>are</strong> allowed to use
ChatGPT<sup id="fnref:other-similar-tools" role="doc-noteref"><a href="#fn:other-similar-tools" class="footnote" rel="footnote">1</a></sup> in this class, including in work submitted for
assessment.</p>
  </li>
  <li>
    <p>Wherever ChatGPT is used it must be cited according according to the <a href="https://platform.openai.com/docs/chatgpt-education/disclosing-the-use-of-chatgpt">OpenAI
citation
instructions</a></p>
  </li>
  <li>
    <p>You are responsible for everything you submit. “It’s not my fault—the AI
generated text introduced non-sequiturs/errors/plagiarised text/offensive
language” will never get you off the hook; if it’s in your submission you’re
responsible for it just as you would be if you’d written it without ChatGPT.</p>
  </li>
  <li>
    <p>You are expected to be able to explain (to your tutor, lecturer of course
convenor) any assessment submission to demonstrate your understanding of the
concepts being assessed.</p>
  </li>
  <li>
    <p>Any violations of the above will be considered a potential breach of academic
integrity under clause 9 of section 12(2) of the <a href="#appendix-anu-academic-integrity-rule">ANU Academic Integrity
Rule</a> “improperly recycles work or
otherwise improperly submits or publishes work that is not original”
(<strong>note</strong>: I’m unsure on which clause is best to use here—could be clause
8, could be one of the others as well).</p>
  </li>
  <li>
    <p>No “is-this-written-by-an-AI?”​ detection tools (e.g.
<a href="https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text/">this</a>)
will be used as part of the marking process.</p>
  </li>
</ol>

<p>One open question (not necessarily part of the student-facing policy, but
relevant for anyone running a course) is what guidance should be given to the
markers (e.g. tutors/TAs) on what to do with ChatGPT-generated content. Should
submissions (or parts thereof) created with the help of ChatGPT be marked lower
than “equivalent standard” submissions that aren’t?</p>

<p>Anyway, these are just some draft thoughts—I’ll keep this post updated as my
thinking changes.</p>

<h2 id="appendix-anu-academic-integrity-rule">Appendix: ANU Academic Integrity Rule</h2>

<p>From the <a href="https://www.legislation.gov.au/Details/F2021L00997/Html/Text#_Toc73961519">ANU Academic Integrity Rule
2021</a>
Section 12 (2), here’s the list of what constitutes a breach of the academic
integrity principle.</p>

<style>
#academic-integrity-definitions ol {list-style-type: lower-alpha;}
#academic-integrity-definitions ol ol {list-style-type: lower-roman;}
</style>

<div id="academic-integrity-definitions">

  <blockquote>
    <p>(2) For this instrument, a student breaches the academic integrity principle if, in scholarly practice, the student:</p>
    <ol>
      <li>cheats; or</li>
      <li>impersonates another person; or</li>
      <li>engages in plagiarism; or</li>
      <li>colludes with another person; or</li>
      <li>improperly shares material with another person; or</li>
      <li>engages in contract cheating or improperly engages another person to prepare, or assist in preparing, work for the student; or</li>
      <li>submits or publishes anything that fails to correctly or appropriately acknowledge the work of another person or otherwise improperly appropriates the intellectual property or contribution of another person; or</li>
      <li>otherwise passes off the work of another person as the student’s own work; or</li>
      <li>improperly recycles work or otherwise improperly submits or publishes work that is not original; or</li>
      <li>takes a prohibited item into an examination or other assessment venue or otherwise breaches the University’s directions (however described) in relation to an examination or other assessment; or</li>
      <li>fabricates or falsifies any document, data or other information, or anything else, including, for example, by intentionally omitting data to obtain a desired result, or by falsely representing observations as genuinely held; or</li>
      <li>otherwise intentionally or recklessly engages in conduct:
        <ol>
          <li>that impedes the progress of research; or</li>
          <li>that risks corrupting research records or compromising the integrity of research practices; or</li>
          <li>that uses research data from another person without appropriate acknowledgement; or</li>
          <li>that breaches a research protocol approved by a research ethics committee or a statutory licence condition applying to research; or</li>
        </ol>
      </li>
      <li>otherwise engages in conduct with the intention of gaining, or assisting another person to gain, an unethical, dishonest, unfair or unjustified advantage; or</li>
      <li>otherwise engages in conduct, or assists another person to engage in conduct, that is unethical, dishonest or unfair; or</li>
      <li>engages in any other conduct declared to be academic misconduct by the orders.</li>
    </ol>
  </blockquote>

  <p>My commentary on the above (and IANAL) is that none of those points really
capture the specific case of “ChatGPT wrote this essay, not the student”, in
particular because so many of the definitions reference “of another <em>person</em>”.
I’m sure this language will be updated in the future in light of the widespread
availability of generative AI tools.</p>
</div>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:other-similar-tools" role="doc-endnote">

      <p>Wherever ChatGPT is named in this policy it should be read as “ChatGPT and
other generative AI tools”, where those tools are defined according to
(ERROR: definition not found). <a href="#fnref:other-similar-tools" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Ben Swift</name></author><category term="teaching" /><category term="ai" /><summary type="html"><![CDATA[Here in Australia Semester 1 is approaching and ChatGPT is, undoubtedly, a thing. From a practical perspective it’s important to have some​ sort of policy about about ChatGPT and other generative AI tools in the classroom (everyone’s doing it). If you don’t have an explicit policy you’ll end up making your policy up as you go along (because it will come up) and policy on the run is policy underdone.]]></summary></entry><entry><title type="html">Jekyll build speedups for Ruby 3.2</title><link href="https://benswift.me/blog/2023/02/02/jekyll-build-speedups-for-ruby-3-2/" rel="alternate" type="text/html" title="Jekyll build speedups for Ruby 3.2" /><published>2023-02-02T00:00:00+11:00</published><updated>2023-02-02T00:00:00+11:00</updated><id>https://benswift.me/blog/2023/02/02/jekyll-build-speedups-for-ruby-3-2</id><content type="html" xml:base="https://benswift.me/blog/2023/02/02/jekyll-build-speedups-for-ruby-3-2/"><![CDATA[<p>There’s a <a href="https://news.ycombinator.com/item?id=34413012">bunch of buzz</a> about
Ruby’s new YJIT in v3.2.0. I have to develop and maintain a bunch of Jekyll
websites for work, some of which are getting into “non-trivial build time”
territory (or maybe I’m really easily distracted, but a 30s build is enough for
me to break my flow).</p>

<p>Here’s some very unscientifc benchmarks from my <a href="https://jekyllrb.com">Jekyll</a>
(v4.3) builds on my M1 Max MBP (64GB).</p>

<h2 id="ruby-312p20-2022-04-12-revision-4491bb740a-arm64-darwin21">ruby 3.1.2p20 (2022-04-12 revision 4491bb740a) [arm64-darwin21]</h2>

<p>First, this is the previous version of Ruby, which I’ve been happily working
with for ages.</p>

<pre><code>bundle exec jekyll build
</code></pre>

<p>Averaged over 3 runs, the build time was 17.7 (±0.8) seconds.</p>

<h2 id="ruby-320-2022-12-25-revision-a528908271-arm64-darwin22">ruby 3.2.0 (2022-12-25 revision a528908271) [arm64-darwin22]</h2>

<p>After upgrading to the latest Ruby v3.2.0, the average over 3 runs was 17.2 (±0.2) seconds.</p>

<h2 id="ruby-320-2022-12-25-revision-a528908271-yjit-arm64-darwin22">ruby 3.2.0 (2022-12-25 revision a528908271) +YJIT [arm64-darwin22]</h2>

<p>I <a href="https://dev.to/dpaluy/install-ruby-320-yjit-with-asdf-b82">followed these
instructions</a> to
build a YJIT-enabled Ruby v3.2. Then, after re-installing all the deps:</p>

<pre><code>RUBY_YJIT_ENABLE=true bundle exec jekyll build
</code></pre>

<p>The build was <em>heaps</em> faster—the average over 3 runs was 3.7 (±0.2) seconds.
<strong>That’s a 4.8x speedup</strong>.</p>

<p>Obviously, like all benchmarks on the internet this one is wrong &amp; stupid and
you should do your own testing. Three runs probably isn’t enough to shake out
any cache effects, and I don’t know (but could guess?) that the JIT might have
even more pronounced cold start issues (although I didn’t really see it above).
Anyway, if you build a lot of Jekyll sites, my anecdotal evidence is that you
can save yourself a bunch of time, and tighten those feedback loops to stay in
the flow state. Have fun!</p>]]></content><author><name>Ben Swift</name></author><category term="web" /><category term="tools" /><summary type="html"><![CDATA[There’s a bunch of buzz about Ruby’s new YJIT in v3.2.0. I have to develop and maintain a bunch of Jekyll websites for work, some of which are getting into “non-trivial build time” territory (or maybe I’m really easily distracted, but a 30s build is enough for me to break my flow).]]></summary></entry><entry><title type="html">Congrats Dr. Kieran Browne</title><link href="https://benswift.me/blog/2023/01/26/congrats-dr-kieran-browne/" rel="alternate" type="text/html" title="Congrats Dr. Kieran Browne" /><published>2023-01-26T00:00:00+11:00</published><updated>2023-01-26T00:00:00+11:00</updated><id>https://benswift.me/blog/2023/01/26/congrats-dr-kieran-browne</id><content type="html" xml:base="https://benswift.me/blog/2023/01/26/congrats-dr-kieran-browne/"><![CDATA[<p>Last December <a href="https://kieranbrowne.com">Kieran</a> graduated—very exciting for
all concerned.</p>

<picture style="position: relative;">
  <img alt="Ben and Kieran in full academic dress at the ANU graduation ceremony in December 2022" src="/assets/images/posts/ben-kieran-phd-graduation.jpg" />

  
</picture>

<p>His thesis, <em>Neurological Metaphor in Deep Learning: Issues and Alternatives</em>,
is <a href="https://openresearch-repository.anu.edu.au/handle/1885/274243">available online through the ANU
Library</a>. It’s a
really interesting mix of insightful scholarship and practice-based design
interventions. In other words, he has interesting things to say <em>and</em> he built
interesting things (some of which are available online).</p>

<p>Here’s the abstract:</p>

<blockquote>
  <p>Representations of deep learning—discursive, historical and
diagrammatic—are structured by a neurological metaphor that overstates a
likeness to the brain and disguises other ways of understanding the
technology. These neurological representations muddle the crucial public
debate even as deep learning is applied in high-stakes applications,
particularly in institutions of social and political power. This thesis draws
on historical sources and contemporary literature to trace the development and
contemporary expression of the neurological metaphor in deep learning
discourse; particularly with respect to the field’s terminology, the telling
of its history, and the drawing of its diagrams. In the manuscript and in
three documented practice-based works, I propose alternative metaphors for
deep learning—divination, surveillance and memory—to highlight
sociotechnical concerns posed by the technology. As a highly interdisciplinary
project, this thesis applies a range of methods drawn variously from digital
humanities, discourse analysis, human-centred computing, visual arts and
design, and deep learning itself. The traditional scholarship and
practice-based aspects of the thesis are situated in contemporary debates of
AI bias and interpretability, and the role of deep learning in systems of
power.</p>
</blockquote>]]></content><author><name>Ben Swift</name></author><category term="research" /><category term="ai" /><summary type="html"><![CDATA[Last December Kieran graduated—very exciting for all concerned.]]></summary></entry><entry><title type="html">Handling Square Webhooks in Phoenix</title><link href="https://benswift.me/blog/2023/01/22/handling-square-webhooks-in-phoenix/" rel="alternate" type="text/html" title="Handling Square Webhooks in Phoenix" /><published>2023-01-22T00:00:00+11:00</published><updated>2023-01-22T00:00:00+11:00</updated><id>https://benswift.me/blog/2023/01/22/handling-square-webhooks-in-phoenix</id><content type="html" xml:base="https://benswift.me/blog/2023/01/22/handling-square-webhooks-in-phoenix/"><![CDATA[<p>My <a href="https://the-riotact.com/hot-in-the-suburbs-little-luxton-serves-up-coffee-for-the-community/618459">brother’s
cafe</a>
donates a dollar to the local community centre for every coffee sold, and over
the summer I built
him a live “donation counter” which displays a small “thankyou” animation when
anyone buys a coffee. It’s a web app which they run on an iPad sitting on the
coffee machine.</p>

<p>Since the cafe uses Square for all payments, I was able to set up a
<a href="https://developer.squareup.com/docs/webhooks/overview">webhook</a> so the app
would receive the “new sale” notification ASAP—this should be both
lower-latency and more efficient than polling.</p>

<p>The app is basically a single <a href="https://www.phoenixframework.org">Phoenix
LiveView</a>. Sadly the Square guides don’t have
examples for Elixir, although it’s pretty easy to modify the e.g. <a href="https://developer.squareup.com/docs/webhooks/step3validate">Ruby
example</a> code to get
the job done. If you’re looking to do something similar I cobbled together this
info from docs (and a few blogs) and it might help you out to have it all in one
place.</p>

<h2 id="step-1-set-up-webhook-controller-including-validation">Step 1: set up webhook controller (including validation)</h2>

<p>It’s important to validate that any incoming webhook is actually from Square, so
Square send a special <code>x-square-hmacsha256-signature</code> header for <a href="https://developer.squareup.com/docs/webhooks/step3validate">validation
purposes</a>, although
performing this validation step requires having access to the raw request body.
Thankfully, the <a href="https://hexdocs.pm/plug/Plug.Parsers.html#module-custom-body-reader">“Custom Body Reader” section in the <code>Plug.Parsers</code>
docs</a> shows
how to do exactly that—just follow the instructions there.</p>

<h2 id="step-2-create-webhook-controller-including-validation">Step 2: create webhook controller (including validation)</h2>

<p>The webhook controller module should look something like this (replace the
<code>notification_url</code> and <code>signature_key</code> with the right values for your
app—you’ll get your signature key from Square when you register the webhook):</p>

<pre><code class="language-elixir">defmodule MyAppWeb.SquareWebhookController do
  @moduledoc """
  Handle webhooks sent from Square.
  """
  use MyAppWeb, :controller

  @doc "handle the webhook request"
  def webhook(conn, params) do
    if is_from_square?(conn) do
      do_stuff(params)
    end

    send_response(conn)
  end

  @doc "respond to the Square server (always 200 OK otherwise they'll freak out)"
  defp send_response(conn) do
    conn
    |&gt; put_resp_content_type("text/plain")
    |&gt; send_resp(200, "webhook received - thanks.")
  end

  @doc "returns `true` if webhook came from Square, `false` otherwise"
  defp is_from_square?(conn) do
    notification_url = "http://example.com/square/webhook"
    signature_key = "WEBHOOK_SIGNATURE_KEY_FROM_SQUARE"
    {_, signature} = List.keyfind!(conn.req_headers, "x-square-hmacsha256-signature", 0)

    ## here's where we access the raw request body we put there in the Plug.Parser
    raw_body = Enum.join(conn.assigns.raw_body)

    hash =
      :crypto.mac(:hmac, :sha256, signature_key, notification_url &lt;&gt; raw_body)
      |&gt; Base.encode64()

    signature == hash
  end
end
</code></pre>

<h2 id="step-3-add-the-endpoint-to-your-router">Step 3: add the endpoint to your router</h2>

<p>Finally, add it to to your <code>router.ex</code> - something like this, you know the
drill.</p>

<pre><code class="language-elixir">scope "/square", MyAppWeb do
  pipe_through :api

  post "/webhook", SquareWebhookController, :webhook
end
</code></pre>

<h2 id="step-4-subscribe-to-the-webhook">Step 4: subscribe to the webhook</h2>

<p>After that’s all done (and you’ve deployed your app) you’re ready to <a href="https://developer.squareup.com/docs/webhooks/overview">set up a
webhook subscription</a>.
Follow the Square docs and Square will start hitting your (deployed) app’s
<code>https://example.com/square/webhook</code> endpoint, and your app can do its thing.</p>

<p class="hl-para">Note that these incoming webhook requests <em>won’t</em> hit your local development
server running on <code>localhost</code>, so testing webhooks is a bit trickier. Since my
app runs on <a href="https://fly.io">fly</a> it involved a little bit of <code>IO.inspect</code>ing in
production and then looking at the logs with <code>flyctl logs</code>.</p>

<p>Have fun! And if you live in Canberra, especially in Tuggeranong/Lanyon, maybe
go buy a coffee from <a href="https://www.littleluxton.com">Little Luxton</a> and you can
see it for yourself 😊</p>]]></content><author><name>Ben Swift</name></author><category term="web" /><category term="elixir" /><category term="phoenix" /><summary type="html"><![CDATA[My brother’s cafe donates a dollar to the local community centre for every coffee sold, and over the summer I built him a live “donation counter” which displays a small “thankyou” animation when anyone buys a coffee. It’s a web app which they run on an iPad sitting on the coffee machine.]]></summary></entry><entry><title type="html">rclone: exclude all git repos</title><link href="https://benswift.me/blog/2023/01/11/rclone-exclude-all-git-repos/" rel="alternate" type="text/html" title="rclone: exclude all git repos" /><published>2023-01-11T00:00:00+11:00</published><updated>2023-01-11T00:00:00+11:00</updated><id>https://benswift.me/blog/2023/01/11/rclone-exclude-all-git-repos</id><content type="html" xml:base="https://benswift.me/blog/2023/01/11/rclone-exclude-all-git-repos/"><![CDATA[<p>For a long time I’ve used <a href="https://rclone.org">rclone</a> for remote backups and
it’s awesome. I have a script which syncs all the files I care about on my
laptop to cloudstor (which, being on the Australian university network has the
benefit that I get 1Gbps upload when I’m on the ANU network). My institution
(the ANU)</p>

<p>However, it turns out that
<a href="https://support.aarnet.edu.au/hc/en-us/articles/5697089309711">cloudstor</a> is
shutting down at the end of this year, so I need to find a new home for my
backups. I’ve been told that the “replacement” is to use my institutional
OneDrive account.</p>

<p>My feelings about closing down useful (local) infrastructure and centralising
things on one of the big cloud providers notwithstanding, this should be an easy
change—<a href="https://rclone.org/onedrive/">rclone supports OneDrive</a>, so it’s a
simple config change to move over.</p>

<p>However, I figured I’d take the opportunity to fix something which had long
bothered me. I have a <em>lot</em> of stuff in git repos which don’t need to be backed
up with rclone, and they just slow down the backup process. I wanted to get
rclone to ignore all git repos, and although it has an <a href="https://rclone.org/filtering/">include/exclude
filtering</a> system it’s not easy to get it to
filter all git repos (trust me, <a href="https://forum.rclone.org/t/ignore-all-git-repos-when-syncing/33023">I
checked</a>).</p>

<p>Now that it’s summertime I had a chance to make it work, and since that forum
thread is now locked I’m posting it here to save you some time, dear reader, if
you ever want to do this for yourself. Feel free to use/modify it (MIT Licence)
if it’s helpful.</p>

<pre><code class="language-bash">#!/bin/bash

EXCLUDE_FROM_FILE="/tmp/rclone-excludes.txt"
CLONE_ROOT_DIR=~/Documents
REMOTE=anu-onedrive

## find all git repo enclosing folders (including trailing slash), munge them
## into the form that rclone expects for its "exclude from" file
cd $CLONE_ROOT_DIR &amp;&amp; find . -type d -name .git -exec  dirname {} \; | sed -e 's/$/\//' -e 's/^.//' &gt; $EXCLUDE_FROM_FILE

## add a few extra excludes
echo ".DS_Store" &gt;&gt; $EXCLUDE_FROM_FILE

## sync to remote
rclone sync --progress --exclude-from=$EXCLUDE_FROM_FILE $CLONE_ROOT_DIR $REMOTE:mitch-rclone/$CLONE_ROOT_DIR
</code></pre>]]></content><author><name>Ben Swift</name></author><category term="tools" /><summary type="html"><![CDATA[For a long time I’ve used rclone for remote backups and it’s awesome. I have a script which syncs all the files I care about on my laptop to cloudstor (which, being on the Australian university network has the benefit that I get 1Gbps upload when I’m on the ANU network). My institution (the ANU)]]></summary></entry><entry><title type="html">A School of Cybernetics strategy meeting with ChatGPT</title><link href="https://benswift.me/blog/2022/12/07/a-school-of-cybernetics-strategy-meeting-with-chatgpt/" rel="alternate" type="text/html" title="A School of Cybernetics strategy meeting with ChatGPT" /><published>2022-12-07T00:00:00+11:00</published><updated>2022-12-07T00:00:00+11:00</updated><id>https://benswift.me/blog/2022/12/07/a-school-of-cybernetics-strategy-meeting-with-chatgpt</id><content type="html" xml:base="https://benswift.me/blog/2022/12/07/a-school-of-cybernetics-strategy-meeting-with-chatgpt/"><![CDATA[<p>Back at my desk after a couple of days off I finally got a chance to fire up the
<a href="https://chat.openai.com">OpenAI ChatGPT</a> AI language model that everyone’s
talking about.</p>

<p>Here’s—and this is the honest truth—the first conversation I had with it.
The initial paragraph was from the <a href="https://cybernetics.anu.edu.au/about/">ANU School of Cybernetics
website</a>, and from there we just
freewheeled. My inputs are in regular type, the ChatGPT responses are in the
coloured boxes.</p>

<hr />

<p><em>begin chat transcript</em></p>

<p>The 3A Institute sits within the School of Cybernetics with the mission to build
a new branch of engineering to take AI-enabled cyber-physical systems to scale
and to create a new generation of practitioners with the skills and knowledge we
need to help shape this future safely, sustainably and responsibly.</p>

<p>As people invent, commercialise and operationalise new technologies, new
practitioners emerge to manage them. Just as the invention of programmable
computers led to the professionalisation of software engineers, cyber-physical
systems will lead to a new type of engineer.</p>

<p>We don’t know what this new type of engineering will be called yet, but we know
we need it if we are to build a safe, sustainable and responsible future.</p>

<p>Give 5 concrete examples of how ideas from cybernetics can help:</p>

<div class="hl-para">

  <ol>
    <li>Cybernetics can help with the design and optimization of complex systems,
such as transportation networks or power grids, by using feedback loops and
control systems to ensure efficient and reliable operation.</li>
    <li>Cybernetic principles can be applied to the development of intelligent
machines and autonomous systems, enabling them to learn from their
environment and adapt to changing conditions.</li>
    <li>Cybernetics can be used to improve human-machine interactions, such as
through the design of user-friendly interfaces or the integration of wearable
technologies that enhance our physical abilities.</li>
    <li>Cybernetic concepts can be applied to the study of biological systems, such
as the nervous system, to gain a better understanding of how they function
and how they can be treated or improved.</li>
    <li>Cybernetics can be used to address societal challenges, such as promoting
sustainable development or addressing inequality, by providing a framework
for analyzing and addressing complex systems-level problems.</li>
  </ol>

</div>

<p>Can you try again, but this time using the 19th Century Australian Overland Telegraph as a framing device?</p>

<div class="hl-para">

  <p>Sure, here are five examples of how ideas from cybernetics can help using the
19th Century Australian Overland Telegraph as a framing device:</p>

  <ol>
    <li>The Overland Telegraph relied on a complex network of telegraph lines,
stations, and operators to transmit messages across the vast Australian
continent. Cybernetics can help optimize the design and operation of such
networks by using feedback loops and control systems to ensure efficient and
reliable communication.</li>
    <li>The Overland Telegraph used complex coding systems to encode and decode
messages, and cybernetic principles can be applied to the development of
intelligent machines and algorithms that can learn and adapt to improve the
efficiency and accuracy of such coding systems.</li>
    <li>The Overland Telegraph required skilled operators to manage the transmission
and receipt of messages, and cybernetics can be used to improve human-machine
interactions through the design of user-friendly interfaces and tools that
enable operators to work more efficiently and effectively.</li>
    <li>The Overland Telegraph relied on a network of towers and poles to support the
telegraph lines, and cybernetic concepts can be applied to the study of such
infrastructure to optimize its design and maintenance for long-term
reliability and durability.</li>
    <li>The Overland Telegraph played a crucial role in connecting remote parts of
Australia and facilitating economic and social development, and cybernetics
can be used to address societal challenges by providing a framework for
analyzing and addressing complex systems-level problems and developing
solutions that promote sustainable and equitable growth.</li>
  </ol>

</div>

<p>Ok, that’s better—I think it’s important that we provide a uniquely Australian
viewpoint on what cybernetics is and how it can help tackle the challenges we
face in the 21st century. As a new School of Cybernetics, then, what should our
top priorities be?</p>

<div class="hl-para">

  <p>As a new School of Cybernetics, some top priorities could include:</p>

  <ol>
    <li>Developing a strong research program focused on applying cybernetic
principles to real-world challenges facing Australia, such as improving the
resilience and sustainability of critical infrastructure, enhancing the
security and privacy of digital systems, or addressing complex societal
issues such as inequality and climate change.</li>
    <li>Providing high-quality education and training programs that enable students
to gain a deep understanding of cybernetic concepts and techniques, and
develop the skills and knowledge needed to become leaders in the field.</li>
    <li>Building partnerships and collaborations with other academic institutions,
industry partners, and government agencies to facilitate the exchange of
ideas, knowledge, and expertise, and to support the development and
implementation of innovative cybernetic solutions.</li>
    <li>Playing a key role in promoting public awareness and understanding of
cybernetics, and addressing common misconceptions and concerns about the
field, in order to foster a positive and informed dialogue about its
potential benefits and limitations.</li>
    <li>Establishing a strong and supportive community of scholars, practitioners,
and stakeholders within the field of cybernetics, and providing opportunities
for networking, collaboration, and professional development.</li>
  </ol>

</div>

<p><em>end chat transcript</em></p>

<hr />

<p>Well, wow. This required no re-prompting or editing on my part.</p>

<p>I should say that I share all of the skepticism (and fears!) of folks who are
pointing out that these language models don’t actually understand things. In
some cases this means the output of these models is benign but incorrect, and
it’s easy to think of situations where real harm could be caused.</p>

<p>Upon close reading, I don’t think the above responses capture the full breadth
of what we’re trying to do here in the School of Cybernetics. But I’d be lying
if I wasn’t impressed.</p>

<p>As I <a href="https://twitter.com/benswift/status/1600265214338867200">tweeted earlier this
morning</a>:</p>

<blockquote>
  <p>all this ChatGPT stuff means that we as a society are gonna have to get a
<strong>lot</strong> better at drinking from the bullshit firehose, and fast</p>
</blockquote>

<p>I’ll pen some more thoughts about what it all means when I’ve had some more time
to digest things.</p>]]></content><author><name>Ben Swift</name></author><category term="ai" /><category term="cybernetics" /><summary type="html"><![CDATA[Back at my desk after a couple of days off I finally got a chance to fire up the OpenAI ChatGPT AI language model that everyone’s talking about.]]></summary></entry><entry><title type="html">AI art installations and livecoding gigs in Nov/Dec</title><link href="https://benswift.me/blog/2022/12/06/ai-art-installations-and-livecoding-gigs-in-nov-dec/" rel="alternate" type="text/html" title="AI art installations and livecoding gigs in Nov/Dec" /><published>2022-12-06T00:00:00+11:00</published><updated>2022-12-06T00:00:00+11:00</updated><id>https://benswift.me/blog/2022/12/06/ai-art-installations-and-livecoding-gigs-in-nov-dec</id><content type="html" xml:base="https://benswift.me/blog/2022/12/06/ai-art-installations-and-livecoding-gigs-in-nov-dec/"><![CDATA[<p>If you <a href="https://twitter.com/benswift">follow me on twitter</a> you’ve seen this
already, but over the last couple of months I’ve been hard at work on an AI art
installation called Panic. This was a collaboration with <a href="https://cybernetics.anu.edu.au/people/adrian-schmidt/">Adrian
Schmidt</a>—I did the
software, he did the hardware (including the cool, 6” diameter <em>Panic!</em> button).</p>

<div style="width:100%; margin: 0px auto; margin-bottom: 1rem;">
  <div style="position: relative; padding-bottom: 62.5%; height: 0px;">
	<iframe style="position: absolute; top: 0px; left: 0px; width: 100%; height: 100%;" src="https://www.youtube.com/embed/wpOkUX_LmQo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="">
	</iframe>
  </div>
</div>

<p>I wrote <a href="https://cybernetics.anu.edu.au/news/2022/11/22/panic-a-serendipity-engine/">an essay on the School of Cybernetics
website</a>
which goes into more detail about how it works and what it all means (I mean,
it’s an artwork, so mostly I built it because I could, but some folks wanna know
“what’s the practical application of this stuff” so I wrote some words to give
plausible deniability).</p>

<p>Here’s a 90min video of every single stable-diffusion image generated over the
full 2 weeks of the exhibition. Not necessarily the sort of thing you’d sit down
and watch from start to finish, but fun to dip in and out of. Even at 8fps it’s
still possible to watch the gestalt change over time (and it’s also interesting
to see which prompts the humans in the room put in).</p>

<div style="width:100%; margin: 0px auto; margin-bottom: 1rem;">
  <div style="position: relative; padding-bottom: 62.5%; height: 0px;">
	<iframe style="position: absolute; top: 0px; left: 0px; width: 100%; height: 100%;" src="https://www.youtube.com/embed/_9gLWebIeeY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="">
	</iframe>
  </div>
</div>

<p>On the livecoding front, Ushini &amp; I did another <a href="https://www.ozchi.org/2022/creative_4.html">livecoding set at the OzCHI
2022 conference</a>—pics &amp; video on
the <a href="/livecoding/2022-12-01-ozchi-22.html">livecoding page</a>.</p>]]></content><author><name>Ben Swift</name></author><category term="livecoding" /><category term="ai" /><summary type="html"><![CDATA[If you follow me on twitter you’ve seen this already, but over the last couple of months I’ve been hard at work on an AI art installation called Panic. This was a collaboration with Adrian Schmidt—I did the software, he did the hardware (including the cool, 6” diameter Panic! button).]]></summary></entry><entry><title type="html">NGA Un-tour: The Hidden Gallery</title><link href="https://benswift.me/blog/2022/10/12/nga-un-tour-the-hidden-gallery/" rel="alternate" type="text/html" title="NGA Un-tour: The Hidden Gallery" /><published>2022-10-12T00:00:00+11:00</published><updated>2022-10-12T00:00:00+11:00</updated><id>https://benswift.me/blog/2022/10/12/nga-un-tour-the-hidden-gallery</id><content type="html" xml:base="https://benswift.me/blog/2022/10/12/nga-un-tour-the-hidden-gallery/"><![CDATA[<p>For the last year or so my team has been collaborating with the good folks at
<a href="https://www.bestfestivalever.com.au">BOHO Interactive</a> and the National Gallery
of Australia on something which launches tonight—the <em>NGA Un-Tour</em>.</p>

<p>From the <a href="https://nga.gov.au/events/un-tour-the-hidden-gallery/">NGA website</a>:</p>

<blockquote>
  <p>Experience an immersive cybernetic walking tour of the National Gallery after
dark. Travel through familiar and behind-the scenes spaces and investigate the
dynamic relationships between humans, technology and the built environment
found within works of art and the Gallery itself. Wear your walking shoes and
join us as we explore previously hidden parts of the building and gardens.</p>

  <p>Held of over one week during the Gallery’s 40th birthday celebrations. This
special event is co-presented by the National Gallery and the ANU School of
Cybernetics.</p>
</blockquote>

<p>I’m not sure if there are any tickets left, but if there are you should
definitely check it out. You won’t get another chance to experience one of
Canberra’s cultural institutions in this way for a long time.</p>]]></content><author><name>Ben Swift</name></author><category term="cybernetics" /><summary type="html"><![CDATA[For the last year or so my team has been collaborating with the good folks at BOHO Interactive and the National Gallery of Australia on something which launches tonight—the NGA Un-Tour.]]></summary></entry><entry><title type="html">So this is how it feels when the robots come for your job: what GitHub’s Copilot ‘AI assistant’ means for coders</title><link href="https://benswift.me/blog/2022/06/30/what-githubs-copilot-ai-assistant-means-for-coders/" rel="alternate" type="text/html" title="So this is how it feels when the robots come for your job: what GitHub’s Copilot ‘AI assistant’ means for coders" /><published>2022-06-30T00:00:00+10:00</published><updated>2022-06-30T00:00:00+10:00</updated><id>https://benswift.me/blog/2022/06/30/what-githubs-copilot-ai-assistant-means-for-coders</id><content type="html" xml:base="https://benswift.me/blog/2022/06/30/what-githubs-copilot-ai-assistant-means-for-coders/"><![CDATA[<p>I wrote <a href="https://theconversation.com/so-this-is-how-it-feels-when-the-robots-come-for-your-job-what-githubs-copilot-ai-assistant-means-for-coders-185957">a piece for the Conversation</a> about GitHub’s new
<em>Copilot</em> AI programming assistant. You can <a href="https://theconversation.com/so-this-is-how-it-feels-when-the-robots-come-for-your-job-what-githubs-copilot-ai-assistant-means-for-coders-185957">head over there</a> to
read it if you like.</p>]]></content><author><name>Ben Swift</name></author><category term="tools" /><category term="ai" /><summary type="html"><![CDATA[I wrote a piece for the Conversation about GitHub’s new Copilot AI programming assistant. You can head over there to read it if you like.]]></summary></entry><entry><title type="html">Redacting craiyon prompts with imagemagick</title><link href="https://benswift.me/blog/2022/06/22/redacting-craiyon-prompts-with-imagemagick/" rel="alternate" type="text/html" title="Redacting craiyon prompts with imagemagick" /><published>2022-06-22T00:00:00+10:00</published><updated>2022-06-22T00:00:00+10:00</updated><id>https://benswift.me/blog/2022/06/22/redacting-craiyon-prompts-with-imagemagick</id><content type="html" xml:base="https://benswift.me/blog/2022/06/22/redacting-craiyon-prompts-with-imagemagick/"><![CDATA[<p>I’ve been messing around with <a href="https://www.craiyon.com">craiyon</a> (formerly
<a href="https://huggingface.co/spaces/dalle-mini/dalle-mini">DALL-E mini</a>), because who
<em>hasn’t</em> been doing that recently.</p>

<p>As part of a workshop I’m running soon at the <a href="https://cybernetics.anu.edu.au">School of
Cybernetics</a> I need to provide “redacted”
versions of the classic 3x3 craiyon output image—and I need to do it for quite
a few outputs.</p>

<p>Because it’s tedious to do that by hand, here’s what I came up with:</p>

<ol>
  <li>
    <p>input a prompt and generate the craiyon output as normal</p>
  </li>
  <li>
    <p>use the <em>📷 Screenshot</em> button to get a nice, clean screenshot</p>
  </li>
  <li>
    <p>run this <a href="https://imagemagick.org">imagemagick</a> command (in my case the
downloaded screenshot name was <code>craiyon_2022-6-22_17-21-5.png</code>, yours will be
similar but with a different timestamp at the end)</p>

    <pre><code class="language-sh">convert craiyon_2022-6-22_17-21-5.png -fill red -draw 'rectangle 30, 240, 1320, 320' -fill white -pointsize 50 -gravity north -annotate +0+250 'REDACTED' craiyon_2022-6-22_17-21-5-redacted.png
</code></pre>
  </li>
  <li>
    <p>(bonus round) if you want to loop over a bunch of files and do it in batch, I
did that in Emacs with:</p>
    <pre><code class="language-lisp">(--each
    (f-entries "." (lambda (s) (s-ends-with? "png" s)))
  (shell-command (format "convert %s -fill red -draw 'rectangle 30, 240, 1320, 320' -fill white -pointsize 50 -gravity north -annotate +0+250 'REDACTED' redacted-%s.jpg"
                         it
                         (f-base it))))
</code></pre>
  </li>
</ol>

<h2 id="an-example">An example</h2>

<p>Here’s an example screenshot:</p>

<p><img src="/assets/images/posts/craiyon/craiyon_2022-6-22_17-21-5.png" alt="Grid of AI image outputs generated in response to the prompt &quot;redacting the prompt from a DALL-E image output with imagemagick&quot;" /></p>

<p>and the same output, after the redaction command has been run:</p>

<p><img src="/assets/images/posts/craiyon/redacted-craiyon_2022-6-22_17-21-5.jpg" alt="Grid of AI image outputs generated in response to the prompt, which has been redacted" /></p>

<p>If you need to do the same, then hopefully I’ve saved you a bit of time ☺</p>]]></content><author><name>Ben Swift</name></author><category term="tools" /><category term="ai" /><summary type="html"><![CDATA[I’ve been messing around with craiyon (formerly DALL-E mini), because who hasn’t been doing that recently.]]></summary></entry></feed>