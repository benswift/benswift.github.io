<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.1">Jekyll</generator><link href="https://benswift.me/feed.xml" rel="self" type="application/atom+xml" /><link href="https://benswift.me/" rel="alternate" type="text/html" /><updated>2023-01-27T15:08:15+11:00</updated><id>https://benswift.me/feed.xml</id><title type="html">benswift.me</title><subtitle>livecoder &amp; researcher homepage - code, creativity, culture</subtitle><author><name>Ben Swift</name></author><entry><title type="html">Congrats Dr. Kieran Browne</title><link href="https://benswift.me/blog/2023/01/26/congrats-dr-kieran-browne/" rel="alternate" type="text/html" title="Congrats Dr. Kieran Browne" /><published>2023-01-26T00:00:00+11:00</published><updated>2023-01-26T00:00:00+11:00</updated><id>https://benswift.me/blog/2023/01/26/congrats-dr-kieran-browne</id><content type="html" xml:base="https://benswift.me/blog/2023/01/26/congrats-dr-kieran-browne/"><![CDATA[<p>Last December <a href="https://kieranbrowne.com">Kieran</a> graduated‚Äîvery exciting for
all concerned.</p>

<picture style="position: relative;">
  <img alt="Ben and Kieran in full academic dress at the ANU graduation ceremony in December 2022" src="/assets/images/posts/ben-kieran-phd-graduation.jpg" />

  
</picture>

<p>His thesis, <em>Neurological Metaphor in Deep Learning: Issues and Alternatives</em>,
is <a href="https://openresearch-repository.anu.edu.au/handle/1885/274243">available online through the ANU
Library</a>. It‚Äôs a
really interesting mix of insightful scholarship and practice-based design
interventions. In other words, he has interesting things to say <em>and</em> he built
interesting things (some of which are available online).</p>

<p>Here‚Äôs the abstract:</p>

<blockquote>
  <p>Representations of deep learning‚Äîdiscursive, historical and
diagrammatic‚Äîare structured by a neurological metaphor that overstates a
likeness to the brain and disguises other ways of understanding the
technology. These neurological representations muddle the crucial public
debate even as deep learning is applied in high-stakes applications,
particularly in institutions of social and political power. This thesis draws
on historical sources and contemporary literature to trace the development and
contemporary expression of the neurological metaphor in deep learning
discourse; particularly with respect to the field‚Äôs terminology, the telling
of its history, and the drawing of its diagrams. In the manuscript and in
three documented practice-based works, I propose alternative metaphors for
deep learning‚Äîdivination, surveillance and memory‚Äîto highlight
sociotechnical concerns posed by the technology. As a highly interdisciplinary
project, this thesis applies a range of methods drawn variously from digital
humanities, discourse analysis, human-centred computing, visual arts and
design, and deep learning itself. The traditional scholarship and
practice-based aspects of the thesis are situated in contemporary debates of
AI bias and interpretability, and the role of deep learning in systems of
power.</p>
</blockquote>]]></content><author><name>Ben Swift</name></author><category term="research" /><category term="ai" /><summary type="html"><![CDATA[Last December Kieran graduated‚Äîvery exciting for all concerned.]]></summary></entry><entry><title type="html">Handling Square Webhooks in Phoenix</title><link href="https://benswift.me/blog/2023/01/22/handling-square-webhooks-in-phoenix/" rel="alternate" type="text/html" title="Handling Square Webhooks in Phoenix" /><published>2023-01-22T00:00:00+11:00</published><updated>2023-01-22T00:00:00+11:00</updated><id>https://benswift.me/blog/2023/01/22/handling-square-webhooks-in-phoenix</id><content type="html" xml:base="https://benswift.me/blog/2023/01/22/handling-square-webhooks-in-phoenix/"><![CDATA[<p>My <a href="https://the-riotact.com/hot-in-the-suburbs-little-luxton-serves-up-coffee-for-the-community/618459">brother‚Äôs
cafe</a>
donates a dollar to the local community centre for every coffee sold, and over
the summer I built
him a live ‚Äúdonation counter‚Äù which displays a small ‚Äúthankyou‚Äù animation when
anyone buys a coffee. It‚Äôs a web app which they run on an iPad sitting on the
coffee machine.</p>

<p>Since the cafe uses Square for all payments, I was able to set up a
<a href="https://developer.squareup.com/docs/webhooks/overview">webhook</a> so the app
would receive the ‚Äúnew sale‚Äù notification ASAP‚Äîthis should be both
lower-latency and more efficient than polling.</p>

<p>The app is basically a single <a href="https://www.phoenixframework.org">Phoenix
LiveView</a>. Sadly the Square guides don‚Äôt have
examples for Elixir, although it‚Äôs pretty easy to modify the e.g. <a href="https://developer.squareup.com/docs/webhooks/step3validate">Ruby
example</a> code to get
the job done. If you‚Äôre looking to do something similar I cobbled together this
info from docs (and a few blogs) and it might help you out to have it all in one
place.</p>

<h2 id="step-1-set-up-webhook-controller-including-validation">Step 1: set up webhook controller (including validation)</h2>

<p>It‚Äôs important to validate that any incoming webhook is actually from Square, so
Square send a special <code>x-square-hmacsha256-signature</code> header for <a href="https://developer.squareup.com/docs/webhooks/step3validate">validation
purposes</a>, although
performing this validation step requires having access to the raw request body.
Thankfully, the <a href="https://hexdocs.pm/plug/Plug.Parsers.html#module-custom-body-reader">‚ÄúCustom Body Reader‚Äù section in the <code>Plug.Parsers</code>
docs</a> shows
how to do exactly that‚Äîjust follow the instructions there.</p>

<h2 id="step-2-create-webhook-controller-including-validation">Step 2: create webhook controller (including validation)</h2>

<p>The webhook controller module should look something like this (replace the
<code>notification_url</code> and <code>signature_key</code> with the right values for your
app‚Äîyou‚Äôll get your signature key from Square when you register the webhook):</p>

<pre><code class="language-elixir">defmodule MyAppWeb.SquareWebhookController do
  @moduledoc """
  Handle webhooks sent from Square.
  """
  use MyAppWeb, :controller

  @doc "handle the webhook request"
  def webhook(conn, params) do
    if is_from_square?(conn) do
      do_stuff(params)
    end

    send_response(conn)
  end

  @doc "respond to the Square server (always 200 OK otherwise they'll freak out)"
  defp send_response(conn) do
    conn
    |&gt; put_resp_content_type("text/plain")
    |&gt; send_resp(200, "webhook received - thanks.")
  end

  @doc "returns `true` if webhook came from Square, `false` otherwise"
  defp is_from_square?(conn) do
    notification_url = "http://example.com/square/webhook"
    signature_key = "WEBHOOK_SIGNATURE_KEY_FROM_SQUARE"
    {_, signature} = List.keyfind!(conn.req_headers, "x-square-hmacsha256-signature", 0)

    ## here's where we access the raw request body we put there in the Plug.Parser
    raw_body = Enum.join(conn.assigns.raw_body)

    hash =
      :crypto.mac(:hmac, :sha256, signature_key, notification_url &lt;&gt; raw_body)
      |&gt; Base.encode64()

    signature == hash
  end
end
</code></pre>

<h2 id="step-3-add-the-endpoint-to-your-router">Step 3: add the endpoint to your router</h2>

<p>Finally, add it to to your <code>router.ex</code> - something like this, you know the
drill.</p>

<pre><code class="language-elixir">scope "/square", MyAppWeb do
  pipe_through :api

  post "/webhook", SquareWebhookController, :webhook
end
</code></pre>

<h2 id="step-4-subscribe-to-the-webhook">Step 4: subscribe to the webhook</h2>

<p>After that‚Äôs all done (and you‚Äôve deployed your app) you‚Äôre ready to <a href="https://developer.squareup.com/docs/webhooks/overview">set up a
webhook subscription</a>.
Follow the Square docs and Square will start hitting your (deployed) app‚Äôs
<code>https://example.com/square/webhook</code> endpoint, and your app can do its thing.</p>

<p class="hl-para">Note that these incoming webhook requests <em>won‚Äôt</em> hit your local development
server running on <code>localhost</code>, so testing webhooks is a bit trickier. Since my
app runs on <a href="https://fly.io">fly</a> it involved a little bit of <code>IO.inspect</code>ing in
production and then looking at the logs with <code>flyctl logs</code>.</p>

<p>Have fun! And if you live in Canberra, especially in Tuggeranong/Lanyon, maybe
go buy a coffee from <a href="https://www.littleluxton.com">Little Luxton</a> and you can
see it for yourself üòä</p>]]></content><author><name>Ben Swift</name></author><category term="web" /><category term="elixir" /><category term="phoenix" /><summary type="html"><![CDATA[My brother‚Äôs cafe donates a dollar to the local community centre for every coffee sold, and over the summer I built him a live ‚Äúdonation counter‚Äù which displays a small ‚Äúthankyou‚Äù animation when anyone buys a coffee. It‚Äôs a web app which they run on an iPad sitting on the coffee machine.]]></summary></entry><entry><title type="html">rclone: exclude all git repos</title><link href="https://benswift.me/blog/2023/01/11/rclone-exclude-all-git-repos/" rel="alternate" type="text/html" title="rclone: exclude all git repos" /><published>2023-01-11T00:00:00+11:00</published><updated>2023-01-11T00:00:00+11:00</updated><id>https://benswift.me/blog/2023/01/11/rclone-exclude-all-git-repos</id><content type="html" xml:base="https://benswift.me/blog/2023/01/11/rclone-exclude-all-git-repos/"><![CDATA[<p>For a long time I‚Äôve used <a href="https://rclone.org">rclone</a> for remote backups and
it‚Äôs awesome. I have a script which syncs all the files I care about on my
laptop to cloudstor (which, being on the Australian university network has the
benefit that I get 1Gbps upload when I‚Äôm on the ANU network). My institution
(the ANU)</p>

<p>However, it turns out that
<a href="https://support.aarnet.edu.au/hc/en-us/articles/5697089309711">cloudstor</a> is
shutting down at the end of this year, so I need to find a new home for my
backups. I‚Äôve been told that the ‚Äúreplacement‚Äù is to use my institutional
OneDrive account.</p>

<p>My feelings about closing down useful (local) infrastructure and centralising
things on one of the big cloud providers notwithstanding, this should be an easy
change‚Äî<a href="https://rclone.org/onedrive/">rclone supports OneDrive</a>, so it‚Äôs a
simple config change to move over.</p>

<p>However, I figured I‚Äôd take the opportunity to fix something which had long
bothered me. I have a <em>lot</em> of stuff in git repos which don‚Äôt need to be backed
up with rclone, and they just slow down the backup process. I wanted to get
rclone to ignore all git repos, and although it has an <a href="https://rclone.org/filtering/">include/exclude
filtering</a> system it‚Äôs not easy to get it to
filter all git repos (trust me, <a href="https://forum.rclone.org/t/ignore-all-git-repos-when-syncing/33023">I
checked</a>).</p>

<p>Now that it‚Äôs summertime I had a chance to make it work, and since that forum
thread is now locked I‚Äôm posting it here to save you some time, dear reader, if
you ever want to do this for yourself. Feel free to use/modify it (MIT Licence)
if it‚Äôs helpful.</p>

<pre><code class="language-bash">#!/bin/bash

EXCLUDE_FROM_FILE="/tmp/rclone-excludes.txt"
CLONE_ROOT_DIR=~/Documents
REMOTE=anu-onedrive

## find all git repo enclosing folders (including trailing slash), munge them
## into the form that rclone expects for its "exclude from" file
cd $CLONE_ROOT_DIR &amp;&amp; find . -type d -name .git -exec  dirname {} \; | sed -e 's/$/\//' -e 's/^.//' &gt; $EXCLUDE_FROM_FILE

## add a few extra excludes
echo ".DS_Store" &gt;&gt; $EXCLUDE_FROM_FILE

## sync to remote
rclone sync --progress --exclude-from=$EXCLUDE_FROM_FILE $CLONE_ROOT_DIR $REMOTE:mitch-rclone/$CLONE_ROOT_DIR
</code></pre>]]></content><author><name>Ben Swift</name></author><category term="tools" /><summary type="html"><![CDATA[For a long time I‚Äôve used rclone for remote backups and it‚Äôs awesome. I have a script which syncs all the files I care about on my laptop to cloudstor (which, being on the Australian university network has the benefit that I get 1Gbps upload when I‚Äôm on the ANU network). My institution (the ANU)]]></summary></entry><entry><title type="html">A School of Cybernetics strategy meeting with ChatGPT</title><link href="https://benswift.me/blog/2022/12/07/a-school-of-cybernetics-strategy-meeting-with-chatgpt/" rel="alternate" type="text/html" title="A School of Cybernetics strategy meeting with ChatGPT" /><published>2022-12-07T00:00:00+11:00</published><updated>2022-12-07T00:00:00+11:00</updated><id>https://benswift.me/blog/2022/12/07/a-school-of-cybernetics-strategy-meeting-with-chatgpt</id><content type="html" xml:base="https://benswift.me/blog/2022/12/07/a-school-of-cybernetics-strategy-meeting-with-chatgpt/"><![CDATA[<p>Back at my desk after a couple of days off I finally got a chance to fire up the
<a href="https://chat.openai.com">OpenAI ChatGPT</a> AI language model that everyone‚Äôs
talking about.</p>

<p>Here‚Äôs‚Äîand this is the honest truth‚Äîthe first conversation I had with it.
The initial paragraph was from the <a href="https://cybernetics.anu.edu.au/about/">ANU School of Cybernetics
website</a>, and from there we just
freewheeled. My inputs are in regular type, the ChatGPT responses are in the
coloured boxes.</p>

<hr />

<p><em>begin chat transcript</em></p>

<p>The 3A Institute sits within the School of Cybernetics with the mission to build
a new branch of engineering to take AI-enabled cyber-physical systems to scale
and to create a new generation of practitioners with the skills and knowledge we
need to help shape this future safely, sustainably and responsibly.</p>

<p>As people invent, commercialise and operationalise new technologies, new
practitioners emerge to manage them. Just as the invention of programmable
computers led to the professionalisation of software engineers, cyber-physical
systems will lead to a new type of engineer.</p>

<p>We don‚Äôt know what this new type of engineering will be called yet, but we know
we need it if we are to build a safe, sustainable and responsible future.</p>

<p>Give 5 concrete examples of how ideas from cybernetics can help:</p>

<div class="hl-para">

  <ol>
    <li>Cybernetics can help with the design and optimization of complex systems,
such as transportation networks or power grids, by using feedback loops and
control systems to ensure efficient and reliable operation.</li>
    <li>Cybernetic principles can be applied to the development of intelligent
machines and autonomous systems, enabling them to learn from their
environment and adapt to changing conditions.</li>
    <li>Cybernetics can be used to improve human-machine interactions, such as
through the design of user-friendly interfaces or the integration of wearable
technologies that enhance our physical abilities.</li>
    <li>Cybernetic concepts can be applied to the study of biological systems, such
as the nervous system, to gain a better understanding of how they function
and how they can be treated or improved.</li>
    <li>Cybernetics can be used to address societal challenges, such as promoting
sustainable development or addressing inequality, by providing a framework
for analyzing and addressing complex systems-level problems.</li>
  </ol>

</div>

<p>Can you try again, but this time using the 19th Century Australian Overland Telegraph as a framing device?</p>

<div class="hl-para">

  <p>Sure, here are five examples of how ideas from cybernetics can help using the
19th Century Australian Overland Telegraph as a framing device:</p>

  <ol>
    <li>The Overland Telegraph relied on a complex network of telegraph lines,
stations, and operators to transmit messages across the vast Australian
continent. Cybernetics can help optimize the design and operation of such
networks by using feedback loops and control systems to ensure efficient and
reliable communication.</li>
    <li>The Overland Telegraph used complex coding systems to encode and decode
messages, and cybernetic principles can be applied to the development of
intelligent machines and algorithms that can learn and adapt to improve the
efficiency and accuracy of such coding systems.</li>
    <li>The Overland Telegraph required skilled operators to manage the transmission
and receipt of messages, and cybernetics can be used to improve human-machine
interactions through the design of user-friendly interfaces and tools that
enable operators to work more efficiently and effectively.</li>
    <li>The Overland Telegraph relied on a network of towers and poles to support the
telegraph lines, and cybernetic concepts can be applied to the study of such
infrastructure to optimize its design and maintenance for long-term
reliability and durability.</li>
    <li>The Overland Telegraph played a crucial role in connecting remote parts of
Australia and facilitating economic and social development, and cybernetics
can be used to address societal challenges by providing a framework for
analyzing and addressing complex systems-level problems and developing
solutions that promote sustainable and equitable growth.</li>
  </ol>

</div>

<p>Ok, that‚Äôs better‚ÄîI think it‚Äôs important that we provide a uniquely Australian
viewpoint on what cybernetics is and how it can help tackle the challenges we
face in the 21st century. As a new School of Cybernetics, then, what should our
top priorities be?</p>

<div class="hl-para">

  <p>As a new School of Cybernetics, some top priorities could include:</p>

  <ol>
    <li>Developing a strong research program focused on applying cybernetic
principles to real-world challenges facing Australia, such as improving the
resilience and sustainability of critical infrastructure, enhancing the
security and privacy of digital systems, or addressing complex societal
issues such as inequality and climate change.</li>
    <li>Providing high-quality education and training programs that enable students
to gain a deep understanding of cybernetic concepts and techniques, and
develop the skills and knowledge needed to become leaders in the field.</li>
    <li>Building partnerships and collaborations with other academic institutions,
industry partners, and government agencies to facilitate the exchange of
ideas, knowledge, and expertise, and to support the development and
implementation of innovative cybernetic solutions.</li>
    <li>Playing a key role in promoting public awareness and understanding of
cybernetics, and addressing common misconceptions and concerns about the
field, in order to foster a positive and informed dialogue about its
potential benefits and limitations.</li>
    <li>Establishing a strong and supportive community of scholars, practitioners,
and stakeholders within the field of cybernetics, and providing opportunities
for networking, collaboration, and professional development.</li>
  </ol>

</div>

<p><em>end chat transcript</em></p>

<hr />

<p>Well, wow. This required no re-prompting or editing on my part.</p>

<p>I should say that I share all of the skepticism (and fears!) of folks who are
pointing out that these language models don‚Äôt actually understand things. In
some cases this means the output of these models is benign but incorrect, and
it‚Äôs easy to think of situations where real harm could be caused.</p>

<p>Upon close reading, I don‚Äôt think the above responses capture the full breadth
of what we‚Äôre trying to do here in the School of Cybernetics. But I‚Äôd be lying
if I wasn‚Äôt impressed.</p>

<p>As I <a href="https://twitter.com/benswift/status/1600265214338867200">tweeted earlier this
morning</a>:</p>

<blockquote>
  <p>all this ChatGPT stuff means that we as a society are gonna have to get a
<strong>lot</strong> better at drinking from the bullshit firehose, and fast</p>
</blockquote>

<p>I‚Äôll pen some more thoughts about what it all means when I‚Äôve had some more time
to digest things.</p>]]></content><author><name>Ben Swift</name></author><category term="ai" /><category term="cybernetics" /><summary type="html"><![CDATA[Back at my desk after a couple of days off I finally got a chance to fire up the OpenAI ChatGPT AI language model that everyone‚Äôs talking about.]]></summary></entry><entry><title type="html">AI art installations and livecoding gigs in Nov/Dec</title><link href="https://benswift.me/blog/2022/12/06/ai-art-installations-and-livecoding-gigs-in-nov-dec/" rel="alternate" type="text/html" title="AI art installations and livecoding gigs in Nov/Dec" /><published>2022-12-06T00:00:00+11:00</published><updated>2022-12-06T00:00:00+11:00</updated><id>https://benswift.me/blog/2022/12/06/ai-art-installations-and-livecoding-gigs-in-nov-dec</id><content type="html" xml:base="https://benswift.me/blog/2022/12/06/ai-art-installations-and-livecoding-gigs-in-nov-dec/"><![CDATA[<p>If you <a href="https://twitter.com/benswift">follow me on twitter</a> you‚Äôve seen this
already, but over the last couple of months I‚Äôve been hard at work on an AI art
installation called Panic. This was a collaboration with <a href="https://cybernetics.anu.edu.au/people/adrian-schmidt/">Adrian
Schmidt</a>‚ÄîI did the
software, he did the hardware (including the cool, 6‚Äù diameter <em>Panic!</em> button).</p>

<div style="width:100%; margin: 0px auto; margin-bottom: 1rem;">
  <div style="position: relative; padding-bottom: 62.5%; height: 0px;">
	<iframe style="position: absolute; top: 0px; left: 0px; width: 100%; height: 100%;" src="https://www.youtube.com/embed/wpOkUX_LmQo" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="">
	</iframe>
  </div>
</div>

<p>I wrote <a href="https://cybernetics.anu.edu.au/news/2022/11/22/panic-a-serendipity-engine/">an essay on the School of Cybernetics
website</a>
which goes into more detail about how it works and what it all means (I mean,
it‚Äôs an artwork, so mostly I built it because I could, but some folks wanna know
‚Äúwhat‚Äôs the practical application of this stuff‚Äù so I wrote some words to give
plausible deniability).</p>

<p>Here‚Äôs a 90min video of every single stable-diffusion image generated over the
full 2 weeks of the exhibition. Not necessarily the sort of thing you‚Äôd sit down
and watch from start to finish, but fun to dip in and out of. Even at 8fps it‚Äôs
still possible to watch the gestalt change over time (and it‚Äôs also interesting
to see which prompts the humans in the room put in).</p>

<div style="width:100%; margin: 0px auto; margin-bottom: 1rem;">
  <div style="position: relative; padding-bottom: 62.5%; height: 0px;">
	<iframe style="position: absolute; top: 0px; left: 0px; width: 100%; height: 100%;" src="https://www.youtube.com/embed/_9gLWebIeeY" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen="">
	</iframe>
  </div>
</div>

<p>On the livecoding front, Ushini &amp; I did another <a href="https://www.ozchi.org/2022/creative_4.html">livecoding set at the OzCHI
2022 conference</a>‚Äîpics &amp; video on
the <a href="/livecoding/2022-12-01-ozchi-22.html">livecoding page</a>.</p>]]></content><author><name>Ben Swift</name></author><category term="livecoding" /><category term="ai" /><summary type="html"><![CDATA[If you follow me on twitter you‚Äôve seen this already, but over the last couple of months I‚Äôve been hard at work on an AI art installation called Panic. This was a collaboration with Adrian Schmidt‚ÄîI did the software, he did the hardware (including the cool, 6‚Äù diameter Panic! button).]]></summary></entry><entry><title type="html">NGA Un-tour: The Hidden Gallery</title><link href="https://benswift.me/blog/2022/10/12/nga-un-tour-the-hidden-gallery/" rel="alternate" type="text/html" title="NGA Un-tour: The Hidden Gallery" /><published>2022-10-12T00:00:00+11:00</published><updated>2022-10-12T00:00:00+11:00</updated><id>https://benswift.me/blog/2022/10/12/nga-un-tour-the-hidden-gallery</id><content type="html" xml:base="https://benswift.me/blog/2022/10/12/nga-un-tour-the-hidden-gallery/"><![CDATA[<p>For the last year or so my team has been collaborating with the good folks at
<a href="https://www.bestfestivalever.com.au">BOHO Interactive</a> and the National Gallery
of Australia on something which launches tonight‚Äîthe <em>NGA Un-Tour</em>.</p>

<p>From the <a href="https://nga.gov.au/events/un-tour-the-hidden-gallery/">NGA website</a>:</p>

<blockquote>
  <p>Experience an immersive cybernetic walking tour of the National Gallery after
dark. Travel through familiar and behind-the scenes spaces and investigate the
dynamic relationships between humans, technology and the built environment
found within works of art and the Gallery itself. Wear your walking shoes and
join us as we explore previously hidden parts of the building and gardens.</p>

  <p>Held of over one week during the Gallery‚Äôs 40th birthday celebrations. This
special event is co-presented by the National Gallery and the ANU School of
Cybernetics.</p>
</blockquote>

<p>I‚Äôm not sure if there are any tickets left, but if there are you should
definitely check it out. You won‚Äôt get another chance to experience one of
Canberra‚Äôs cultural institutions in this way for a long time.</p>]]></content><author><name>Ben Swift</name></author><category term="cybernetics" /><summary type="html"><![CDATA[For the last year or so my team has been collaborating with the good folks at BOHO Interactive and the National Gallery of Australia on something which launches tonight‚Äîthe NGA Un-Tour.]]></summary></entry><entry><title type="html">So this is how it feels when the robots come for your job: what GitHub‚Äôs Copilot ‚ÄòAI assistant‚Äô means for coders</title><link href="https://benswift.me/blog/2022/06/30/what-githubs-copilot-ai-assistant-means-for-coders/" rel="alternate" type="text/html" title="So this is how it feels when the robots come for your job: what GitHub‚Äôs Copilot ‚ÄòAI assistant‚Äô means for coders" /><published>2022-06-30T00:00:00+10:00</published><updated>2022-06-30T00:00:00+10:00</updated><id>https://benswift.me/blog/2022/06/30/what-githubs-copilot-ai-assistant-means-for-coders</id><content type="html" xml:base="https://benswift.me/blog/2022/06/30/what-githubs-copilot-ai-assistant-means-for-coders/"><![CDATA[<p>I wrote <a href="https://theconversation.com/so-this-is-how-it-feels-when-the-robots-come-for-your-job-what-githubs-copilot-ai-assistant-means-for-coders-185957">a piece for the Conversation</a> about GitHub‚Äôs new
<em>Copilot</em> AI programming assistant. You can <a href="https://theconversation.com/so-this-is-how-it-feels-when-the-robots-come-for-your-job-what-githubs-copilot-ai-assistant-means-for-coders-185957">head over there</a> to
read it if you like.</p>]]></content><author><name>Ben Swift</name></author><category term="tools" /><category term="ai" /><summary type="html"><![CDATA[I wrote a piece for the Conversation about GitHub‚Äôs new Copilot AI programming assistant. You can head over there to read it if you like.]]></summary></entry><entry><title type="html">Redacting craiyon prompts with imagemagick</title><link href="https://benswift.me/blog/2022/06/22/redacting-craiyon-prompts-with-imagemagick/" rel="alternate" type="text/html" title="Redacting craiyon prompts with imagemagick" /><published>2022-06-22T00:00:00+10:00</published><updated>2022-06-22T00:00:00+10:00</updated><id>https://benswift.me/blog/2022/06/22/redacting-craiyon-prompts-with-imagemagick</id><content type="html" xml:base="https://benswift.me/blog/2022/06/22/redacting-craiyon-prompts-with-imagemagick/"><![CDATA[<p>I‚Äôve been messing around with <a href="https://www.craiyon.com">craiyon</a> (formerly
<a href="https://huggingface.co/spaces/dalle-mini/dalle-mini">DALL-E mini</a>), because who
<em>hasn‚Äôt</em> been doing that recently.</p>

<p>As part of a workshop I‚Äôm running soon at the <a href="https://cybernetics.anu.edu.au">School of
Cybernetics</a> I need to provide ‚Äúredacted‚Äù
versions of the classic 3x3 craiyon output image‚Äîand I need to do it for quite
a few outputs.</p>

<p>Because it‚Äôs tedious to do that by hand, here‚Äôs what I came up with:</p>

<ol>
  <li>
    <p>input a prompt and generate the craiyon output as normal</p>
  </li>
  <li>
    <p>use the <em>üì∑ Screenshot</em> button to get a nice, clean screenshot</p>
  </li>
  <li>
    <p>run this <a href="https://imagemagick.org">imagemagick</a> command (in my case the
downloaded screenshot name was <code>craiyon_2022-6-22_17-21-5.png</code>, yours will be
similar but with a different timestamp at the end)</p>

    <pre><code class="language-sh">convert craiyon_2022-6-22_17-21-5.png -fill red -draw 'rectangle 30, 240, 1320, 320' -fill white -pointsize 50 -gravity north -annotate +0+250 'REDACTED' craiyon_2022-6-22_17-21-5-redacted.png
</code></pre>
  </li>
  <li>
    <p>(bonus round) if you want to loop over a bunch of files and do it in batch, I
did that in Emacs with:</p>
    <pre><code class="language-lisp">(--each
    (f-entries "." (lambda (s) (s-ends-with? "png" s)))
  (shell-command (format "convert %s -fill red -draw 'rectangle 30, 240, 1320, 320' -fill white -pointsize 50 -gravity north -annotate +0+250 'REDACTED' redacted-%s.jpg"
                         it
                         (f-base it))))
</code></pre>
  </li>
</ol>

<h2 id="an-example">An example</h2>

<p>Here‚Äôs an example screenshot:</p>

<p><img src="/assets/images/posts/craiyon/craiyon_2022-6-22_17-21-5.png" alt="Grid of AI image outputs generated in response to the prompt &quot;redacting the prompt from a DALL-E image output with imagemagick&quot;" /></p>

<p>and the same output, after the redaction command has been run:</p>

<p><img src="/assets/images/posts/craiyon/redacted-craiyon_2022-6-22_17-21-5.jpg" alt="Grid of AI image outputs generated in response to the prompt, which has been redacted" /></p>

<p>If you need to do the same, then hopefully I‚Äôve saved you a bit of time ‚ò∫</p>]]></content><author><name>Ben Swift</name></author><category term="tools" /><category term="ai" /><summary type="html"><![CDATA[I‚Äôve been messing around with craiyon (formerly DALL-E mini), because who hasn‚Äôt been doing that recently.]]></summary></entry><entry><title type="html">Pulling apart Zoom attendance csv dumps in tidy R</title><link href="https://benswift.me/blog/2022/05/23/pulling-apart-zoom-attendance-csv-dumps-in-tidy-r/" rel="alternate" type="text/html" title="Pulling apart Zoom attendance csv dumps in tidy R" /><published>2022-05-23T00:00:00+10:00</published><updated>2022-05-23T00:00:00+10:00</updated><id>https://benswift.me/blog/2022/05/23/pulling-apart-zoom-attendance-csv-dumps-in-tidy-r</id><content type="html" xml:base="https://benswift.me/blog/2022/05/23/pulling-apart-zoom-attendance-csv-dumps-in-tidy-r/"><![CDATA[<p>My team ran some Zoom training last week and today I needed to figure out who
actually attended across all the days, and for how long.</p>

<p>Zoom can give you a csv dump of all attendees but doesn‚Äôt provide the
aggregations I was after, so I hacked up a little script (in <a href="https://www.tidyverse.org">tidy
R</a>) to do it. If you ever want to do something
similar, feel free to use it (<a href="https://mit-license.org">MIT Licence</a>).</p>

<pre><code class="language-R">read_zoom_attendance_csv = function(filename){
  read_csv(filename, show_col_types = FALSE) %&gt;%
    # I only needed the date, not the actual start time, so I didn't bother parsing
    # the full datetime + timezone string that Zoom gives
    mutate(date = parse_date(str_sub(`Join Time`, end = 10), format = "%m/%d/%Y")) %&gt;%
    # this isn't necessary, but I like shorter column names
    rename(name = `Name (Original Name)`, email = `User Email`, duration = `Duration (Minutes)` ) %&gt;%
    # I'm only intrested in these columns
    select(name, email, date, duration) %&gt;%
    # this isn't necessary, but handy if individuals have signed in with
    # slightly different names on different days (requires eyeballing the data)
    mutate(name = recode(name,
                         "JS" = "Joanna Smith",
                         "Louise" = "Louise Jones"
}
</code></pre>

<p>Then you can read the Zoom csv file like so:</p>

<pre><code class="language-R">df = read_zoom_attendance_csv("zoom-call.csv")
</code></pre>

<p>And to visualise in <a href="https://ggplot2.tidyverse.org">ggplot2</a> (which was my
reason for using R in the first place) you could try something like:</p>

<pre><code class="language-R">df %&gt;%
  group_by(name, date) %&gt;%
  # this was the key summarisation I was after - total time 
  # in-call across multiple connects/re-connects
  summarise(duration = sum(duration)) %&gt;%
  ungroup() %&gt;%
  ggplot(aes(name, duration)) +
  geom_col() +
  coord_flip() +
  facet_wrap(~date, nrow = 1) +
  labs(
    title = "Zoom call attendance",
    x = "participant name",
    y = "duration on the call (minutes)"
  )
</code></pre>

<p>Enjoy!</p>]]></content><author><name>Ben Swift</name></author><category term="tools" /><summary type="html"><![CDATA[My team ran some Zoom training last week and today I needed to figure out who actually attended across all the days, and for how long.]]></summary></entry><entry><title type="html">Scar trees &amp;amp; living typefaces</title><link href="https://benswift.me/blog/2022/05/02/scar-trees-living-typefaces/" rel="alternate" type="text/html" title="Scar trees &amp;amp; living typefaces" /><published>2022-05-02T00:00:00+10:00</published><updated>2022-05-02T00:00:00+10:00</updated><id>https://benswift.me/blog/2022/05/02/scar-trees-living-typefaces</id><content type="html" xml:base="https://benswift.me/blog/2022/05/02/scar-trees-living-typefaces/"><![CDATA[<picture style="position: relative;">
  <img alt="Yellow box tree on ANU campus. üì∏ ANU Photography, 2016" src="/assets/images/posts/20190103_H1P3978_scar_tree.jpg" />

  
</picture>

<p>I wrote something up for the ANU School of Cybernetics blog (where <a href="https://cybernetics.anu.edu.au/people/ben-swift/">I
work</a>) which has the same
energy as some of the stuff I post on here. If you‚Äôre interested, <a href="https://cybernetics.anu.edu.au/2022/05/02/scar-trees-living-typefaces/">go check it
out</a> ‚ò∫</p>]]></content><author><name>Ben Swift</name></author><category term="cybernetics" /><category term="web" /><summary type="html"><![CDATA[]]></summary></entry></feed>