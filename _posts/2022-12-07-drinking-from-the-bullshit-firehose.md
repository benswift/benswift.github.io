---
title: Drinking from the bullshit firehose
tags: ai teaching
published: false
---

As I scrolled through my social media feeds over the Christmas break
[I](https://www.ft.com/content/86e64b4c-a754-47d6-999c-fcc54f62fb5d)
[read](https://www.theatlantic.com/technology/archive/2022/12/chatgpt-ai-writing-college-student-essays/672371/)
[through](https://www.theguardian.com/technology/2022/dec/04/ai-bot-chatgpt-stuns-academics-with-essay-writing-skills-and-usability)
[several](https://garymarcus.substack.com/p/how-come-gpt-can-seem-so-brilliant)
"what do AI tools like [ChatGPT](https://chat.openai.comhttps://chat.openai.com)
mean for the future of Higher Education" pieces---I'm sure you did as well. I'm
somewhat reluctant to add to that discourse, because most of my thoughts on the
issue have already been made.

I was at a BBQ dinner with a colleague last weekend and our chat turned to
"how's your class shaping up for the coming semester?" They were aware of
ChatGPT and weren't worried about it destroying the fabric of higher education
or anything like that, but they were a bit unsure about if and how they could
make use of it in their class. So here are a few things to think about if you're
in that position. I'm going to use
[ChatGPT](https://chat.openai.comhttps://chat.openai.com) as an example (because
it's the hot one right now), but similar questions apply for any AI content
generation tool, whether for generating text
[images](https://stability.ai/blog/stablediffusion2-1-release7-dec-2022),
[music](https://www.riffusion.com),
[voiceover](https://blog.elevenlabs.io/enter-the-new-year-with-a-bang/) or
[video](https://twitter.com/SmokeAwayyy/status/1613765555768668160).

First, if your class includes student deliverables which involve submitting
written work (e.g. essays, but also process blogs, forum posts and more), some
of your students are going to use ChatGPT to write their submissions. It's
inevitable, and although the NY Schools district is trying to bury its head in
the sand and [ban
ChatGPT](https://www.nbcnews.com/tech/tech-news/new-york-city-public-schools-ban-chatgpt-devices-networks-rcna64446),
position is (in my opinion) both
[wrongheaded](https://time.com/6246574/schools-shouldnt-ban-access-to-chatgpt/)
and [too difficult to enforce in
practice](https://www.theguardian.com/technology/2023/jan/12/college-student-claims-app-can-detect-essays-written-by-chatbot-chatgpt).

So, as you look over your course outline and assessment schedule you need to ask
yourself whether you care if your students use ChatGPT. It's a question that
goes to the heart of why we set deliverables at all, which includes reasons like
[legal
compliance](https://www.teqsa.gov.au/guides-resources/resources/guidance-notes/guidance-note-course-design-including-learning-outcomes-and-assessment)
but for most educators is also about deeply held ideals about education as the
pursuit of knowledge and truth, as well as what it means to give a good (or bad)
grade.

Maybe you don't care, or at least you don't care enough to re-jig your whole
class to "defend" against students using ChatGPT to submit work that they don't
understand. I think that's an ok position to take for now, while other educators
do try and fail and we learn from each others experiences in how best to
incorporate these tools in our classrooms. But you should at least think hard
about "why do I set that particular essays as the final assessment item in this
course, and what would it mean if a student used ChatGPT to write it?"

Secondly, there are already some good ideas floating around about how to use
ChatGPT productively in your teaching. This isn't just if you're designing a new
course on "Applied AI Language Models", there are ways to incorporate it into an
existing course as well. The Centre for Learning and Teaching at Washington
University has already got a helpful [ChatGPT and AI Composition
Tools](https://ctl.wustl.edu/resources/chatgpt-and-ai-composition-tools/) page
up on their website. There are a [bunch of folks experimenting with
ChatGPT-designed syllabi](https://twitter.com/search?q=chatgpt%20syllabus), too.

I think that people like Yoav Goldberg are on the right track when [they say
things like](https://twitter.com/yoavgo/status/1602026029979164675)

> "actually now that i think of it more, i think a "write an essay with the help
> of chatGPT and discuss the process and the resulting prose" can be a
> super-effective assignment also in a humanities-centric, critical-ai program."

If you're wondering how you might incorporate ChatGPT into your class this
coming semester, look at all the times over the semester to produce a written
artefact in response to some sort of question or prompt. Can you tweak it so
that the student (or students) asks that question of ChatGPT and have to
critically reflect on the output they recieve from the AI model. This process
could be scaffolded by first doing it in a facilitated class discussion setting,
but then later as an assessment task (and perhaps the students need to create
their own rubric or criteria on which the output of the AI model should be
evaluated). There are heaps of variations on this, but the general idea is this:
wherever in your current class you ask your students to write something, that's
an opportunity to get the student to co-write (or evaluate) something the with
ChatGPT. On a superficial level this sort of "AI tool use" is the sort of
process that knowledge workers will increasingly be incorporating into our daily
workflows. And at a deeper level it's an opportunity to reflect on where these
tools work well, where they're useless, and where they might be actively
harmful.

One final point which I made to my colleague in the context of incorporating
ChatGPT into this semesters's class is about availability. During the [current
initial research preview ChatGPT is free to
use](https://help.openai.com/en/articles/6783457-chatgpt-faq). But OpenAI
(creators of ChatGPT) haven't released any information about how long this
research preview window will last, or how much it'll cost when that window
ends.

ChatGPT running costs are [estimated at $3m USD per
month](https://twitter.com/tomgoldsteincs/status/1600196995389366274), and
OpenAI are a private company, so they can't necessarily be counted on to keep it
running free forever as a public good. If it's priced similarly to GPT3 (the AI
Language Model on which it's based) then it's fairly cheap---probably only a few
cents to write an article as long as this one---but you're still left with an
equity issue unless you're willing to pay for a subscription for all your
students. Even if your institution is willing, these tools don't yet have an
easy way to do things like sign up a whole class, ensuring that student's activity stays
under a given budget $100, and send one easy bill. I'm sure that will come in
time, and AI companies may well be willing to offer partnerships and
scholarships with educational institutions doing this sort of thing, but be
prepared for a small panic if ChatGPT's free trial gets turned off 24 hours
before an assessment deadline.

I'm not trying to downplay the potential impacts of ChatGPT in higher education
and say "everything's gonna be fine". These tools might [blow up
society](https://www.nytimes.com/2023/01/15/opinion/ai-chatgpt-lobbying-democracy.html),
and higher education is (clearly!) not going to be unaffected if that happens.
My main point is that you can start using them in the classroom today. There
will be some challenges, and you might have to ask yourself some deep questions
about why your class is designed the way it is. But it is a pretty exciting
chance to be part of a community of educators figuring it out together, and
whatever conclusions we come to I do strongly believe that we need to learn how
to live in a world of AI-generated bullshit, so why _wouldn't_ we set our
students up to start that learning journey with us while they're in our
classrooms?



https://stratechery.com/2022/ai-homework/

https://en.wikipedia.org/wiki/Brandolini's_law
https://en.wikipedia.org/wiki/On_Bullshit

https://www.wired.com/story/chatgpt-fluent-bs/ (ChatGPT is fluent in bullshit
because it's trained on (human-created) bullshit)



https://www.cnn.com/2021/11/16/media/steve-bannon-reliable-sources/index.html
("flood the zone")

https://twitter.com/LuminanceBloom/status/1600598003391266816 (snarky zizek
tweet about the absurdity of the whole thing)

https://twitter.com/yoavgo/status/1602026029979164675 (write an essay and
critique the resulting prose)

https://medium.com/essays-and-non-fiction/i-am-a-bullshit-artist-6638eaedb300 (I
am a Bullshit Artist)


how ChatGPT hijacks democracy


Why Metaâ€™s latest large language model survived only three days online
https://www.technologyreview.com/2022/11/18/1063487/meta-large-language-model-ai-only-survived-three-days-gpt-3-science/


NY Schools banning chatgpt

Aussie piece on using chatGPT in HE (positive slant)
https://thebigsmoke.com.au/2023/01/15/chatgpt-banned-in-new-york-schools/



---

## points to make


it's no good trying to ban it

need a plan in-case chatGPT goes behind a paywall

take-home point: it should cause soul-searching about why we set the specific
assessment tasks we set

---

AI language models have advanced to the point where they can generate text that is convincing and difficult to distinguish from human-generated content. This has led to the rise of AI-generated bullshit, which is defined as text that is designed to deceive or manipulate without providing any real information or value.

Brandolini's law states that the amount of energy necessary to refute bullshit is an order of magnitude bigger than to produce it. In other words, the main problem with AI-generated bullshit is not that it will be factually incorrect, but that educators will be overwhelmed by the sheer amount of it.

Better AI-generated bullshit detection tools might seem like the solution, but it is likely to be an endless arms race between the bullshit generators and the detectors. Instead, our society needs to get better at dealing with bullshit at scale.

One way to do this is to teach our students how to recognize and evaluate the quality of written content. This not only helps them avoid being deceived by AI-generated bullshit, but also enables them to become more discerning consumers of information in general. Educators can also play a role by partnering with students to generate and detect bullshit, and by providing guidance on how to navigate the overwhelming amount of information available today.

In conclusion, the use of AI-generated bullshit in higher education is becoming more common and presents both benefits and drawbacks. By being aware of its existence and potential impact, educators and students can make informed decisions about its use and work towards building a society that is better equipped to deal with bullshit at scale.

---

Let's try again. The three points I want to make are:

1. AI language models are now at a point where they can generate convincing bullshit (here I'm using bullshit in the technical sense, following Harry Frankfurt) with minimal human effort
2. Brandolini's law tells us that the main problem here isn't that the text will be wrong, but that educators will be overwhelmed.
3. Better AI-generated bullshit detection tools aren't the answer, because it'll always be an arms race between the bullshit generators and the bullshit detectors.
4. What's clear is that our society needs to get better at dealing with bullshit at scale, and fast. And this is what we should be teaching our students. Which means we get to partner with them in generating the bullshit, but also training them to recognise it (and become more discerning consumers of information in the process).

Can you write the above points into an article for a general audience?

---

_this was the initial one_

I need to write an article on the use of AI-generated bullshit in higher education. I'm not interested in saying either "this is amazing" or "this is terrible". The points I want to make are:

1. AI language models are now at a point where they can generate convincing bullshit (here I'm using bullshit in the technical sense, following Harry Frankfurt) with minimal human effort
The use of AI-generated bullshit in higher education is becoming more common
There are potential benefits and drawbacks to using AI-generated bullshit in higher education
It is important for educators and students to be aware of the existence and potential impact of AI-generated bullshit in order to make informed decisions about its use
In recent years, AI language models have advanced to the point where they can generate text that is convincing and difficult to distinguish from human-generated content. This has led to the rise of AI-generated bullshit, which is defined as text that is designed to deceive or manipulate without providing any real information or value.

One area where AI-generated bullshit is gaining popularity is higher education. In some cases, educators are using AI tools to generate papers and other written assignments that are indistinguishable from human-generated content. This can save time and effort for both students and educators, but it also raises ethical concerns.

On the one hand, AI-generated bullshit has the potential to be a valuable tool in higher education. By automating the production of written assignments, it can free up time for educators and students to focus on more important tasks, such as research and critical thinking. It can also help students learn to identify and evaluate the quality of written content, which is an important skill in the digital age.

On the other hand, there are also potential drawbacks to using AI-generated bullshit in higher education. For one thing, it can be used to cheat on exams and assignments, undermining the integrity of the education system. It can also lead to a proliferation of low-quality content that does not provide any real value or knowledge.

It is important for educators and students to be aware of the existence and potential impact of AI-generated bullshit in higher education. By understanding the potential benefits and drawbacks of using AI tools to generate written content, they can make informed decisions about whether and how to use these tools in their own work. It is also important for educators to develop strategies for detecting and dealing with AI-generated bullshit, in order to maintain the integrity of the education system and ensure that students are learning valuable information and skills.

---
