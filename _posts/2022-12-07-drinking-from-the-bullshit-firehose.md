---
title: Drinking from the bullshit firehose
tags: ai teaching
published: false
---

As I scrolled through my social media feeds over the Christmas break
[I](https://www.ft.com/content/86e64b4c-a754-47d6-999c-fcc54f62fb5d)
[read](https://www.theatlantic.com/technology/archive/2022/12/chatgpt-ai-writing-college-student-essays/672371/)
[through](https://www.theguardian.com/technology/2022/dec/04/ai-bot-chatgpt-stuns-academics-with-essay-writing-skills-and-usability)
[several](https://garymarcus.substack.com/p/how-come-gpt-can-seem-so-brilliant)
"what do AI tools like ChatGPT mean for the future of Higher Education"
pieces---I'm sure you did as well. I'm somewhat reluctant to add to that
discourse, because most of my thoughts on the issue have already been made.

I was at a BBQ dinner with a colleague last weekend and our chat turned to
"how's your class shaping up for the coming semester?" They were aware of
ChatGPT and weren't worried about it destroying the fabric of higher education
or anything like that, but they were a bit unsure about if and how they could
make use of it in their class. So here are a few things to think about if you're
in that position. I'm going to use ChatGPT as an example (because it's the hot
one right now), but similar questions apply for any AI content generation tool,
whether for generating text
[images](https://stability.ai/blog/stablediffusion2-1-release7-dec-2022),
[music](https://www.riffusion.com),
[voiceover](https://blog.elevenlabs.io/enter-the-new-year-with-a-bang/) or
[video](https://twitter.com/SmokeAwayyy/status/1613765555768668160).

First, if your class includes student deliverables which involve submitting
written work (e.g. essays, but also process blogs, forum posts and more), some
of your students are going to use ChatGPT to write their submissions. It's
inevitable, and although the NY Schools district is trying to bury its head in
the sand and [ban
ChatGPT](https://www.nbcnews.com/tech/tech-news/new-york-city-public-schools-ban-chatgpt-devices-networks-rcna64446),
position is (in my opinion) both
[wrongheaded](https://time.com/6246574/schools-shouldnt-ban-access-to-chatgpt/)
and [too difficult to enforce in
practice](https://www.theguardian.com/technology/2023/jan/12/college-student-claims-app-can-detect-essays-written-by-chatbot-chatgpt).

So, as you look over your course outline and assessment schedule you need to ask
yourself whether you care if your students use ChatGPT. It's a question that
goes to the heart of why we set deliverables at all, which includes reasons like
[legal
compliance](https://www.teqsa.gov.au/guides-resources/resources/guidance-notes/guidance-note-course-design-including-learning-outcomes-and-assessment)
but for most educators is also about deeply held ideals about education as the
pursuit of knowledge and truth, as well as what it means to give a good (or bad)
grade.

Maybe you don't care, or at least you don't care enough to re-jig your whole
class to "defend" against students using ChatGPT to submit work that they don't
understand. I think that's an ok position to take for now, while other educators
do try and fail and we learn from each others experiences in how best to
incorporate these tools in our classrooms. But you should at least think hard
about "why do I set that particular essays as the final assessment item in this
course, and what would it mean if a student used ChatGPT to write it?"

Secondly, there are ways to 




discussion about ChatGPT in general, especially in the context of Higher Education






https://stratechery.com/2022/ai-homework/

https://en.wikipedia.org/wiki/Brandolini's_law
https://en.wikipedia.org/wiki/On_Bullshit

https://www.wired.com/story/chatgpt-fluent-bs/ (ChatGPT is fluent in bullshit
because it's trained on (human-created) bullshit)

https://twitter.com/kjhealy/status/1600167449449549825 (Kieran Healy on
chatGPT-designed syllabus)

https://www.cnn.com/2021/11/16/media/steve-bannon-reliable-sources/index.html
("flood the zone")

https://twitter.com/LuminanceBloom/status/1600598003391266816 (snarky zizek
tweet about the absurdity of the whole thing)

https://twitter.com/yoavgo/status/1602026029979164675 (write an essay and
critique the resulting prose)

https://medium.com/essays-and-non-fiction/i-am-a-bullshit-artist-6638eaedb300 (I
am a Bullshit Artist)

WashU has already got a pretty helpful ChatGPT page up on their CLT website
https://ctl.wustl.edu/resources/chatgpt-and-ai-composition-tools/

how ChatGPT hijacks democracy
https://www.nytimes.com/2023/01/15/opinion/ai-chatgpt-lobbying-democracy.html

Why Metaâ€™s latest large language model survived only three days online
https://www.technologyreview.com/2022/11/18/1063487/meta-large-language-model-ai-only-survived-three-days-gpt-3-science/

estimated ChatGPT running costs: $3m USD per month
https://twitter.com/tomgoldsteincs/status/1600196995389366274

NY Schools banning chatgpt

Aussie piece on using chatGPT in HE (positive slant)
https://thebigsmoke.com.au/2023/01/15/chatgpt-banned-in-new-york-schools/

https://www.timeshighereducation.com/campus/chatgpt-and-rise-ai-writers-how-should-higher-education-respond

---

## points to make


it's no good trying to ban it

need a plan in-case chatGPT goes behind a paywall

take-home point: it should cause soul-searching about why we set the specific
assessment tasks we set

---

AI language models have advanced to the point where they can generate text that is convincing and difficult to distinguish from human-generated content. This has led to the rise of AI-generated bullshit, which is defined as text that is designed to deceive or manipulate without providing any real information or value.

Brandolini's law states that the amount of energy necessary to refute bullshit is an order of magnitude bigger than to produce it. In other words, the main problem with AI-generated bullshit is not that it will be factually incorrect, but that educators will be overwhelmed by the sheer amount of it.

Better AI-generated bullshit detection tools might seem like the solution, but it is likely to be an endless arms race between the bullshit generators and the detectors. Instead, our society needs to get better at dealing with bullshit at scale.

One way to do this is to teach our students how to recognize and evaluate the quality of written content. This not only helps them avoid being deceived by AI-generated bullshit, but also enables them to become more discerning consumers of information in general. Educators can also play a role by partnering with students to generate and detect bullshit, and by providing guidance on how to navigate the overwhelming amount of information available today.

In conclusion, the use of AI-generated bullshit in higher education is becoming more common and presents both benefits and drawbacks. By being aware of its existence and potential impact, educators and students can make informed decisions about its use and work towards building a society that is better equipped to deal with bullshit at scale.

---

Let's try again. The three points I want to make are:

1. AI language models are now at a point where they can generate convincing bullshit (here I'm using bullshit in the technical sense, following Harry Frankfurt) with minimal human effort
2. Brandolini's law tells us that the main problem here isn't that the text will be wrong, but that educators will be overwhelmed.
3. Better AI-generated bullshit detection tools aren't the answer, because it'll always be an arms race between the bullshit generators and the bullshit detectors.
4. What's clear is that our society needs to get better at dealing with bullshit at scale, and fast. And this is what we should be teaching our students. Which means we get to partner with them in generating the bullshit, but also training them to recognise it (and become more discerning consumers of information in the process).

Can you write the above points into an article for a general audience?

---

_this was the initial one_

I need to write an article on the use of AI-generated bullshit in higher education. I'm not interested in saying either "this is amazing" or "this is terrible". The points I want to make are:

1. AI language models are now at a point where they can generate convincing bullshit (here I'm using bullshit in the technical sense, following Harry Frankfurt) with minimal human effort
The use of AI-generated bullshit in higher education is becoming more common
There are potential benefits and drawbacks to using AI-generated bullshit in higher education
It is important for educators and students to be aware of the existence and potential impact of AI-generated bullshit in order to make informed decisions about its use
In recent years, AI language models have advanced to the point where they can generate text that is convincing and difficult to distinguish from human-generated content. This has led to the rise of AI-generated bullshit, which is defined as text that is designed to deceive or manipulate without providing any real information or value.

One area where AI-generated bullshit is gaining popularity is higher education. In some cases, educators are using AI tools to generate papers and other written assignments that are indistinguishable from human-generated content. This can save time and effort for both students and educators, but it also raises ethical concerns.

On the one hand, AI-generated bullshit has the potential to be a valuable tool in higher education. By automating the production of written assignments, it can free up time for educators and students to focus on more important tasks, such as research and critical thinking. It can also help students learn to identify and evaluate the quality of written content, which is an important skill in the digital age.

On the other hand, there are also potential drawbacks to using AI-generated bullshit in higher education. For one thing, it can be used to cheat on exams and assignments, undermining the integrity of the education system. It can also lead to a proliferation of low-quality content that does not provide any real value or knowledge.

It is important for educators and students to be aware of the existence and potential impact of AI-generated bullshit in higher education. By understanding the potential benefits and drawbacks of using AI tools to generate written content, they can make informed decisions about whether and how to use these tools in their own work. It is also important for educators to develop strategies for detecting and dealing with AI-generated bullshit, in order to maintain the integrity of the education system and ensure that students are learning valuable information and skills.

---
