---
title: "Academic integrity guidelines re: ChatGPT and generative AI tools"
tags: teaching ai
---

Here in Australia Semester 1 is approaching and
[ChatGPT](https://chat.openai.com) is, undoubtedly, _a thing_. From a practical
perspective it's important to have some​ sort of guidelines about about ChatGPT
and other generative AI tools in the classroom ([everyone's doing
it](https://twitter.com/dbkahn/status/1616494433587040257)). If you don't
provide any advice ahead of time you'll end up making it up as you go along
(because it _will_ come up) and [policy on the run is policy
underdone](https://www.youtube.com/watch?v=7XeQin9abx4).

In terms of the opportunities to incorporate, explore and critique new tools in
the classroom, I'm actually kindof excited. [I've written elsewhere about how
you might be able to do
this](https://www.timeshighereducation.com/campus/so-you-want-use-chatgpt-classroom-semester).
The _tl;dr_ is that you should look at your class activities (including
assessment items) and try and actually _do_ them with ChatGPT, just to see how
it goes. OpenAI have also just released some stuff about [considerations for
educators](https://platform.openai.com/docs/chatgpt-education).

{:.hl-para}

At this stage these are just my own personal thoughts as a teaching academic;
I'm not wearing my [Associate Director
(Education)](https://cybernetics.anu.edu.au/people/ben-swift/) hat here, and
**this is not an official (or unofficial) ANU School of Cybernetics policy**. If
you're also putting together some guidelines for your own classroom, then
questions/comments/suggesions are welcome---do [get in
touch](mailto:ben.swift@anu.edu.au).

Here are my current thoughts what some good _use of ChatGPT in the classroom_
guidelines might look like. It doesn't have everything precisely defined, but it
gives you an idea of how I want to run my classes, balancing the opportunities
and challenges these tools present for student learning.

1. Unless otherwise specified, you **are** allowed to use
   ChatGPT[^other-similar-tools] in this class, including in work submitted for
   assessment.

2. Wherever ChatGPT is used it must be cited according to the [OpenAI citation
   instructions](https://platform.openai.com/docs/chatgpt-education/disclosing-the-use-of-chatgpt).[^attribution]

3. You are responsible for everything you submit. "It's not my fault---the AI
   generated text introduced non-sequiturs/errors/plagiarised text/offensive
   language" will never get you off the hook; if it's in your submission you're
   responsible for it just as you would be if you'd written it without ChatGPT.

4. You are expected to be able to explain (to your tutor, lecturer or course
   convenor) any assessment submission to demonstrate your understanding of the
   concepts being assessed.

5. Any violations of the above will be considered a potential breach of academic
   integrity under clause 9 of section 12(2) of the [ANU Academic Integrity
   Rule](#appendix-anu-academic-integrity-rule) "improperly recycles work or
   otherwise improperly submits or publishes work that is not original"
   (**note**: I'm unsure on which clause is best to use here---could be clause
   8, could be one of the others as well).

6. No "is-this-written-by-an-AI?"​ detection tools (e.g.
   [this](https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text/))
   will be used as part of the marking process.

[^other-similar-tools]:
    Wherever ChatGPT is named in these guidelines it should be read as "ChatGPT
    and other generative AI tools", where those tools are defined according to
    (ERROR: definition not found). Any guidelines which are restrict themselves
    to specific AI tools by name are doomed to become out of date real fast.

[^attribution]:
    These guidelines deliberately doesn't try to address the (important) issue
    of AI tools and the way they appropriate the skilled labour of the millions
    of individuals who created, edited and labelled the data on which they were
    trained.

One open question (not necessarily part of the student-facing guidelines, but
relevant for anyone running a course) is what guidance should be given to the
markers (e.g. tutors/TAs) on what to do when marking ChatGPT-generated content.
Should submissions created with the help of ChatGPT be marked lower than
"equivalent standard" (whatever that means) submissions that aren't?

Anyway, these are just some draft thoughts---I'll keep this post updated as my
thinking changes.

## Appendix: ANU Academic Integrity Rule {#appendix-anu-academic-integrity-rule}

From the [ANU Academic Integrity Rule
2021](https://www.legislation.gov.au/Details/F2021L00997/Html/Text#_Toc73961519)
Section 12 (2), here's the list of what constitutes a breach of the academic
integrity principle.

<style>
#academic-integrity-definitions ol {list-style-type: lower-alpha;}
#academic-integrity-definitions ol ol {list-style-type: lower-roman;}
</style>

<div id="academic-integrity-definitions" markdown="1">

> (2) For this instrument, a student breaches the academic integrity principle if, in scholarly practice, the student:
>  1. cheats; or
>  2. impersonates another person; or
>  3. engages in plagiarism; or
>  4. colludes with another person; or
>  5. improperly shares material with another person; or
>  6. engages in contract cheating or improperly engages another person to prepare, or assist in preparing, work for the student; or
>  7. submits or publishes anything that fails to correctly or appropriately acknowledge the work of another person or otherwise improperly appropriates the intellectual property or contribution of another person; or
>  8. otherwise passes off the work of another person as the student’s own work; or
>  9. improperly recycles work or otherwise improperly submits or publishes work that is not original; or
> 10. takes a prohibited item into an examination or other assessment venue or otherwise breaches the University’s directions (however described) in relation to an examination or other assessment; or
> 11. fabricates or falsifies any document, data or other information, or anything else, including, for example, by intentionally omitting data to obtain a desired result, or by falsely representing observations as genuinely held; or
> 12. otherwise intentionally or recklessly engages in conduct:
>     1. that impedes the progress of research; or
>     2. that risks corrupting research records or compromising the integrity of research practices; or
>     3. that uses research data from another person without appropriate acknowledgement; or
>     4. that breaches a research protocol approved by a research ethics committee or a statutory licence condition applying to research; or
> 17. otherwise engages in conduct with the intention of gaining, or assisting another person to gain, an unethical, dishonest, unfair or unjustified advantage; or
> 18. otherwise engages in conduct, or assists another person to engage in conduct, that is unethical, dishonest or unfair; or
> 19. engages in any other conduct declared to be academic misconduct by the orders.

My commentary on the above (and IANAL) is that none of those points really
capture the specific case of "ChatGPT wrote this essay, not the student", in
particular because so many of the definitions reference "of another _person_".
I'm sure this language will be updated in the future in light of the widespread
availability of generative AI tools.
